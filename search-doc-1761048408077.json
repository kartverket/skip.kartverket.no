{"searchDocs":[{"title":"20 teams on SKIP: What we've learned along the way","type":0,"sectionRef":"#","url":"/blog/20-teams-on-skip","content":"","keywords":"","version":null},{"title":"Principles matterâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#principles-matter","content":" When you set out to create something new, you have the privilege of setting some standards that encourage best practices. While this is possible to do for an existing system, in practice it will mean a lot of work to get to the point where you're able to enforce these standards. It's much easier to start with a clean slate.  For our platform, we decided on a set of principles that we wanted to follow. Some of these are:  Stateless: Our clusters are stateless, which means that we can easily replace them if something goes wrong. All configuration is held in a GitOps repository and all state is held in external systems like managed databases, object storage, etc. This significantly reduces operational complexity and recovery time. If a cluster fails we can easily replace or revert it by applying the configuration from the GitOps repository without worrying about losing state, or doing time-consuming data recovery operations.Ownership: For each application, there is a clear owner. This owner is responsible for the application and maintains and supports it. This way we're able to avoid the &quot;tragedy of the commons&quot;, where no one is responsible for an application. If an app has unclear or short-term ownership, you simply don't get to use the platform. We're not an orphanage.Financing: You use the platform? You also need to pay for its continued support and development. We're working towards a chargeback model where your department is billed for the resources they use as a way to ensure that the platform is sustainable. Until this is ready, we expose the costs of the resources used by each team and then negotiate with the departments on how to cover these costs, but this is time-consuming work.Secure by default: We enforce security best practices by default. Examples of this are zero trust networking with Network Policies, where no app can talk to another without explicitly allowing this. Some applications will need to opt out of some of these defaults, and they can do so by altering their configuration. But the defaults are secure, which is especially useful for teams that are new to Kubernetes.  All teams that are onboarded on SKIP are given an introduction to these principles and are expected to follow them. This means that being able to use the modern platform is contingent on the teams being able to prioritize modernizing their applications and working in sustainable ways, which helps push for positive change.  ","version":null,"tagName":"h2"},{"title":"Encourage collaborationâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#encourage-collaboration","content":" It's easy for a product team to ask the platform team for help when they're stuck. We're always happy to help, but we also have a heavy workload of exciting things we're working on. Therefore it's much better when platform users can help each other, as this facilitates collaboration and learning. This is why we highly encourage teams to help each other out - to build a community around the platform.  In practice this is done through a single Slack channel where all teams that are using the platform are invited. This is a great place to ask questions, share experiences, and learn from each other - and it's a place where all new features and changes are announced. We used to have many different channels for different teams, but we found that this was not as effective for building a community as a channel where everyone can help each other out.  And a final tip: As a platform developer, sometimes it's better to wait a little while before responding to questions in these channels to allow the community to help each other out before you jump in and help.  ","version":null,"tagName":"h2"},{"title":"Make time for innovationâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#make-time-for-innovation","content":" It's easy to get bogged down in the day-to-day work of keeping the platform running. This is why it's important to set aside time for innovation, this is something we take very seriously.  On SKIP we have dedicated innovation days where we work on new features, improvements, and other things that we think will make the platform better. This is an extraordinarily successful initiative, and we've seen many great features come out of these days. It's also a great way to build team morale and to build a culture of learning and innovation.  In practice we have two days in a row of dedicated innovation work every other month. We used to have one day every month, but we found that this was not enough time to really get into the flow of things so we started doing two days every 2 months, which worked better. We also have a rule that you can't work on anything that's on the roadmap, as this is work that we're already going to do. This is a great way to get new ideas and to work on things that might not otherwise get done.    There's a little bit of structure around these days, but not too much.  First, it is understood by everyone that these days are for things that are &quot;useful for Kartverket&quot;. This means that you can't work on your own pet project, but it's vague enough that you can work on pretty much anything that you think will be useful for the organization.  Then, a week before the innovation day we will have a &quot;pitching session&quot;, where everyone who has an idea can pitch it to the rest of the team. This is a great way to get feedback on your idea and to get others to join you in working on it.  Finally, we have a &quot;show and tell&quot; session at the end of the last day where everyone shows what they've been working on. This way we can share our experiences and discuss if this work can be improved and put into production. We encourage everyone to show something, even if it's not finished or you did video lessons, as this creates discussion and further ideas.    There's plenty of examples of features that are results of work done on these days. On-premise Web Application Firewall with Wasm, Grafana features, open source tools like Skiperator andSkyline as well as this very website!  No one has time to prioritize innovation, and we're no different. But we prioritize it anyway, because we know that it's important to keep improving and to keep learning.  ","version":null,"tagName":"h2"},{"title":"Communication is keyâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#communication-is-key","content":"   Unfortunately a lot of infrastructure teams don't prioritize communication very well. This is a mistake. Communication is key to building a successful platform.  Your users exist in the context of all the platform features that you have shipped and the changes you will ship in the future. Not informing them and keeping them up to date with what's going on is a surefire way to lose their trust and to make them unhappy.  It starts with simply informing users of the new features that ship. This can be done through a Slack channel, a newsletter, a blog or a town hall meeting. We use a combination of all of these, but the most important thing is that you inform your users of what's coming. An added benefit of this is helps push adoption of new features and excitement around the platform by showcasing innovation.  The next step is informing users on what will ship and when. This will help users plan their work and to know what to expect, but it also helps users feel involved when they see their requests being planned. This can be done through a roadmap, a technical forum, or a blog. We use a combination of all of these, but the easiest way to do this is to have a roadmap that you keep up to date on a regular basis.  Now for the hard part: When things go wrong, you need to communicate this as well. Product teams will want to know when their applications are affected by outages or other issues, and they will want to know what you're doing to fix it. This can be done through a status page, a Slack channel, or postmortems. Again, we use a mix of these so that we can reach as many users as possible at the right time.  Do these things and you will have happy users that feel informed.  ","version":null,"tagName":"h2"},{"title":"Branding is importantâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#branding-is-important","content":"   Do you think Spotify would be as successful if it was called &quot;Music Player&quot;? Do you think Apple would be as successful if it was called &quot;Computer Company&quot;? Of course not. Branding is important. It builds a sense of identity and community around your platform.  This is especially important for a platform team, as you're not just building a product, you're building a community. You want your users to feel like they're part of something bigger, and you want them to feel excited to use the platform.  When you're starting out, you want to drive adoption. Here a brand really helps as it's easier to talk about a good brand in a positive way. It's also easier to get leadership buy-in when you have a strong brand.  This holds true when you're more established as well. When you grow larger than your ability to talk to everyone, a brand helps you communicate your values and intent to your users, which will drive organic growth from teams that want to work with you.  A minimum viable brand is a logo, a name, and a color scheme. This is something you should think deeply about, as it's something that will stick with you for a long time. After this you can think about a website, merchandise like stickers and t-shirts, and a mascot. These things are not necessary, but they can help build a sense of identity and community around your platform.  ","version":null,"tagName":"h2"},{"title":"Using the cloud is a long journeyâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#using-the-cloud-is-a-long-journey","content":" As a platform team, it's our responsibility to push for modern, user-friendly and secure solutions. This generally means using public cloud solutions like Google Cloud Platform. But for most organizations, pushing this narrative incurs significant friction and to some extent fear due to legal and cost concerns. This is understandable, as the known is always more comfortable than the unknown, and it's a view that's hard to change.  This is why it's important to take a long-term view on this. You're not going to move everything to the cloud overnight, and you're not going to convince everyone to get on board with this idea overnight. It's a long journey, and you need to be patient and persistent.  We've spent years pushing for the cloud, and we're still not there. You're going to have to participate in many (many!) meetings, and you're going to have to fight for every little thing over and over again. But it's necessary. Once everyone has a clear understanding of the risks and how to mitigate them, you will be able to formulate a document guiding the organization's teams on how to get to the cloud from a compliance point of view.  If you asked me for any recommendations on how to get to the cloud as easily as possible, it would be to first get leadership buy-in across the organization. This is important, as it will make any large initiative like cloud migration easier. After this and a competent platform team is in place, you can start pushing for the cloud technologies and eventually cloud migration. Here you need to talk directly with the legal team, not via other people. Have representatives of the platform team sit down with the lawyers and talk through the risks and how to mitigate them. This is the only way you can combine the technical and legal aspects of this work. Working in silos and not talking to each other is a surefire way to fail.  ","version":null,"tagName":"h2"},{"title":"Autonomy and platform as a productâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#autonomy-and-platform-as-a-product","content":" Your platform is a product, and so you need to work as a product team. This means continuously improving your product, listening to your users, and building the features that they need.  Research-based literature like &quot;Team Topologies&quot; establishes the importance of autonomous teams in modern organizations. Traditional top-down organizations are just not going to be able to have as close of a relationship with their stakeholders as a team that is able to proactively understand the needs of their users and make their own decisions that push continuous improvement of their products. This is why it's important, even for infrastructure teams, to be able to own their roadmap and make decisions on what to build when.  As a team you're obviously limited to the amount of resources you have and not able to do everything, so understanding the needs of your stakeholders and prioritizing them is essential. You need to do research to know the needs of your users; sometimes requests don't align well with the actual needs. Just because someone asks loudly for something, doesn't mean it's the right fit for your platform. Saying yes to everything does not result in a good product. Dare to challenge assumptions and ask why.  ","version":null,"tagName":"h2"},{"title":"Abstractions save timeâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#abstractions-save-time","content":" It should go without saying that a platform team's job is to make tools that make product teams' jobs easier. But it really can't be said enough. The better the tooling you provide, the less you have to do support. This is a win-win for everyone.  When building tools, think about how you can abstract away complexity. This can be done in many ways, but we've had great success building an operator that abstracts away the complexity of managing applications on Kubernetes. The operator is called Skiperator and makes deploying applications on Kubernetes as easy as writing a configuration manifest.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: namespace: sample name: sample-two spec: image: nginxinc/nginx-unprivileged port: 80 replicas: 2 ingresses: - foo.com - bar.com   The key takeaway here is that abstractions like Skiperator are designed to speak the language of the user. There is no mention of NetworkPolicies or Istio VirtualServices in the configuration, as these are things that the user generally doesn't have any knowledge of. Instead, the user can specify things like &quot;I want to expose this service to the internet&quot; or &quot;I want to run this job every day at midnight&quot;. This simplifies the user experience of Kubernetes, which is a complex system, and makes it easier for users to get started.  Work smarter not harder.  ","version":null,"tagName":"h2"},{"title":"Build forward- and backwards compatibilityâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#build-forward--and-backwards-compatibility","content":" We've had multiple experiences where we've weighed our options and decided to make a breaking change. Just recently we asked our users to migrate their apps from one cluster to another in order to improve the architecture of the platform. Multiple options were considered, but in the end the scale of the changes meant that upgrading the clusters in-place would not be practical, so we commissioned new clusters with the new architecture and asked users to migrate their apps.  In our case, we had a simple way to migrate, only requiring moving a config file from one directory to another to make the change. But even so, this was a time consuming process for our users, and a laborious process for us to support. This is because even though the change was simple, it was still a change that required testing and validation, and it was a change that was not necessarily the highest priority for the teams that were asked to make it. So even though the change was simple, it took months.  If you ask your users to make changes to their applications, you're asking a team that is already busy to do more work. Any changes you ask them to make will take time, as it would not necessarily be the highest priority for them. Therefore avoiding breaking changes should be a primary goal, so wherever possible building in forward and backwards compatibility by inferring as much as possible from the existing configuration is a good thing.  When building operators, don't change or remove fields that are in use. Use default values for new fields, and use lists of objects instead of raw values like lists of strings as they are easier to extend.  ","version":null,"tagName":"h2"},{"title":"Documentation is keyâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#documentation-is-key","content":" One thing we keep hearing from our users is the need for more and better documentation. This is understandable. When you're using a platform, you don't want to have to ask for help all the time - you want to be able to discover platform features and implement them yourself with the support of good documentation.  The point here is that as a platform team you need to prioritize documentation. A task is not done until it has been documented. This way announcing new features will always include a link to the documentation where users can dive deeper into the feature and how to use it, like the example below.    The bigger challenge here is preventing documentation from going stale. It's too easy to forget about updating documentation to reflect changes in the code. Here we can share a few tips from our experience:  First, the obvious way to keep docs up to date is to allocate time to update them. One way we do this is that a few times a year we will do a documentation grooming session where we huddle together and review documentation, rewriting it when we find out of date information.  A more interesting way to keep docs up to date is changing how you respond to questions. Instead of answering questions immediately, we should be asking ourselves: &quot;How can we make sure that this question never gets asked again?&quot;. In our case we spend some time to write documentation or improve existing documentation and reply with a link to the documentation page. This is a triple win, as you will now have more updated documentation, save time in the future by being able to refer to the improved docs instead of writing a lengthy response and the user will now know where to look for answers.  ","version":null,"tagName":"h2"},{"title":"Learn from othersâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#learn-from-others","content":" When building a platform you'll quickly learn that you don't have all the answers. You might discuss how to implement a feature with your team, but you might not have the experience to know what works well in this context. When you get into this situation, an outside perspective can be crucial to avoid making costly mistakes.  One great advantage of working in the public sector is that we can ask other public sector platform teams for advice and learn from their experiences. We can also share our experiences with others, which is usually interesting. Invest some time in building these relationships of mutual benefit.    I also want to give special credit to Hans Kristian Flaatten and the Public PaaS network here. Having a shared forum to discuss platform issues is a strong asset and helps the Norwegian public sector get ahead and stay competitive.  Even if you work in the private sector, you can still learn from other organizations. Honestly, if you want to learn from someone's experiences it never hurts to ask. Teams generally want to help each other out, and it's usually possible to make a trade of some sort. I suggest to offer to give a talk on your experiences and ask if they can do the same. It's a win-win for both parties.  ","version":null,"tagName":"h2"},{"title":"Conclusionâ€‹","type":1,"pageTitle":"20 teams on SKIP: What we've learned along the way","url":"/blog/20-teams-on-skip#conclusion","content":" You may think building a platform is mostly technology, and we've written a lot about technology in previous blog posts. But it's important to remember that building a platform is also about building a community, and communities have expectations and needs that go beyond technology. This is a strength, and not a weakness, as if you're able to inspire and motivate your users you will be able to build a platform that is sustainable and that drives positive change in your organization.  Best of luck in your endeavors! ","version":null,"tagName":"h2"},{"title":"Hybrid Kubernetes in production pt. 1","type":0,"sectionRef":"#","url":"/blog/hybrid-kubernetes-in-production-part-1","content":"","keywords":"","version":null},{"title":"So why a hybrid cloud?â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#so-why-a-hybrid-cloud","content":"   Were you to take the time machine back a few years, you would see Kartverket as a traditional enterprise with a lot of knowledge and experience in running on-premise workloads. This knowledge served us well, but also slightly held us back in terms of our imagination. We knew that there had to be a better way, but our enterprise was simply not mature enough to adopt a pure cloud strategy. The fear of the unknown cloud weighed heavily on many people, and therefore few people wanted to take the risk of moving to the cloud.  This is something we've worked on for a long time, and still are. After a long time of working with the stakeholders in the organization, we eventually built a cloud strategy, which in simple terms stated that we would prefer SaaS-products over hosting things ourselves, and that we would gradually move our workloads to the cloud.  This cloud strategy however, which cleared up a lot of blockers, came too late for us on SKIP. At that point we had already done most of the work on our on-premise platform, building on the assumptions the organization held at the time, which was that we met our needs through existing infrastructure and that using public cloud had disqualifying cost and compliance implications. For SKIP it was therefore full steam ahead, building the on-prem part first, then adding the hybrid and cloud part later.  It's not like we would have ended up with a pure cloud setup in any case, though. If you're at all familiar with large enterprises, you will know that they are often very complex. This is also true for Kartverket, where we have a lot of existing systems that are not easy to move to the cloud. We also have a lot of systems that are not suitable for the cloud, mostly because they are designed to run in a way that would not be cost effective in the cloud. In addition we have absolutely massive datasets (petabyte-scale) that would be very expensive to move to the cloud.  Because of these limitations, a pure cloud strategy is not considered to be a good fit for us.  A hybrid cloud, however, can give us the scalability and flexibility of the cloud, while still allowing us to run some of our systems on-prem, with the experience being more or less seamless for the developers.  ","version":null,"tagName":"h2"},{"title":"Why we chose Anthosâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#why-we-chose-anthos","content":" After some disastrous issues with our previous hybrid cloud PoC (that's a whole story in itself) we decided to to look at what alternatives existed on the market. We considered various options, but eventually decided to run a PoC on Anthos. This was based on a series of conditions at the time, to name a few:  We had a decent pool of knowledge in GCP compared to AWS and Azure at the timeSome very well established platform teams in the public sector were also using GCP, which meant it would be easier to share work and learningsAnthos and GCP seemed to offer a good developer experience, which for us as a platform team is of paramount importanceA provider like Google is well established in the cloud space (especially Kubernetes), and would have a fully featured, stable and user friendly product  SKIP ran the Anthos PoC over a few months, initially as an on-prem offering only. Drawing on the knowledge of internal network and infrastructure engineers, this took us all the way from provisioning clusters and networking, to iterating on tools and docs and finally onboarding an internal product team on the platform. Once we felt we had learned what we could from the PoC, we gathered thoughts from the product team, infrastructure team and of course the SKIP platform team.  The results were unanimous. All the participants lauded the GCP user interfaces that allowed visibility into running workloads, as well as the new self-service features that came with it. Infrastructure engineers complimented the installation scripts and documentation, which would make it easier to keep the clusters up to date.  Based on the total package we therefore decided to move ahead with Anthos. To infinity and beyond! ðŸš€  ","version":null,"tagName":"h2"},{"title":"What is Anthos anyway?â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#what-is-anthos-anyway","content":"   Anthos is Google's solution to multicloud. It's a product portfolio where the main product is GKE (Google Kubernetes Engine) on-premise. Using GKE on-prem you can run Kubernetes clusters on-premise and manage them from the same control plane in Google Cloud, as if they were proper cloud clusters.  In fact, Anthos is truly multi-cloud. That means you can deploy Anthos clusters to GKE and on-prem, but also AWS and Azure. On other cloud platforms it uses the provider's Kubernetes distribution likeAKS, but you can still manage it from GKE alongside your other clusters.  In addition to GKE, the toolbox includes:  ","version":null,"tagName":"h2"},{"title":"Anthos Service Mesh (ASM)â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#anthos-service-mesh-asm","content":" A networking solution based on Istio. This is sort of the backbone of the hybrid features of Anthos, as provided you've configured a hybrid mesh it allows applications deployed to the cloud to communicate with on-premise workloads automatically and without manual steps like opening firewalls.  All traffic that flows between microservices on the mesh is also automatically encrypted with mTLS.  ","version":null,"tagName":"h3"},{"title":"Anthos Config Managment (ACM)â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#anthos-config-managment-acm","content":" A way to sync git repos into a running cluster. Think GitOps here. Build a repo containing all your Kubernetes manifests and sync them into your cluster, making cluster maintenance easier.  ACM also includes a policy controller based on Open Policy Agent Gatekeeper (OPA) which allows platform developers to build guardrails into developers' workflows using policies like &quot;don't allow containers to run as root&quot;.  ","version":null,"tagName":"h3"},{"title":"Anthos Connect Gatewayâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#anthos-connect-gateway","content":" The connect gateway allows developers to log on to the cluster using gcloudand kubectl commands, despite the cluster potentially being behind a firewall. From a user experience standpoint this is quite useful, as devs will be logged in to GCP using two factor authentication, and the same strong authentication allows you to access kubernetes on-premise.  Connect Gateway also integrates with GCP groups, enabling RBAC in Kubernetes to be assigned to groups instead of manually administered lists of users.  Currently the connect gateway only supports stateless requests, for examplekubectl get pods or kubectl logs (including -f). It does not supportport-forward, exec or run, which can be a bit annoying.  ","version":null,"tagName":"h3"},{"title":"Summaryâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 1","url":"/blog/hybrid-kubernetes-in-production-part-1#summary","content":" As you can see, the above tools gives us a lot of benefits.  Combined with the power of Google Cloud and Terraform, they give us a good combination of flexibility through cloud servicesEase the maintenance by using the tools that Anthos and Terraform supply usEases the compliance and modernization burden by allowing a gradual or partial migration to cloud, allowing parts to remain on-premise while still retaining most of the modern tooling of the cloud  That's it for now! ðŸ™‚ We'll be back with more details on how we run Anthos as well as the pros and cons we've seen so far in the coming weeks. Stay tuned!  Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not endorsed by or affiliated with Google in any way. ","version":null,"tagName":"h2"},{"title":"Crisis Management Exercises","type":0,"sectionRef":"#","url":"/blog/crisis-management-exercises","content":"","keywords":"","version":null},{"title":"Exercise 1: Malicious actorâ€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#exercise-1-malicious-actor","content":"   The first exercise scenario revolved around a malicious actor gaining privileged access to our production Kubernetes cluster, simulated in this case by our internal sandbox cluster. Admittedly, it was somewhat difficult to set up a realistic scenario without outright disabling some of our security tools, so in the end we simulated a hostile takeover of the user account belonging to the person responsible for planning and running the exercise.  The first sign that something was amiss was an alert from our Sysdig Secure toolset, a Falco-based agent software which continually monitors our cluster for signs of abnormal activity according to a predefined ruleset and provides a SaaS portal for further analysis and management of threats. (We will cover more of our security features and mechanisms and how we try to build a modern kubernetes based application platform with built-in security and zero trust in a future blog post.) After initial examination, we found that the incident was of such a nature that we engaged our crisis management plan in order to investigate, contain and mitigate the incident. We simulated communication with the organization-level crisis management team, having regular meetings in order to keep them informed of progress. Systematic examination of logs and audit logs soon turned up suspicious activity confined to one specific platform developer account, and the decision was made to immediately suspend (simulated in this case) the account, removing all access to organizational systems and in effect locking it out. Simultaneously, the malicious software was removed once enough evidence was secured in order to further analyze the actions and impact of it. The exercise was announced as ended once we suspended the compromised user account and removed the malicious application while retaining and analyzing enough logs, forensic captures and other traces of activity.  ","version":null,"tagName":"h2"},{"title":"Exercise 2: \"Everything is on fire\"â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#exercise-2-everything-is-on-fire","content":"   The second exercise scenario was somewhat more involved, taking place over two days. The incident itself was as follows: A software update or rogue script caused catastrophic hardware failure in production infrastructure, necessitating creation of a new Kubernetes cluster from scratch. Once the cluster itself and all underlying infrastructure had been created and configured, it would then be up to our platform team to deploy all necessary IAM configuration, service accounts, RBAC and supporting systems (Istio, ArgoCD ++) needed to deploy workloads and restore normal operations. The exercise itself focused on this second phase of restoration, as the infrastructure configuration and cluster creation itself is done by another team, with little involvement by our platform team members.  The failure itself was simulated by having our infrastructure team wipe our sandbox environment and present us with a clean-slate Kubernetes cluster. We called an all-hands meeting and set to work restoring services right away. Right at the onset, we recognized that this was a golden opportunity both to ensure that our documentation was up-to-date, consistent and easy to follow, as well as give our three newest team members some much-needed experience and insight into setting up our services from scratch. We therefore decided that the newest team members would be the ones to actually execute all the actions outlined in our documentation, while the rest of us followed along and made notes, updated documentation and otherwise provided guidance throughout the process.  The first run-through of the recovery process took around 2-3 hours before everything was in working order. Keep in mind that we took the time to update our documentation and explain everything we did while we were working, so in a real-life scenario this would have been even quicker. Once the IAM, RBAC, Istio and ArgoCD was up and running, it was merely a matter of using ArgoCD to synchronize and deploy all relevant workloads. Afterwards, we had a meeting to discuss the process and what experiences we gained from it. Based on the feedback from this meeting, we made further adjustments and updates to our documentation in order to make it even easier to follow on a step-by-step basis, focusing on removing any ambiguity and put any &quot;tribal&quot; knowledge among our platform developers into writing. This ensured that we are way less dependent on the knowledge and skillset of specific people, enabling any team member to contribute to recovery efforts by simply following the documentation.  The newest team members greatly enjoyed being responsible for the recovery effort itself, and expressed a wish to run through the scenario again in order to refine their skills and further improve the documentation. Therefore, we decided to set aside most of day 2 to do just that. We had the infrastructure team tear down and setup the cluster again, and let the newest team members loose on it - this time on their own without guidance - an additional two times. The last run-through of the exercise took between 30 and 60 minutes, a significant improvement from the initial attempt.  All in all, we considered the exercise to be a great success, with many important lessons learned and a substantial improvement in the quality of our documentation and crisis management plans.  ","version":null,"tagName":"h2"},{"title":"What did we learn?â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#what-did-we-learn","content":"   ","version":null,"tagName":"h2"},{"title":"Lesson 1: You are only as good as your documentationâ€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-1-you-are-only-as-good-as-your-documentation","content":" Documentation is vitally important during a crisis, and should be detailed enough that any team member may follow it on a step-by-step basis and be able to restore normal service, even with minimal knowledge and during a stressful situation. This ensures that you avoid being dependent upon key personnel that might or might not be available during a crisis scenario, and also ensures that you retain vital institutional knowledge even when team members move on to different tasks or even new jobs.  ","version":null,"tagName":"h3"},{"title":"Lesson 2: Logging, logging, logging! Oh, and monitoring too!â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-2-logging-logging-logging-oh-and-monitoring-too","content":" Having the ability to search through logs of all parts of our system greatly simplifies any incident management, whether the incident revolved around malicious actors or other factors. But logs by themselves are not sufficient - you need some sort of monitoring and alerting system in order to alert on and react to abnormal situations/behaviour in your systems. Ideally, you should be able to react on these alerts instead of messages from users - or worse, customers - that something is wrong.  ","version":null,"tagName":"h3"},{"title":"Lesson 3: Test your plans!â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-3-test-your-plans","content":" Merely having plans, routines and documentation is insufficient. Unless they have been thoroughly tested and their quality assured through crisis exercises in realistic scenarios and conditions, they should be treated as flawed and unreliable until the opposite is proven. Running crisis management exercises is a great way to expose flaws, insufficiencies and outdated documentation, and careful note-taking and postmortems should be the norm throughout the exercise in order to easily identify and update weak spots in your plans and documentation. As systems and circumstances change, so should plans and documentation too in order to reflect the new order of the day.  ","version":null,"tagName":"h3"},{"title":"Lesson 4: Communicate!â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-4-communicate","content":" Openness and communication is critical during both exercises and real-world crisis scenarios. Plans should always involve key points of communication - who needs to be informed, whose responsibility it is to keep said people informed, and the frequency, scope and format of information to disseminate. This also applies to communication afterwards. Anyone in your organization should be able to understand what happened, how it was solved and what lessons were learned from it. In Kartverket, we solve this by writing postmortems about incidents, summing up the incident itself and what we learned from it. We favour Blameless Postmortems, enabling us to quickly and thoroughly analayze and document all aspects of an incident without focusing on individual mistakes and avoid passing blame. This contributes to a culture of openness, learning and improvement. Hoarding information and disseminating it only on a &quot;need-to-know&quot; basis only breeds distrust and contempt, as does a culture that focuses on blaming and punishing people for mistakes instead of learning from them. A further bonus when communicating the happenings and results of your crisis management exercises is the potential to inspire others - when people see the great results and lessons you yourselves have gained from such exercises, they might want to try it with their own systems and teams.  ","version":null,"tagName":"h3"},{"title":"Lesson 5: Let the \"newbies\" handle itâ€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-5-let-the-newbies-handle-it","content":" Putting our newest team members in charge of the recovery operations was a great learning experience for them, as well as enabling us to quickly find flaws and shortcomings in our documentation and crisis management plans. It is also a great confidence booster, because if they succeed, they'll gain valuable insight and positive experiences with setting up all those scary critical systems from scratch - and if they don't succeed, well, that's not their fault, it was because the documentation and training was insufficent to enable them to handle the situation!  ","version":null,"tagName":"h3"},{"title":"Lesson 6: Crisis exercises as team buildingâ€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#lesson-6-crisis-exercises-as-team-building","content":" Crisis exercises are fun and contribute to better teamwork! They bring everyone together in order to achieve a common goal - get things up and running again as quickly as possible. Combine it with &quot;pair programming&quot; - that is, if possible make sure at least two people are working on any given task together - this helps facilitate cooperation and communication, and provides an extra set of eyes to help catch any manual errors or deviations from the plan.  ","version":null,"tagName":"h3"},{"title":"Thank you for reading!â€‹","type":1,"pageTitle":"Crisis Management Exercises","url":"/blog/crisis-management-exercises#thank-you-for-reading","content":" We appreciate you taking the time to read through this blog post. We have learned quite a lot (and had lots of fun) through our approach to crisis management exercises. We hope our experiences and thoughts regarding this subject has been interesting, and that they may inspire others to start doing crisis management exercises as well. ","version":null,"tagName":"h2"},{"title":"Hybrid Kubernetes in production pt. 3","type":0,"sectionRef":"#","url":"/blog/hybrid-kubernetes-in-production-part-3","content":"","keywords":"","version":null},{"title":"Do you really need hybrid?â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#do-you-really-need-hybrid","content":" When we started out, there was an assumption that it was simply impossible to use the cloud. This came from all sides of the organization, so this was taken as a given. SKIP was therefore started as a project to build an on-premise Kubernetes platform to service our needs as a transition to cloud native development principles.  As we moved along, a lot of these assumptions got challenged. We found that most of these assumptions were based on misunderstandings or a lack of a deeper understanding of cloud technologies and the surrounding legal aspects. This led to a fear of the unknown, and subsequent inaction. In the end it turned out that quite a lot of our workloads could indeed run in the public cloud, given some minor adjustments.  Had we started out with the knowledge we have now, we would probably have started with a public cloud provider, and then moved to hybrid when and if we saw a need for it. Using a cloud provider's managed Kubernetes offering is significantly easier than running your own, and you can get started much faster, with less risk.  Given our organization, we would probably have ended up with hybrid anyway, but that complexity could potentially have been moved down the timeline to a point where the platform was more mature.  Starting with hybrid is a massive undertaking, and you should have a good reason for doing so. Do you need hybrid, or do you just need to mature your organization? If you do, reduce the scope of the initial work to get to a workable platform, and preferably start in the cloud, adding hybrid features later. If you're not sure, you probably don't need hybrid.  ","version":null,"tagName":"h2"},{"title":"Hybrid gives your organization flexibilityâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#hybrid-gives-your-organization-flexibility","content":"   Now that we've built a platform that seamlessly runs workloads in both public cloud and on-premise, we have a lot of flexibility in where we run our workloads and how we manage them. Our experience is that this makes it easier for the organization to mature legacy workloads.  All our greenfield projects are written with cloud native principles in mind, which makes it trivial to run them in the cloud. Legacy workloads, however, are not so lucky. They are often written with a lot of assumptions about the underlying infrastructure and are not cognizant of the resources they use. This means they are a poor fit to lift and shift to the cloud, as they will often be expensive and inefficient.  With a hybrid platform, we can use our on-premise offering as a spring board for modernization. Product teams will start by shifting their app to our on-premise Kubernetes platform, and then gradually modernize it to be cloud native. This method gives a few immediate benefits from the lift and shift like better observability, developer experience and security features but also gives fewer of the drawbacks, as the on-premise cloud is closer to the existing dependencies than a public cloud. Once this is done, smaller chunks kan be rewritten as microservices and moved to the cloud, communicating with the monolith seamlessly over the hybrid network. This is sometimes referred to as the strangler application.  This method significantly reduces the scope of refactoring, as one can focus on gradually rewriting smaller modules instead of rewriting the entire application.  ","version":null,"tagName":"h2"},{"title":"Service mesh is hard, but maybe a necessary evil to make hybrid less painfulâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#service-mesh-is-hard-but-maybe-a-necessary-evil-to-make-hybrid-less-painful","content":"   Oh my word how we have struggled with service mesh.  Starting from nothing with a goal of providing a secure-by-default zero-trust network layer with observability and traffic control is quite an undertaking, especially when you pair that with setting up a new kubernetes-based infrastructure from scratch. Istio is famously complex, and we've had our fair share of that.  So how do we feel about Istio? There are various opinions in the team, but if we average them all out, we're content. It's quite complex and can be hard to debug, but it does the job. As we've matured and gotten more experience with Istio, we've also started to see more benefits, like extensions for handling OAuth2and the traffic control features for gradual rollouts which we used for canary-testing the migration of some of our larger applications to SKIP. Not all of these features, like EnvoyFilters, are supported by Anthos Service Mesh (ASM), which is why we're exploring using upstream Istio instead of ASM.  One thing we quickly learned is to not let the product teams configure the service mesh directly using service mesh resources. This is a recipe for disaster. We tried this in the beginning, and first of all it's a huge complexity burden for the product teams. We also started getting a lot of weird issues when product teams would configure the mesh in ways that broke their encapsulation. Since the service mesh is a cluster-wide feature, if one team makes an invalid configuration, it can break other teams' workloads. Kubernetes namespaces be damned. We've therefore moved to a model where the platform team provides an abstraction throughSkiperator which configures the service mesh on their behalf.  Finally, I think it's prudent to ask yourself wether or not you actually need a service mesh. If you're running a small cluster with a few services, you'll probably be fine with using the built-in Kubernetes features like Ingress and Network Policies. The observability features are nice, but you can get most of them with a combination of instrumentation and Grafana.  If you need service mesh then limit the scope until you get comfortable with the mesh, for example start with just mTLS and observability, and then add zero trust networking features later.  Also keep in mind there is a lot of competition in the service mesh space, and there are some interesting alternatives to Istio, likeLinkerd and the up-and-coming Cilium Service Mesh.  ","version":null,"tagName":"h2"},{"title":"Anthos helps you as a platform team getting started with best practices.. Even if you plan to move to open source components laterâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#anthos-helps-you-as-a-platform-team-getting-started-with-best-practices-even-if-you-plan-to-move-to-open-source-components-later","content":"   When our platform team started out a few years ago, we picked some of the brightest cloud engineers from within the organization and combined them with some consultants to work on the platform. Most of these engineers had some experience working with Kubernetes and cloud, but not building something of this scale from scratch. The first months would therefore be a learning experience for most of the team.  I think a lot of teams will be in a similar situation, and this is where a managed service like Anthos can be a huge help. Anthos is built with best practices in mind, so a lot of the architecture decisions were built-in to the installer. Choosing a managed offering, even when running on-prem has therefore helped us deliver value to the product teams much quicker than if we had to build everything from scratch.  What's important to point out is that choosing something that is managed does not rule out using open source components later. We started out using all the parts that Anthos gave us, including service mesh, logging, monitoring and configuration management. Managed services do come with some tradeoffs, however, as you lose some of the finer control of the platform. As the team has matured and gained experience, we've started to replace some of these components with open source alternatives, which has helped us save money and gain more control over our platform. This has the downside of having to maintain these components ourselves, but with more experience in the team, this is a tradeoff we feel is worth it.  Even though we're increasingly using more open source components, we don't regret using a paid managed offering in the beginning. It helped us get started and make the right decisions early on, and we're now in a position where we can capitalize on that great start.  ","version":null,"tagName":"h2"},{"title":"Keep in mind autoscaling when choosing licensing modelsâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#keep-in-mind-autoscaling-when-choosing-licensing-models","content":"   This may be an obvious point to some of the more experienced platform engineers out there, but it was still something that we had to learn. When we started out, we appreciated the simplicity of SaaS products that billed per node, as it made it easy to predict costs. We could simply look at the number of nodes we had running and multiply that with the price per node to get a relatively accurate estimate of what this offering would cost. This would turn out to be a double edged sword, however.  It is safe to assume that one of the reasons people choose Kubernetes is the ability to scale workloads easily. This could be scaling up to handle more traffic, or scaling down to save money. This is a great feature, but as the number of workloads grow, the provisioned nodes will start to become insufficient and new nodes will be provisioned. With Kubernetes and Anthos on VMware this can be done automatically, which is a fantastic feature.  The problem arises when you scale out more nodes and have a static license that bills per node. We've made the mistake of getting contracts with two (now just one) SaaS providers where we order a set of nodes, let's say 10, and when workloads scale up, we end up with more than 10 nodes. This means we're not running that SaaS-service's agents on the new nodes, which can be anything from inconvenient to critical, depending on the service. In the end we've had to restrict our node scaling to avoid this issue, which goes against the whole ethos of Kubernetes. We're also provisioning bigger nodes than we need to avoid scaling out, which can be suboptimal.  We're now working with the vendors to get a more flexible license that bills per node on demand, but this is something to keep in mind when choosing a SaaS offering. Try to factor in the future scaling needs of your platform when purchasing SaaS services.  ","version":null,"tagName":"h2"},{"title":"Summaryâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 3","url":"/blog/hybrid-kubernetes-in-production-part-3#summary","content":" To summarize: We've learned a lot on our journey to building a hybrid Kubernetes platform. Over the last few years we've iterated on our platform and learned lots of great lessons. It's been a huge help and privilege to have the support of our organization, especially in terms of us being allowed to fail and learn from our mistakes. The Norwegian saying &quot;it's never too late to turn around&quot; comes to mind, as we've changed course several times on our journey, sometimes to the annoyance of our product teams who depend on a stable platform - but in the end we've ended up with a better product - a platform we can be proud of and that our product teams love using.  Thanks for reading this series on Anthos and hybrid Kubernetes. We hope you've learned something from our experiences, and that our hard earned lessons can help you on your journey to building a hybrid Kubernetes platform.  Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not endorsed by or affiliated with Google in any way. ","version":null,"tagName":"h2"},{"title":"Hybrid Kubernetes in production pt. 2","type":0,"sectionRef":"#","url":"/blog/hybrid-kubernetes-in-production-part-2","content":"","keywords":"","version":null},{"title":"Installation and upgradesâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#installation-and-upgrades","content":"   We have been early adopters of Anthos, so when doing the install we did not have options for controlplane architecture. We wanted to use existing underlying VMware infrastructure, so the nodes in our clusters are VMs, provisioned by scripts provided by Google. Our cluster is installed withkubeceptioncontrolplane architechture, this no longer the only, or recommended way. The recommended model is Controlplane V2, where the controlplane nodes for the user cluster are in the user cluster itself.  In the kubeception model, Kubernetes clusters are nested inside other Kubernetes clusters. Specifically, the control plane of the user clusters runs in an admin-cluster. For each on-premise cluster created, a new set of nodes and a namespace are created in the admin cluster.  To install and make changes to the admin cluster, an admin workstation is required, which must be located in the same network as the admin cluster. All configurations are done using a CLI tool called gkectl. This tool handles most cluster administration tasks, and the cluster specific configuration is provided in YAML files.  Our cluster setup is more or less static, and most cluster administration tasks involve upgrading or scaling existing clusters. The SKIP team has a cluster referred to as â€œsandboxâ€, which is always the first recipient of potentially breaking changes. After testing in sandbox, we'll deploy changes to both development and test environments, and if nothing breaks, we roll out the changes to our production environment. This is mostly done outside work-hours, although we have not experienced downtime during cluster upgrades. Here is the general workflow for upgrading:  Upgrade your admin workstation to the target version of your upgrade.From your admin workstation, upgrade your user clusters.After all of the user clusters have been upgraded, you can upgrade your admin cluster from the admin workstation.  We have tried using Terraform where possible to simplify the setup. This can not be done in the same way for clusters using the kubeception model. When we migrate to Controlplane V2 however, clusters can be managed via GCP, and we can finally start using terraform for our on-premise cluster config in the same way as for our GKE clusters, and GCP configuration in general.  ","version":null,"tagName":"h2"},{"title":"GCP integrationâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#gcp-integration","content":" When working with an on-premise Anthos cluster, some of the nice-to-have features of a standard GKE cluster have been lost. However, recently Anthos on VMware clusters have gradually received more and more features compared to GKE clusters.  ","version":null,"tagName":"h2"},{"title":"IAM and Groupsâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#iam-and-groups","content":" Since we were early adaptors of Anthos, we had to endure not being able to delegate clusterroles to IAM groups, and had to add single users to clusterrole/rolebindings in Kubernetes. This was not a huge problem for us, since we were working with a very limited number of teams and devs, but it was apparent that this was not going to scale well. Luckily we got support for groups before it was a problem, and our config files went from containing way too many names and email addresses, to only containing groups.  Our Google Workspace receives groups and users from our Microsoft Active Directory. Groups are initially created either in Entra ID, or on our local Domain Controllers, and at set intervals changes are pushed to Google Workspace.Role-based access control (RBAC) based on membership in these groups was needed. We wanted to manage this through Terraform, and created a repo with where we store and configure our entire IAM configuration. Since we have had growing adoption of Kubernetes and public cloud in our organization, more teams, projects and apps have been onboarded to SKIP, and this IAM repo has grown. We've tried to simplify the structure more than once, but since this is a problem not affecting dev teams, we have chosen to prioritize other tasks.  ","version":null,"tagName":"h3"},{"title":"Workloadsâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#workloads","content":" All clusters created in in Anthos can be viewed from the GCP console, and theConnect gatewaymakes it possible to do management from the console (or via kubectl) as well. The GCP console can be used to get information about, or manage the state of the cluster, workloads and resources present. This is a web GUI, part of the GCP console, and not as snappy as cli-tools, but still usable, and intuitive to use.  This view shows workloads running in the argocd namespace. All workloads displayed here can be clicked, and explored further.  When accessing the cluster via the Connect gateway there are some limits. The Connect gateway does not handle persistent connections, and this makes it impossible to do exec, port-forward, proxy or attach. This is not a problem for a production environment, where containers should never be used in this way. But for a dev, or sandbox environment, this is a bit of a pain-point.  This issue should be partially fixed in Kubernetes 1.29 and should be completely resolved in Kubernetes 1.30.  ","version":null,"tagName":"h3"},{"title":"Service Meshâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#service-mesh","content":" A Service Mesh in Kubernetes is an infrastructure layer that manages communication between services. We are using Anthos Service Mesh (ASM), which is based on Istio and nicely integrated with the GCP console. It's easy to get an overview of services, the connection between them, and what services are connected to either our internal or external gateways. This can be displayed in a Topology view, or if you click on a service, you'll get a more detailed drilldown.  A snippet of services running in our sandbox cluster.  When we deploy services to our cluster we create almost all Kubernetes and service-mesh resources with our custom operator;Skiperator. This operator configures the resources to fit our setup, and applies &quot;best practices&quot; the easy way. This has been one of the great success stories in SKIP, and Skiperator is in continuous development.  ","version":null,"tagName":"h3"},{"title":"Deploymentâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#deployment","content":" Deployment is a very interesting subject when it comes to Anthos. As a platform team, it is our job to make sure that deployment is as quick and convenient as possible for the product teams. This ambition has led us to iterate on our processes, which has finally led us to a solution that both we and the developers enjoy using.  ","version":null,"tagName":"h2"},{"title":"Iteration 1 - Terraformâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#iteration-1---terraform","content":" When we first started out with Anthos, we had a very manual process for deploying applications. A service account was provisioned in GCP, which allowed the developers to impersonate a service account in Kubernetes, which in turn allowed them to deploy apps using Terraform. This approach worked, but had a decent amount of rough edges, and also would fail in ways that was hard to debug.  With this approach the developers would have to manage their own Terraform files, which most of the time was not within their area of expertise. And while SKIP was able to build modules and tools to make this easier, it was still a complex system that was hard to understand. Observability and discoverability was also an issue.  Because of this we would consistently get feedback that this way of deploying was too complicated and slow, in addition handling Terraform state was a pain. As a platform team we're committed to our teams' well being, so we took this seriously and looked at alternatives. This was around the time we adopted Anthos, so thus Anthos Config Managment was a natural choice.  ","version":null,"tagName":"h3"},{"title":"Iteration 2 - Anthos Config Managment (ACM)â€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#iteration-2---anthos-config-managment-acm","content":"   ACM is a set of tools that allows you to declaratively manage your Kubernetes resources. Here we're mostly going to talk about Config Sync, which is aGitOps system for Kubernetes.  In a GitOps system, a team will have a Git repository that contains all the Kubernetes resources that they want to deploy. This repository is then synced to the Kubernetes cluster, and the resources are applied.  This can be likened to a pull-based system, where the GitOps tool (Config sync) watches the repo for changes and pulls them into the cluster. This is in contrast to a push-based system, where a script pushes the changes to a cluster. It is therefore a dedicated system for deployment to Kubernetes, and following the UNIX philosophywhich focuses on doing that one thing well.  Using this type of a workflow solves a lot of the issues around the Terraform based deployment that we had in the previous iteration. No longer do developers need to set up a complicated integration with GCP service accounts and impersonation, committing a file to a Git repo will trigger a deployment. The Git repo and the manifests in them also works as a state of truth for the cluster, instead of having to reverse engineer what was deployed based on terraform diffs and state.    It started well, however we soon ran into issues. The system would often take a long time to reconcile the sync, and during the sync we would not have any visibility into what was happening. This was not a deal breaker, but at the same time this was not a particularly good developer experience.  We also ran into issues with implementing a level of self-service that we were satisfied with. We wanted to give the developers the ability to provision their own namespaces, but due to the multi-tenant nature of our clusters we also had to make sure that teams were not able to write to each others' namespaces. This was not a feature we were able to implement, but luckily our next iteration had this built in, and we'll get back to that.  The final nail was the user interface. We simply expected more from a deployment system than what ACM was able to provide. The only view into the deployment was a long list of resources, which to a developer that is not an expert in Kubernetes, was not intuitive enough.  ","version":null,"tagName":"h3"},{"title":"Final iteration - Argo CDâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#final-iteration---argo-cd","content":"   This finally brought us to our current iteration. We had heard about Argo CD before, but initially we were hesitant to add another system to our stack. After ACM had introduced us to GitOps and we looked deeper into Argo CD, it was obvious to us that Argo was more mature and would give our developers a better user experience.  The killer feature here is the UI. Argo CD has an intuitive and user-friendly UI that gives the developers a good overview of what is deployed. Whenever anything fails, it's immediately obvious which resource is failing, and Argo allows you to drill down into the resource to see the details of the failure, logs for deployments, Kubernetes events, etc.    The above photo illustrates this well. Here you can see a project with a number of Skiperator applications. The green checkmarks indicate that the application is synced and the green heart indicates that the application is healthy. A developer can see the underlying &quot;owned&quot; resources that Skiperator creates (such as a deployment, service, etc), and get a look &quot;behind the curtain&quot; to see what is actually deployed. This helps debugging and gives the developers a better insight into what is happening during a deployment.  In terms of multi tenancy, Argo CD has a concept of projects. A project is a set of namespaces that a team has access to, and a team can only use Argo to sync to namespaces that are part of their project. The namespace allowlist can also include wildcards, which sounds small but this solved our self-service issue! With our apps-repo architecture, we would give a team a &quot;prefix&quot; (for example seeiendom-), and that team would then be able to deploy to and create any namespace that started with that prefix. If they tried to deploy to another team's namespace they would be stopped, as they would not have access to that prefix.  The prefix feature allows product teams to create a new directory in their apps repo, which will then be synced to the cluster and deployed as a new namespace. This is a very simple and intuitive workflow for creating short-lived deployments, for example for pull requests, and it has been very well received by the developers.  The apps-repo architecture will be a blog post itself at some point, so I won't go too much into it.  And finally, if you're wondering what disaster recovery of an entire cluster looks like with Argo CD, I leave you with the following video at the end.    ","version":null,"tagName":"h3"},{"title":"Hybrid Meshâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#hybrid-mesh","content":" A hybrid mesh service mesh configuration is a setup that allows for service networking across different environments. For Kartverket this includes a hybrid cloud environment. The setup involves several steps, including setting up cross-cluster credentials, installing the east-west gateway, enabling endpoint discovery, and configuring certificate authorities. All clusters in a hybrid mesh are registered to the same fleet host project, and istiod in each cluster must be able to communicate with the Kube-API on the opposing clusters.  ASM is as previously mentioned based on Istio, and after some internal discussion we decided to experiment with running vanilla upstream Istio in our GKE clusters running in GCP. Pairing it with ASM in our on-premise clusters worked as expected (after a bit of config), and we are now running upstream Istio in GKE, with ASM on-prem in a multi-cluster setup. We also looked into using managed ASM in our GKE cluster, this was hard for us however, due to it requiring firewall openings on-prem for sources we could not predict.    We have chosen the Multi-Primary on different networksafter reviewing our network topology and configuration. We connect our on-premise network, with the GCP VPC through a VPN connection (using host and service projects). To have a production ready environment, the VPN connection must be configured with redundancy.  We're working towards getting this architecture into production, as this will enable us to seamlessly use GKE clusters in GCP together with our on-premise clusters. The elasticity of cloud infrastructure can be utilized where needed, and we can handle communication between services on different clusters much more smoothly. This has been a bit of a journey to configure, but as a learning experience it has been valuable. Being able to address services seamlessly and communicate with mTLS enabled by default across sites, zones and clusters without developers having to think about it feels a bit like magic.  ","version":null,"tagName":"h2"},{"title":"Monitoringâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#monitoring","content":" ","version":null,"tagName":"h2"},{"title":"Google Cloud Monitoringâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#google-cloud-monitoring","content":"   GKE Enterprise includes an agent that collects metrics from the cluster and sends them to Google Cloud. This is a great feature which makes it relatively easy to get started with metrics and monitoring. However, we have decided not to use the agent, and instead use Grafana and LGTM for metrics and monitoring.  This is mainly due to a couple of challenges:  The amount of metrics that are collected out of the box and sent to GCP contributes a significant part of our total spend. It's not that we have a lot of clusters, but the amount of metrics that are collected out of the box is very high, and Anthos' default setup didn't give us the control we needed to be able to manage it in a good way.  Note that this was before Managed Service for Prometheus was released with more fine grained control over what metrics are collected. It is now the recommended default, which should make metrics collection easier to manage.  Second, while Google Cloud Monitoring has a few nice dashboards ready for Anthos, it feels inconsistent which dashboards work on-premise and which only work in cloud as they are not labeled as such. This is not a big issue, but it's a bit annoying. The bigger issue is that all the dashboards feel sluggish and slow to load. Several of us have used Grafana before, so we're used to a snappy and responsive UI. In our opinion, Google Cloud Monitoring feels clunky in comparison.  So the cost and the user experience were the main reasons we decided to look at alternatives to Google Cloud Monitoring. We ended up using Grafana and LGTM, which we'll talk about next.  ","version":null,"tagName":"h3"},{"title":"Grafana with the LGTM stackâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#grafana-with-the-lgtm-stack","content":"   When we realized that our needs were not entirely met by Google Cloud Monitoring, we started a project to develop a monitoring stack that would meet our needs. Since Grafana is open source and has a large community, we decided to use that as our frontend. Our backend is the LGTM stack, which is a set of open source tools that are designed to work well together for ingesting, storing and querying logs, traces and metrics.  What we noticed immediately was that the product teams were much more engaged with this stack than they were with Google Cloud Monitoring. Previously they would not really look at the dashboards, but now they are using them and even creating their own. This is a huge win for us, as we want the teams to be engaged with the monitoring and observability of their services.  It definitely helps that most developers on the product teams are familiar with Grafana, which makes it easier for them to get started as the learning curve is not as steep.  There was a discussion about what the backend should be, if we should useGrafana Cloud or host it ourselves. There would be a lot of benefits of using the cloud, as we would not have to maintain the stack or worry about performance or storage. There was, however, a concern about cost and whether or not log files could be shipped to a cloud provider. In the end we decided to host it ourselves, mostly because we didn't have control over what quantities of data we're processing. Now that we have a better understanding of our usage we can use that to calculate our spend, so we're not ruling out migrating to Grafana Cloud in the future.  The collection (scraping) of data is done by Grafana Agent, which is an &quot;all-in-one&quot; agent that collects metrics, logs and traces. This means a few less moving parts for the stack, as we don't have to run both Prometheus,Fluent Bit and someOpenTelemetry compatible agent for traces. It's a relatively new project, but it's already relative stable and has a lot of features. It uses a funky format for configuration called river, which is based on Hashicorp's HCL. The config enables forming pipelines to process data before it's forwarded to Loki, Tempo or Mimir. It's a bit different, but it works well and is easy to understand and configure to our needs.    Using a system like Grafana also enables us to build an integrated experience that also includes alerting. Using Grafana alerting and OnCall, we configure alerts that are sent to the correct team based on the service that is failing. This helps the teams get a better overview of what is happening in their services, and also helps us as a platform team to not have to be involved in every alert that is triggered.  Overall we're very happy with the LGTM stack, even though it's a fair bit of work to maintain the stack (especially with Istio and other security measures). We're also happy with Grafana, and we're looking forward to seeing what the future holds for monitoring and observability in Kubernetes.  ","version":null,"tagName":"h3"},{"title":"Summaryâ€‹","type":1,"pageTitle":"Hybrid Kubernetes in production pt. 2","url":"/blog/hybrid-kubernetes-in-production-part-2#summary","content":" To summarize: We like Anthos, and we think it's a great platform for running hybrid Kubernetes. As a platform team we look at each feature on a case-by-case basis, with the goal of giving our developers the best possible experience instead of naively trying to use as much as possible of the platform. Because of this we've decided to use Anthos for Kubernetes and service mesh, but not for config sync and monitoring. This has given us a great platform that we're confident will serve us well for years to come.  Stay tuned for the third and final part of this series, where we'll talk about the benefits we've seen from Anthos, and what we would have done differently if we were to start over.  Disclaimer - Google, GKE and Anthos are trademarks of Google LLC and this website is not endorsed by or affiliated with Google in any way. ","version":null,"tagName":"h2"},{"title":"SKIP on Plattformpodden!","type":0,"sectionRef":"#","url":"/blog/skip-on-plattformpodden","content":"Very recently, SKIP was featured on thePlattformpodden podcast! Vegar and Eline were invited to talk about SKIP, how it came to be and what it's like to work on it. Give it a listen! https://plattformpodden.no/episode/6","keywords":"","version":null},{"title":"Scaling with Argo CD: Introducing the Apps Repo Architecture","type":0,"sectionRef":"#","url":"/blog/introducing-apps-repositories","content":"","keywords":"","version":null},{"title":"Multi-tenancy in Argo CDâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#multi-tenancy-in-argo-cd","content":" So you've deployed Argo CD on your multi-tenant cluster and given your teams access to the user interface. Let's imagine we now have tens of teams and hundreds of applications in the Argo UI. When we start scaling out to more than a handful of users we get into some issues with scale. Examples of these issues can be:  How do you organize your apps and projects?How do you make sure no two teams accidentally (or maliciously) use the same namespace?How can we make sure teams clean up unused deployment resources?How do you seamlessly deploy to multiple clusters?  As a platform team we often find ourselves thinking that everyone loves infrastructure and Kubernetes as much as we do. This is not the case! Most people have not had the joy of having their childhood ruined by installing Linux on their school laptops and configuring WLAN drivers using ndiswrapper. Believe it or not, most people just want tools to get out of their way and let them do their job, be that programming, testing or anything else. Not every team is going to be experts in Kubernetes and Argo. So should we expect all teams to know what a deletion finalizer is? What about the intricacies of serverside apply vs. clientside apply?  It's our responsibility as a platform team to make the user experience of deploying to Kubernetes as user friendly as possible. After implementing an architecture built with UX in mind we've had the joy of seeing people who are extremely skeptical of Kubernetes and the cloud be won over by how easy it is to get your workloads running on Kubernetes. This is thanks to the consistent user experience and built-in best practices of the apps-repo architecture. But we're getting ahead of ourselves, first we need to talk about a few abstractions that make this possible.  ","version":null,"tagName":"h2"},{"title":"What are ApplicationSets?â€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#what-are-applicationsets","content":" In Argo CD there's an advanced feature that allows for automating creation of Argo CD Applications calledApplicationSets. Using an ApplicationSet we can essentially make a template that generates Argo CD applications based on files or folders in a Git repository, sort of like a ReplicaSet for Pods. Using ApplicationSets we can build in features and assumptions and provide the teams with a user experience that essentially boils down to &quot;add a file to a repo and it gets deployed to the cluster&quot;. The purest form of GitOps. No messing around with Argo CD applications and projects.  A core Argo CD component called the ApplicationSet controller will detect anyApplicationSet resources deployed to the cluster and read them. After this, it will periodically scan the a repo configured in the ApplicationSet resource and generate Application resources, which in turn scan a repo for manifest files and sync them to the cluster. So in other words: ApplicationSet -&gt;Application -&gt; Deployments  For this to work you need a Git repo containing manifest files. You could have the teams put these manifest files into their source code repositories, but this is not considered best practice. Usually you would put your manifests into a separate repo so that changes to the manifests don't conflict with changes in the source code. At Kartverket we call this manifest repo an apps repo.  ","version":null,"tagName":"h2"},{"title":"Introducing apps repositoriesâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#introducing-apps-repositories","content":"   The apps repo is where the product teams put their manifests. It has a consistent structure and is designed to be read by an Argo CD ApplicationSet. It also has a lot of nifty features that enable self-service which we'll get back to.  First, let's have a look at the structure of an apps repo.  teamname-apps/ env/ clustername/ namespace/ example.yaml   In the simplest of terms, this tree describes where to deploy a given manifest. By using a directory tree it makes setting up an ApplicationSet for this repo trivial.  Consider this example ApplicationSet:  apiVersion: argoproj.io/v1alpha1 kind: ApplicationSet metadata: name: exampleteam-apps namespace: argocd spec: generators: - git: directories: - path: env/*/* repoURL: 'https://github.com/kartverket/exampleteam-apps.git' revision: HEAD goTemplate: true goTemplateOptions: - missingkey=error template: metadata: name: '{{.path.basename}}' spec: destination: namespace: '{{ index .path.segments 2 }}' name: '{{ index .path.segments 1 }}' project: exampleteam source: path: '{{.path.path}}' repoURL: 'https://github.com/kartverket/exampleteam-apps.git' targetRevision: HEAD syncPolicy: syncOptions: - CreateNamespace=true automated: prune: true allowEmpty: true selfHeal: true   With this ApplicationSet any directory within env/*/* will be picked up by the ApplicationSet controller and a new Argo CD Application will be created based on the template in the template object. This enables a product team to create any number of applications for their products.    An example use for this is a product team wanting a namespace for each of their products. Instead of having to order a new namespace from the platform team when they create a new product, they can simply create it themselves by adding a new directory with the same name as the namespace they want. A new Kubernetes namespace will be automatically created thanks to theCreateNamespace=true sync option.  Ephemeral namespaces, aka. preview namespaces, is another usecase. Say a team wants to review a change before merging it to main. They could review the change in the Pull Request, but this removes us from the end user's perspective and is not suitable for non-technical people. With a preview environment the team will automatically create a new directory in the apps repo when a PR is created, and thus get a complete deployment with the change in question. This enables end-to-end testing in a browser, and also allows non-technical people to do QA before a change is merged. When it is merged another workflow can automatically delete the directory, which cleans up and deletes the preview environment.  Our convention is that namespaces are formatted with productname-branch. This allows teams to have multiple deploys per product, and also multiple products per team. So when a new PR is created all a team needs to do to automate the creation of a new directory using CI tools like GitHub actions to create a new commit in the apps-repo. This also enables the flexibility to create it as a PR in the apps-repo, but for ephemeral namespaces, this is usually not necessary.  For example:  footeam-apps/ env/ foo-cluster/ foo-main/ app.yaml foo-feature-123/ app.yaml   ","version":null,"tagName":"h2"},{"title":"Automating and avoiding duplicationâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#automating-and-avoiding-duplication","content":" Depending on the complexity of the apps repo, the amount of products and branches and a subjective &quot;ickyness&quot; with duplicating files (can you spell DRY?), you have several options on how to automate creating new namespaces.  Simple repos will probably be fine with directories containing simple yaml-files that are synced to the cluster. Newer product teams especially appreciate the simplicity of this approach. To optimize for this you may consider using atemplate directory at the base containing some example files that are copied into the sub-directories. A pseudo-coded GitHub action that uses afrontend.yaml template from the templates directory could look like the following:  jobs: build: # Build a container image and push it deploy: strategy: matrix: env: ['dev', 'test', 'prod'] steps: # .. Checkout repo &amp; other setup .. - name: Deploy to ${{ matrix.version }} run: | namespace=&quot;myapp-${{ github.ref_name }}&quot; path=&quot;./env/atkv3-${{ matrix.env }}/$namespace&quot; mkdir -p $path cp -r templates/frontend.yaml $path/frontend.yaml kubectl patch --local \\ -f $path/frontend.yaml \\ -p '{&quot;spec&quot;:{&quot;image&quot;:&quot;${{needs.build.outputs.container_image_tag}}&quot;}}' \\ -o yaml git config --global user.email &quot;github-actions@github.com&quot; git config --global user.name &quot;GitHub Actions&quot; git commit -am &quot;Deploy ${{ matrix.env }} version ${{ github.ref_name }}&quot; git push   This works for most simple apps. Our experience, however, is that as a team matures and gets more experienced with Kubernetes and Argo CD, they add more complexity and want more control. At this point most teams will migrate to usingjsonnet to enable referencing and extending a reusable library shared between multiple components. SKIP also provides some common manifests via ArgoKit, a jsonnet library.  Kustomize is also a common choice, widely used by SKIP for our own infrastructure, but not really widespread with other teams.  Despite Argo supporting Helm we mostly avoid using it to create reusable templates due to the complexity of templating YAML. Jsonnet is superior in this regard.  Fixing indentation errors in YAML templates in a Helm chart pic.twitter.com/Dv2JUkCdiM â€” memenetes (@memenetes) December 8, 2022  ","version":null,"tagName":"h2"},{"title":"Security considerationsâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#security-considerations","content":" You may be wondering: &quot;This seems great and all, but what about the security implications of allowing teams to create and edit namespaces in a multi-tenant cluster? That seems really dangerous!&quot;.  First of all, I love you for thinking about security. We need more people like you. Second, Argo CD has some great features we can leverage to make this work without removing the self-service nature of the apps repo architecture.  ","version":null,"tagName":"h2"},{"title":"Prefixesâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#prefixes","content":" In order to make this work we need to give each team a set of prefixes. A prefix will usually be the name of a product that a product team has responsibility for maintaining. The only important part is that it is unique and that no other teams have been allocated the same prefix. At Kartverket this is done by the platform team as part of the team onboarding process.  The prefix is used as part of all namespaces that are created by the teams. In the example namespace product-feature-123, product is the prefix. By giving each team a set of prefixes it helps them separate products into easily identifiable namespaces and it ensures that a product team does not accidentally use another team's namespace.  Since each product team has an apps repo with the ability to name their directories as they wish, how can we enforce this? This is where Argo CD's Projects come into play.  Argo CD Projectsprovide a logical grouping of applications, which is useful when Argo CD is used by multiple teams. It also contains a field that allows allowlisting which clusters and namespaces are usable by a project.  Add the following to a Project to only allow this project to create and sync to namespaces prefixed with myprefix-.  metadata: name: exampleteam spec: destinations: - namespace: 'myprefix-*' server: '*'   If you scroll back up to the ApplicationSet example above, you will see that it only creates applications with the project exampleteam. This will automatically wire any applications created to the destination rules we've defined in this project and therefore deny any attempts by a team to use prefixes that they have not been allocated.  The crucial part here is that ApplicationSets and Projects are provisioned by the platform team, and therefore build in these security features. These resources must not be accessible to the teams, or an attacker can simply add exclusions.  ","version":null,"tagName":"h3"},{"title":"Namespace resourcesâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#namespace-resources","content":" Another way this could be abused is if a team is able to create Namespace resources in their apps repository. This should be denied using Argo and/or cluster policies.  If a team is able to create namespace resources (or other cluster scoped resources) in their namespace an attacker can use this to break their namespace &quot;encapsulation&quot;. Imagine for example if one could use their apps repo to sync a namespace resource named kube-system into their env/foo-cluster/foo-maindirectory. Argo CD would allow this, as the manifests are read into an Argo CD application. Then the attacker could delete the namespace and take down the cluster.    It's useful in this multi-tenancy scenario to think of namespaces as resources owned by the platform team and namespace-scoped resources as owned by the product teams. This is considered a best practice, and was reiterated at KubeCon Europe 2024 by Marco De Benedictis. Allowing product teams to edit namespaces can open up a ton of attack vectors, like disabling Pod Security Admissioncontrollers, allowing an attacker to create privileged containers which can compromise the host node.  Friends don't let friends edit namespaces!  ","version":null,"tagName":"h3"},{"title":"Self service customizationâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#self-service-customization","content":" So we set up an ApplicationSet that configures best practices and secure defaults for product teams! Great! But now that team with experienced cloud engineers really wants to customize their Argo configuration. Maybe they want to configure that one app has auto sync on, but another app has it turned off. Maybe they want to disable self-healing for a short period to manually edit in the cluster. In any case, how can we let teams change this configuration self-service when applications are provisioned by theApplicationSet resource?  We could let the teams edit the ApplicationSet. In our case this would mean the teams need to learn about the ApplicationSet abstraction, gotemplate and SKIP's internal GitOps repo structure. This is overkill when a team usually just wants to flip a flag between true or false for a directory. There could also be security implications with allowing teams to edit ApplicationSet resources that could break encapsulation, which we want to avoid.  Another option would be to contact the platform team and tell us to change some config for them. This is not in line with our thinking, as we want the teams to be able to work autonomously for most operations like this. It would also mean we were given a lot of menial tasks which would mean we have less time to do other more meaningful things or become a bottleneck for the teams.  A third option is setting the ApplicationSet sync policy to create-only. This would confifure the ApplicationSet controller to create Application resources, but prevent any further modification, such as deletion, or modification of Application fields. This would allow a team to edit the application in the UI after creation, for example disabling auto sync. This last option is user friendly, but in violation of GitOps principles where config lives in git and not in a database. If you run Argo stateless like we do this would also mean the changes disappear when the pod restarts.  Because none of these options seemed to be the best, we created a better solution. By using a combination of generators and the new template patchfeature in Argo CD 2.8 we can look through every directory in the apps repo for a configuration file called config.json.  Let's look at an example config.json file. This example file is commited in the apps repo to the env/foo-cluster/foo-main directory.  { &quot;tool&quot;: &quot;kustomize&quot;, &quot;autoSync&quot;: false }   This file is not required, but if this file is found the values configured there overrides a set of default values in the ApplicationSet template. These flags are then used to determine how the resulting Application will behave. This means the team is able to change the values they care about per directory of their apps repo  footeam-apps/ env/ foo-cluster/ foo-main/ config.json app.yaml foo-feature-123/ config.json app.yaml foo-feature-with-default-config/ app.yaml   Additionaly, since the platform team is in control of the template we can eliminate the ability to maliciously change the template by parsing the inputs in a secure way.  ","version":null,"tagName":"h2"},{"title":"Example ApplicationSetâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#example-applicationset","content":" Let's look at how we can write an ApplicationSet that allows us to useconfig.json files.  First, we need to configure the ApplicationSet to look through all directories, and at the same time use a config.json file if it is found. This is perhaps the least intuitive part of this new ApplicationSet, so let's walk through it step by step.  First we create a merge generator, which will merge two generators. The key thing here is that it only merges if the key matches in both generators, so this allows us to first find all directories (the default), then directories that contain config.json files (the override).   generators: - merge: generators: - # default - # override mergeKeys: - key   Now we're going to add the generator from before into the default. The only difference is we're doing this using a matrix generator. Doing this combines the parameters generated by the two child generators, which gives us the values from the git generator like before, but also a set of default values we can use in our template later if the config.json file is not provided.  We're also using a value from the git generator to assign a key that will uniquely identify this directory for the merge generator later.   generators: - merge: generators: - matrix: generators: - git: directories: - path: env/*/* repoURL: 'https://github.com/kartverket/exampleteam-apps.git' revision: HEAD - list: elements: - allowEmpty: false autoSync: true key: '{{ .path.basenameNormalized}}' prune: true selfHeal: true tool: directory - # override mergeKeys: - key   Now we use a variant of the git generator to find all config.json files in the same repo and extract the values from it. Again we're using the key field to uniquely identify this directory so that it will be merged with the correct directory in the merge generator.  We're repeating the default values here as well, since not all fields are required and we don't want them to be overwritten as null in the resulting merge.   generators: - merge: generators: - matrix: generators: - git: directories: - path: env/*/* repoURL: 'https://github.com/kartverket/exampleteam-apps.git' revision: HEAD - list: elements: - allowEmpty: false autoSync: true key: '{{ .path.basenameNormalized}}' prune: true selfHeal: true tool: directory - matrix: generators: - git: files: - path: env/*/*/config.json repoURL: 'https://github.com/kartverket/exampleteam-apps.git' revision: HEAD - list: elements: - allowEmpty: false autoSync: true key: '{{ .path.basenameNormalized}}' prune: true selfHeal: true tool: directory mergeKeys: - key   That's it for the generator! Now we can use these variables in thetemplatePatch field (and other fields). In this case we want to set syncPolicy options, so we need to use the templatePatch, as gotemplates don't work for objects.  We're also adding a special case where for directory sources (the default) we exclude config.json files, as we don't want to sync the config file with Argo. This allows us to extend it later to add options for other tools like Kustomize or Helm.  Keep in mind that we don't want users to inject maliciously formed patches, so we cast booleans to booleans.   templatePatch: | spec: source: directory: {{- if eq .tool &quot;directory&quot; }} exclude: config.json {{- end }} {{- if .autoSync }} syncPolicy: automated: allowEmpty: {{ .allowEmpty | toJson }} prune: {{ .prune | toJson }} selfHeal: {{ .selfHeal | toJson }} {{- end }}   ","version":null,"tagName":"h3"},{"title":"Complete ApplicationSetâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#complete-applicationset","content":" Here is a complete ApplicationSet containing all the features we've discussed so far.  apiVersion: argoproj.io/v1alpha1 kind: ApplicationSet metadata: name: exampleteam-apps namespace: argocd spec: generators: - merge: generators: - matrix: generators: - git: directories: - path: env/*/* repoURL: 'https://github.com/kartverket/exampleteam-apps.git' revision: HEAD - list: elements: - allowEmpty: false autoSync: true key: '{{ .path.basenameNormalized}}' prune: true selfHeal: true tool: directory - matrix: generators: - git: files: - path: env/*/*/config.json repoURL: https://github.com/kartverket/exampleteam-apps.git revision: HEAD - list: elements: - allowEmpty: false autoSync: true key: '{{ .path.basenameNormalized}}' prune: true selfHeal: true tool: directory mergeKeys: - key goTemplate: true goTemplateOptions: - missingkey=error template: metadata: name: '{{.path.basenameNormalized}}' spec: destination: namespace: '{{ index .path.segments 2 }}' name: '{{ index .path.segments 1 }}' project: exampleteam source: path: '{{.path.path}}' repoURL: 'https://github.com/kartverket/exampleteam-apps.git' targetRevision: HEAD syncPolicy: managedNamespaceMetadata: labels: app.kubernetes.io/managed-by: argocd pod-security.kubernetes.io/audit: restricted team: exampleteam syncOptions: - CreateNamespace=true - ServerSideApply=true - PrunePropagationPolicy=background templatePatch: | spec: source: directory: {{- if eq .tool &quot;directory&quot; }} exclude: config.json {{- end }} {{- if .autoSync }} syncPolicy: automated: allowEmpty: {{ .allowEmpty | toJson }} prune: {{ .prune | toJson }} selfHeal: {{ .selfHeal | toJson }} {{- end }}   ","version":null,"tagName":"h2"},{"title":"Resultsâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#results","content":" With Argo CD and the apps repo architecture, we've seen some real improvements in our deploy system. Teams find it to be incredibly intuitive to just update a file in Git and have it be instantly reflected in Argo CD and Kubernetes, especially when combined with Argo CD auto-sync.  Onboarding new teams is quick and easy, since just putting files into a Git repo is something most developers are already familiar with. We just show them the structure of the apps repo and they're good to go. A team can go from not having any experience with Kubernetes to deploying their first application in a matter of minutes.  Migrating from one cluster to another is also a breeze. Just move manifests from one directory under env to another, and the ApplicationSet will take care of the rest. This is especially useful for teams that want to start developing with new cloud native principles on-premises, modernizing the application and eventually moving to the cloud.  I feel the key part of this architecture is the config.json file. It allows a degree of customization that is not possible with the default ApplicationSettemplate and was to us the last missing piece. It allows teams to change configuration without needing to know about the ApplicationSet abstraction, and it allows the platform team to enforce security and best practices.  ","version":null,"tagName":"h2"},{"title":"Tradeoffsâ€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#tradeoffs","content":" But of course, there are some drawbacks. Like always, it's tradeoffs all the way down.  Since a product team uses an apps repo to organize their apps, moving apps from one team to another will require migrating files from one repo to another. This will require some manual work to prevent Argo deleting the entire namespace when the directory is removed from the old repo. Usually this is not a big issue, and moving projects between teams happens very rarely, but it's something to keep in mind.  There is also a risk that a team could accidentally delete a namespace by removing a directory in the apps repo. We have mitigated this by disabling auto-sync for most mission critical applications in production.  And finally, projects that don't have clear ownership or shared ownership can be tricky to place into a repo. You could make an apps repo for a &quot;pseudo-team&quot; consisting of the teams that need access, but generally we find that it's better that all products have a clear singular main owner. This also preventsdiffusion of responsibility.  ","version":null,"tagName":"h3"},{"title":"Thank you for reading!â€‹","type":1,"pageTitle":"Scaling with Argo CD: Introducing the Apps Repo Architecture","url":"/blog/introducing-apps-repositories#thank-you-for-reading","content":" We hope you found this article helpful and informative. Getting intoApplicationSets can be a bit tricky, so we hope we managed to convey the most important parts in a clear and understandable way. Thanks for reading!  We recently created a Mastodon account @kv_plattform! If you want to contact us or discuss this article, feel free to reach out to us there. ","version":null,"tagName":"h2"},{"title":"SKIP has a tech blog!","type":0,"sectionRef":"#","url":"/blog/welcome","content":"","keywords":"","version":null},{"title":"Like what you see?â€‹","type":1,"pageTitle":"SKIP has a tech blog!","url":"/blog/welcome#like-what-you-see","content":" We're a small team, but we're growing fast. We're also hiring, so if you're interested in working with us, check out our open positions. ","version":null,"tagName":"h2"},{"title":"Velkommen til SKIP! ðŸŽ‰","type":0,"sectionRef":"#","url":"/docs","content":"Velkommen til SKIP! ðŸŽ‰ SKIP stÃ¥r for Statens Kartverks Infrastrukturplattform. SKIP uttales som det norske ordet skip, et stÃ¸rre sjÃ¸gÃ¥ende fartÃ¸y. SKIP-teamet jobber med en utviklingsplattform hvor kjernekomponentene er Kubernetes, Google Cloud, Argo CD og GitHub. Hensikten er Ã¥ ha en helhetlig plattform for moderne utvikling hvor utviklere enkelt skal kunne lage, teste og kjÃ¸re containerbaserte applikasjoner basert pÃ¥ Cloud Native-prinsipper pÃ¥ en enkel og sikker mÃ¥te. I menyen til venstre kan navigere deg frem i dokumentasjonen om plattformen.","keywords":"","version":"Next"},{"title":"ðŸš€ Applikasjon & utrulling","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling","content":"ðŸš€ Applikasjon &amp; utrulling Her kan du lÃ¦re det du trenger om applikasjoner og utrulling.","keywords":"","version":"Next"},{"title":"ðŸš€ Argo CD","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd","content":"","keywords":"","version":"Next"},{"title":"Lenker til Argoâ€‹","type":1,"pageTitle":"ðŸš€ Argo CD","url":"/docs/applikasjon-utrulling/argo-cd#lenker-til-argo","content":" Du mÃ¥ vÃ¦re pÃ¥ Kartverkets nettverk eller VPN for Ã¥ kunne nÃ¥ disse lenkene.  Dev (argo-dev.kartverket.dev)Prod (argo-prod.kartverket.dev)  ","version":"Next","tagName":"h2"},{"title":"GitOpsâ€‹","type":1,"pageTitle":"ðŸš€ Argo CD","url":"/docs/applikasjon-utrulling/argo-cd#gitops","content":" Argo CD er et GitOps-verktÃ¸y, det vil si at kilden til sannhet ligger i git og synkes inn i clusteret derfra. GitOps er beskrevet i bildet over og er en â€œPull-basertâ€ deployment-flyt kontra den tradisjonelle â€œPush-baserteâ€ deployment-flyten. En operator kjÃ¸rer i clusteret og overvÃ¥ker kontinuerlig ett eller flere git-repoet og synker yaml-filer inn i clusteret. PÃ¥ den mÃ¥ten kan produktteam forholde seg til noe sÃ¥ enkelt som filer i en mappe i git, og nÃ¥r disse filene endres gjÃ¸res en deploy helt automatisk.  GitOps vil gi mange fordeler, men det blir et paradigmeskifte for mange. Istedenfor Ã¥ tenke â€œPushâ€-basert deploy ved Ã¥ kjÃ¸re et skript for Ã¥ deploye vil man legge inn Ã¸nsket state i en fil og sÃ¥ vil systemet jobbe for Ã¥ bringe clusteret i synk med Ã¸nsket state. Denne overgangen kan ogsÃ¥ sammenlignes litt med imperativ vs. deklarativ programmering, som jQuery vs. React. For de fleste som har jobbet med Kubernetes vil det fÃ¸les veldig kjent, siden Kubernetes i praksis er en stor reconciliation loop som kontinuerlig driver clusteret mot Ã¸nsket state.  Det er mange fordeler med et slikt deployment-system. NÃ¥r deployment og CI er to distinktive komponenter i systemet blir deployment-systemet mye mer spisset inn mot sin rolle og vil kunne perfeksjonere den, den sÃ¥kalte â€œDo one thing and do it wellâ€-tankegangen.  I de neste sidene skal vi beskrive hvordan Argo CD fungerer og hvordan dere kan bruke det til Ã¥ deploye til SKIP. ","version":"Next","tagName":"h2"},{"title":"Configuring apps repositories with config.json","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/configuring-apps-repositories-with-configjson","content":"","keywords":"","version":"Next"},{"title":"Supported optionsâ€‹","type":1,"pageTitle":"Configuring apps repositories with config.json","url":"/docs/applikasjon-utrulling/argo-cd/configuring-apps-repositories-with-configjson#supported-options","content":" Key\tType\tDescriptiontool (required)\tdirectory / kustomize / helm\tWhich tool should Argo CD use to sync this directory? The â€œDirectoryâ€ option supports yaml and jsonnet files. See also tools . autoSync\tboolean ( true / false )\tWhen set to true , the directory is automatically synced when changes are detected. The default value is true in dev and false in prod. prune\tboolean ( true / false )\tWhen enabled, Argo CD will automatically remove resouces that are no longer present in Git. Default is true . See prune . Only used when autoSync is true allowEmpty\tboolean ( true / false )\tSafety mechanism. When prune is enabled it deletes resources automatically, but it will not allow empty syncs (delete all) unless allowEmpty also is enabled. Default is false . See allowEmpty . Only used when autoSync is true selfHeal\tboolean ( true / false )\tWhen changes are made on the cluster directly, Argo will not revert them unless selfHeal is provided. Default is true . See self heal . Only used when autoSync is true ","version":"Next","tagName":"h2"},{"title":"Hente hemmeligheter fra hemmelighetshvelv","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv","content":"","keywords":"","version":"Next"},{"title":"Hvordan bruke External Secretsâ€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#hvordan-bruke-external-secrets","content":" ESO lytter i clusteret etter ExternalSecret - og SecretStore -manifester. I det Ã¸yeblikket disse blir plukket opp blir de lest som konfigurasjon for ESO og en synk mot hvelvet starter som vil ende opp med Ã¥ opprette en Kubernetes Secret. Kubernetes Secreten vil ogsÃ¥ synkroniseres regelmessig slik at man kan f.eks. rullere hemmeligheter ved Ã¥ endre dem i hvelvet.  ","version":"Next","tagName":"h2"},{"title":"SecretStoreâ€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#secretstore","content":" SecretStore-manifestet definerer et hvelv, slik som Vault eller GSM, og mÃ¥ settes opp fÃ¸rst. Denne konfigurasjonen vil ogsÃ¥ inneholde hvordan ESO skal autentisere seg og kan gjenbrukes av flere ExternalSecret-manifester. Disse settes typisk opp av et produktteam for deres namespace for Ã¥ definere hvor de har lagret sine hemmeligheter.  Se GCPSMProvider for alle gyldige verdier.  apiVersion: external-secrets.io/v1beta1 kind: SecretStore metadata: name: gsm spec: provider: gcpsm: projectID: &lt;YOUR_PROJECT_ID&gt;   For at det skal vÃ¦re lov Ã¥ hente ut secrets mÃ¥ i tillegg fÃ¸lgende gjÃ¸res:  Man mÃ¥ gÃ¥ inn pÃ¥ secreten som skal eksponeres til ESO og gi rollen roles/secretmanager.secretAccessor til servicekontoen: Dev - eso-secret-accessor@skip-dev-7d22.iam.gserviceaccount.comProd - eso-secret-accessor@skip-prod-bda1.iam.gserviceaccount.com Namespacene dere oppretter mÃ¥ allowlistes for Ã¥ kunne hente ut fra prosjektene deres, kontakt SKIP sÃ¥ setter vi skip.kartverket.no/gcpProject pÃ¥ prosjektene deres og synkroniserer Argo pÃ¥ nytt  ","version":"Next","tagName":"h2"},{"title":"Synkronisering av hemmeligheter: ExternalSecret og PushSecretâ€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#synkronisering-av-hemmeligheter-externalsecret-og-pushsecret","content":" External Secrets Operator (ESO) tilbyr to primÃ¦re metoder for Ã¥ hÃ¥ndtere hemmeligheter: pull og push. Den vanligste metoden er Ã¥ hente (pull) hemmeligheter fra et eksternt hvelv som Google Secret Manager til Kubernetes, men i noen tilfeller er det ogsÃ¥ nyttig Ã¥ kunne dytte (push) hemmeligheter fra Kubernetes til hvelvet.  ","version":"Next","tagName":"h2"},{"title":"ExternalSecret (Pull)â€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#externalsecret-pull","content":" NÃ¥r du har definert et hemmelighetshvelv med SecretStore, kan du definere hvilke hemmeligheter som skal hentes ut. Dette gjÃ¸res med ExternalSecret-manifestet, som refererer til et SecretStore for Ã¥ vite hvilken backend og autentisering som skal brukes. ESO vil bruke dette manifestet til Ã¥ hente de definerte feltene fra den gitte hemmeligheten og putte dem inn i en Kubernetes Secret i det formatet som blir spesifisert. Dette lar deg for eksempel mappe om navn pÃ¥ nÃ¸kler.  I eksempelet under hentes en hemmelighet fra Google Secret Manager og synkroniseres inn som en Kubernetes Secret.  apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: dbpass spec: # Refererer til SecretStore for autentisering mot Google Secret Manager secretStoreRef: kind: SecretStore name: gsm-backend # Definerer hvilke data som skal hentes data: - remoteRef: # Navnet pÃ¥ hemmeligheten i Google Secret Manager key: db-pass # NÃ¸kkelen som skal brukes i Kubernetes Secret secretKey: DB_PASSWORD # Spesifiserer navnet pÃ¥ Kubernetes Secret som skal opprettes target: name: dbpass # Hvor ofte hemmeligheten skal synkroniseres refreshInterval: 1h     ","version":"Next","tagName":"h3"},{"title":"PushSecret (Push)â€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#pushsecret-push","content":" I motsetning til ExternalSecret som henter hemmeligheter, lar PushSecret deg dytte hemmeligheter fra Kubernetes til et eksternt hvelv som Google Secret Manager. Dette er nyttig nÃ¥r en hemmelighet genereres inne i Kubernetes-klusteret â€“ for eksempel et automatisk generert passord, en privat nÃ¸kkel eller et token â€“ og du Ã¸nsker Ã¥ lagre denne sikkert i et sentralt hvelv for gjenbruk, revisjon eller tilgang fra andre systemer.  PushSecret fungerer ved Ã¥ overvÃ¥ke en Kubernetes Secret. NÃ¥r denne Secret-en opprettes eller endres, vil ESO dytte dataene til den spesifiserte hemmeligheten i hvelvet.  I eksempelet under vises hvordan man dytter en Kubernetes Secret kalt my-app-secret til Google Secret Manager.  apiVersion: external-secrets.io/v1alpha1 kind: PushSecret metadata: annotations: name: push-secret-navn namespace: app-namespace spec: # Dette er secreten som pushes til i gsm. data: - conversionStrategy: None match: remoteRef: remoteKey: gsm-secret # Hvor ofte ESO skal sjekke om hemmeligheten har endret seg refreshInterval: 10m # Refererer til SecretStore for autentisering secretStoreRefs: - kind: SecretStore name: gsm # Velger hvilken Kubernetes Secret som skal overvÃ¥kes og dyttes selector: secret: name: kubernetes-secret   Viktig: For at PushSecret skal fungere, mÃ¥ Service Account-en som brukes av SecretStore-en ha skriverettigheter (f.eks. secretmanager.secretVersionAdder) til hemmelighetene i Google Secret Manager.    ","version":"Next","tagName":"h3"},{"title":"Mounting av hemmelighetâ€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#mounting-av-hemmelighet","content":" NÃ¥r ESO har synkronisert inn hemmeligheten og opprettet en Kubernetes Secret er det ofte slik at man Ã¸nsker Ã¥ bruke dette i en Pod. Vanligvis gjennom Ã¥ mounte dette som miljÃ¸variabler eller som en fil pÃ¥ filsystemet, eksempelvis for sertfikater. Bruker man Skiperator er dette veldig rett frem.  Se ogsÃ¥ Using Secrets as files from a Pod og Using Secrets as environment variables , men merk at spec er annerledes med Skiperator.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: teamname-frontend spec: # Each key will be set as an env var with its value as the value envFrom: - secret: dbpass # Each key will be created as a file with the key as filename and value as content filesFrom: - secret: dbpass mountPath: /var/run/secret   ","version":"Next","tagName":"h3"},{"title":"Hva hindrer andre Ã¥ hente min hemmelighet?â€‹","type":1,"pageTitle":"Hente hemmeligheter fra hemmelighetshvelv","url":"/docs/applikasjon-utrulling/argo-cd/hente-hemmeligheter-fra-hemmelighetsvelv#hva-hindrer-andre-Ã¥-hente-min-hemmelighet","content":" Med External Secrets gis en sentral servicekonto tilgang til Ã¥ hente ut hemmelighetene i GSM. Man skulle derfor tro at det var mulig for andre som bruker den samme servicekontoen Ã¥ hente ut hemmeligheten. Det er ikke tilfellet og er lÃ¸st med andre policies i clusteret.  Ditt team oppretter en SecretStore, og det finnes policies i clusteret som sÃ¸rger for at kun prosjekter som dere eier kan knyttes opp her. SecretStore-en er det som brukes for Ã¥ hente fra GCP. Dermed er det kun prosjektet som ligger her som kan hentes fra, og kun ditt team som kan hente fra ditt prosjekt. ","version":"Next","tagName":"h3"},{"title":"ArgoCD Notifications","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/argocd-notifications","content":"","keywords":"","version":"Next"},{"title":"Slackâ€‹","type":1,"pageTitle":"ArgoCD Notifications","url":"/docs/applikasjon-utrulling/argo-cd/argocd-notifications#slack","content":" For Slack er det satt opp en notifikasjonskanal for hvert team pÃ¥ mÃ¸nster &lt;teamnavn&gt;-argocd-alerts, f.eks. #nrl-argocd-alerts. Disse kanalene er videre satt opp med integration mot Slack-appen â€œArgoCD Notificationsâ€ som tar imot meldinger fra ArgoCD og dytter de inn i korrekt kanal.  (NB: Hvis du ikke finner en slik kanal for teamet ditt, kontakt en administrator for Kartverkets Slack og be om Ã¥ fÃ¥ opprettet en kanal med korrekt navnemÃ¸nster og integrasjon mot â€œArgoCD Notificationsâ€).    ","version":"Next","tagName":"h2"},{"title":"Githubâ€‹","type":1,"pageTitle":"ArgoCD Notifications","url":"/docs/applikasjon-utrulling/argo-cd/argocd-notifications#github","content":" For Github er det satt opp en app kalt â€œKV ArgoCD Notificationsâ€ som har mulighet til Ã¥ skrive til Github workflow statuser til de forskjellige apps-repoene. Kontakt en av Kartverkets Github-administratorer dersom flere apps-repoer skal legges til her.  Eksempler pÃ¥ notifikasjoner:  ","version":"Next","tagName":"h3"},{"title":"Standardnotifikasjonerâ€‹","type":1,"pageTitle":"ArgoCD Notifications","url":"/docs/applikasjon-utrulling/argo-cd/argocd-notifications#standardnotifikasjoner","content":" FÃ¸lgende triggers er lagt til som standard for alle apps-repoer:  Trigger\tKommunikasjonskanal\tNÃ¥r trigges denne?notifications.argoproj.io/subscribe.on-sync-failed.slack\tSlack\tSynkronisering av applikasjon feilet notifications.argoproj.io/subscribe.on-sync-failed.github\tGithub\tSynkronisering av applikasjon feilet notifications.argoproj.io/subscribe.on-sync-succeeded.github\tGithub\tSynkronisering av applikasjon gikk bra notifications.argoproj.io/subscribe.on-sync-running.github\tGithub\tSynkronisering av applikasjon kjÃ¸rer notifications.argoproj.io/subscribe.on-health-degraded.github\tGithub\tHelsesjekk av applikasjonen returnerer et â€œdegradedâ€-resultat notifications.argoproj.io/subscribe.on-sync-status-unknown.github\tGithub\tUkjent synkroniseringsstatus notifications.argoproj.io/subscribe.on-deployed.github\tGithub\tNy versjon av applikasjonen deployet til miljÃ¸ notifications.argoproj.io/subscribe.on-outofsync-one-day.slack\tSlack\tApplikasjonen har status OutOfSync i minst en dag (det har blitt sjekket inn endringer i apps-repoet som ikke har blitt deployet) notifications.argoproj.io/subscribe.on-outofsync-one-week.slack\tSlack\tApplikasjonen har status OutOfSync i minst en uke (det har blitt sjekket inn endringer i apps-repoet som ikke har blitt deployet)  ","version":"Next","tagName":"h3"},{"title":"Ekstra triggersâ€‹","type":1,"pageTitle":"ArgoCD Notifications","url":"/docs/applikasjon-utrulling/argo-cd/argocd-notifications#ekstra-triggers","content":" I tillegg er det mulig Ã¥ spesifisere andre triggers (sÃ¥ lenge disse er lagt inn i ArgoCD) per team i objektet triggerSubscriptions i https://github.com/kartverket/skip-apps/blob/main/lib/argocd/argocd.libsonnet .  info Husk Ã¥ spesifisere om det er slack eller github notifikasjon man Ã¸nsker ved Ã¥ legge til suffikset .slack eller .github pÃ¥ slutten av trigger, og husk Ã¥ spesifisere kanalnavn ved bruk av slack notifikasjon  { name: 'teamnavn', oidcGroup: 'aabbbcc-123-321-ccbbbaa', allowlistedPrefixes: [{ name: 'teamnavn' }], triggerSubscriptions: { 'notifications.argoproj.io/subscribe.on-sync-succeeded.slack': 'navn-paa-slack-kanal', 'notifications.argoproj.io/subscribe.eksempel-trigger.github': '', # denne er blank siden det ikke er en kanal Ã¥ sende til pÃ¥ github } },  ","version":"Next","tagName":"h3"},{"title":"Hvordan bruke Argo CD","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd","content":"","keywords":"","version":"Next"},{"title":"Applikasjonerâ€‹","type":1,"pageTitle":"Hvordan bruke Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd#applikasjoner","content":" Det fÃ¸rste man gjÃ¸r nÃ¥r man skal ta i bruk Argo er Ã¥ gÃ¥ til nettsiden og logge inn. Lenkene til nettsiden finner man pÃ¥ Argo CD og alle kan logge inn med kartverket-brukeren sin hvis man er pÃ¥ et team som har fulgt Komme i gang med Argo CD.    Det neste som mÃ¸ter deg er en oversikt over applikasjonene som Argo leser ut, avbildet over. Dersom man ikke sere noen applikasjoner her, sjekk om dere har fulgt alle stegene i Komme i gang med Argo CD og at dere har manifester som er satt opp til Ã¥ bli synket inn fra apps-repoet deres. Disse prosjektene blir automatisk opprettet basert pÃ¥ mappestrukturen i apps-repoet deres, sÃ¥ det er ingen behov for Ã¥ opprette eller rydde opp prosjekter manuelt.  Klikk pÃ¥ et av kortene pÃ¥ denne siden og dere vil gÃ¥ inn i en mer detaljert visning hvor man ser alle ressursene som blir synkronisert.    Dersom man bruker Skiperator og eksponererer en URL via ingresses vil man ogsÃ¥ kunne se smÃ¥ ikoner som er lenker og om man klikker pÃ¥ dem Ã¥pnes applikasjonen i nettleseren.  Det er ogsÃ¥ et sett med filtere pÃ¥ venstre side som er lurt Ã¥ bli kjent med, spesielt dersom applikasjonene blir store og vanskelige Ã¥ se pÃ¥ en skjerm uten Ã¥ scrolle.  ","version":"Next","tagName":"h2"},{"title":"Syncâ€‹","type":1,"pageTitle":"Hvordan bruke Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd#sync","content":"   info Merk at i dev synkroniseres applikasjoner automatisk  PÃ¥ prosjektsiden ser man alle kubernetes-ressurser som er en del av applikasjonen. Legg merke til de smÃ¥ fargede symbolene pÃ¥ hvert kort som sier noe om statusen pÃ¥ ressursen. Hvis de er grÃ¸nne viser det at den ressursen er â€œhealthyâ€. Dersom den er rÃ¸d er det et tegn pÃ¥ at noe er galt med ressursen. Dersom den er gul er den â€œute av synkâ€, og da mÃ¥ man synkronisere applikasjonen.  Bildet over viser hvordan man kan synkronisere ut endringene til kubernetes-miljÃ¸et. Sync-knappen i menylinjen lar deg velge hvordan ting skal synkroniseres ut, og man kan til og med gjÃ¸re en Selective Sync av kun noen av ressursene. Det vanligste og tryggeste er vel Ã¥ merke Ã¥ synkronisere alt med default-innstillingene.  Dersom en synk ikke har fungert vil man se en feilmelding i menylinjen Ã¸verst. I det tilfellet kan det vÃ¦re lurt Ã¥ trykke pÃ¥ â€œsync statusâ€-knappen Ã¸verst for Ã¥ fÃ¥ en mer detaljert oversikt over hva som har gÃ¥tt galt.  ","version":"Next","tagName":"h2"},{"title":"Rollbackâ€‹","type":1,"pageTitle":"Hvordan bruke Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd#rollback","content":" I noen tilfeller kan man tenke seg at en uÃ¸nsket endring er kommet ut i kjÃ¸remiljÃ¸et. Da vil den raskeste og enkleste mÃ¥ten Ã¥ gjenopprette funksjonaliteten for brukerene ofte vÃ¦re en rollback til en tidligere kjent fungerende versjon.  Rollbacks er det innebygget stÃ¸tte for i Argo CD som en del av applikasjonsvisningen. Klikk â€œHistory and rollbackâ€ for Ã¥ fÃ¥ en liste over alle tidligere synker som er gjort i denne applikasjonen. Dersom man Ã¸nsker Ã¥ rulle tilbake finner man versjonen man Ã¸nsker i listen og trykker pÃ¥ de tre prikkene og velger rollback. â€œRevisjoneneâ€ i listen peker pÃ¥ en commit i git-historikken til apps-repoet.  Ved en rollback gjÃ¸r Argo CD en synk som vanlig, men mot en tidligere kjent tilstand. Den vil da ikke bruke tilstanden som ligger i git, men tilstanden til en tidligere synk. Etter en rollback vil applikasjonen stÃ¥ som â€œout of syncâ€, og det er forventet siden den ikke matcher tilstanden i git.  info Husk at container imaget mÃ¥ finnes for at det skal vÃ¦re mulig Ã¥ rulle tilbake. Om container imaget er slettet i ghcr.io , for eksempel av en oppryddingsjobb, sÃ¥ vil det ikke vÃ¦re mulig Ã¥ starte opp den tidligere versjonen.  ","version":"Next","tagName":"h2"},{"title":"Detaljer og Web Terminalâ€‹","type":1,"pageTitle":"Hvordan bruke Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd#detaljer-og-web-terminal","content":"   Dersom man klikker pÃ¥ en ressurs i prosjektvisningen vil man se flere detaljer om denne ressursen. Man finner blant annet en oversikt over metadata, manfiest-filen som Argo CD skal synke ut, events og logger.  Det er ogsÃ¥ mulig Ã¥ endre pÃ¥ manifestfilen som ligger i clusteret om man gÃ¥r pÃ¥ â€œlive manifestâ€ og trykker â€œeditâ€. Dette vil fÃ¸re til at applikasjonen kommer ut av synk, og i miljÃ¸er hvor auto-synking er skrudd pÃ¥ vil det tilbakestilles med en gang. Men i noen tilfeller kan det vÃ¦re nyttig.    Legg ogsÃ¥ merke til â€œterminalâ€-fanen. Denne er kun synlig om man velger en pod. Velger man denne fanen fÃ¥r man en live terminaltilkobling inn til podden som man kan bruke til feilsÃ¸king.  info Web terminal er ikke tilgjengelig i prod  ","version":"Next","tagName":"h2"},{"title":"Hvordan bruke Argo gjennom APIâ€‹","type":1,"pageTitle":"Hvordan bruke Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/hvordan-bruke-argocd#hvordan-bruke-argo-gjennom-api","content":" Visst du Ã¸nsker Ã¥ automatisere oppgaver, for eksempel synk ved ny image versjon sÃ¥ kan det vÃ¦re greit Ã¥ ha muligheten til Ã¥ gjÃ¸re dette fra Github. Det fÃ¸rste du trengre da er nettverkstilgang fra Github, det fÃ¥r du med tailscale.  For Ã¥ autentisere mot Argo sÃ¥ mÃ¥ du generere en JWT, dette kan du gjÃ¸re i Argo UIet. GÃ¥ inn pÃ¥ f.eks , trykk pÃ¥ settings oppe til venstre â†’ Projects â†’ ditt prosjekt â†’ trykk pÃ¥ â€œRolesâ€ fanen, og deretter pÃ¥ apiuser. Scroll helt ned pÃ¥ modalen som kommer opp og trykk Create under JWT Tokens. Det er samme framgangsmÃ¥te i andre miljÃ¸.    Etter at token er generert kan du testen den med kommandoen:  curl https://argo-dev.kartverket.dev/api/v1/applications/&lt;min-app&gt; -H &quot;Content-Type: application/json&quot; -H &quot;Authorization: Bearer &lt;token&gt;&quot;   Argos API spec kan man finne her:  ","version":"Next","tagName":"h2"},{"title":"Komme i gang med Argo CD","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/komme-i-gang-med-argocd","content":"","keywords":"","version":"Next"},{"title":"Sjekklisteâ€‹","type":1,"pageTitle":"Komme i gang med Argo CD","url":"/docs/applikasjon-utrulling/argo-cd/komme-i-gang-med-argocd#sjekkliste","content":" For Ã¥ starte med Argo CD mÃ¥ du gjÃ¸re fÃ¸lgende:  SÃ¸rg for at teamet ditt oppfyller Hva skal til for Ã¥ bruke SKIP?Produktteamet deres mÃ¥ ha en team-gruppe i Entra IDDet mÃ¥ settes opp et apps-repo Les Hva er et apps-repo for Ã¥ forstÃ¥ hvordan apps-repoer fungererRepoet opprettes fra apps-template malenGitHub teamet deres mÃ¥ gis tilgang til apps-repoet som adminSKIP mÃ¥ gi Argo CD-appen pÃ¥ GitHub tilgang slik at Argo kan pulle apps-repoet, dette gjÃ¸res gjennom Github IAC repoet Det bestemmes et â€œprefiksâ€ som dere deployer til Vanligvis er dette navnet pÃ¥ applikasjonen som skal deploye til SKIPDere kan administrere alle Kubernetes namespacer som starter med dette prefikset SKIP mÃ¥ konfigurere Argo til Ã¥ lese og synkronisere fra apps-repoet SKIP gjÃ¸r en endring i skip-apps repoet NÃ¥ skal du kunne logge inn pÃ¥ Argo CD og se applikasjonen din! ðŸš€ Du finner lenker til Argo pÃ¥ Argo CDVidere dokumentasjon finnes pÃ¥ Hvordan bruke Argo CD ","version":"Next","tagName":"h2"},{"title":"Hva er et apps-repo","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo","content":"","keywords":"","version":"Next"},{"title":"Mappestrukturâ€‹","type":1,"pageTitle":"Hva er et apps-repo","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo#mappestruktur","content":" Du vil se at et apps-repo har en predefinert mappestruktur. Den ser omtrent slik ut:  env/ # 1 [cluster]/ # 2 foo-main/ # 3 app.yaml # 4   PÃ¥ env nivÃ¥ (2) finner man mapper som gjenspeiler hvilket miljÃ¸ det skal synkroniseres til. Dette er navnet pÃ¥ clusteret, enten atkv3-dev, atvk3-prod, atgcp1-dev eller atgcp1-prod.  PÃ¥ nivÃ¥ 2 finner man navnet pÃ¥ namespacet som det skal deployes til. Dette mÃ¥ starte med et gitt prefiks, vanligvis produktnavnet (i dette tilfellet heter produktet foo ). Etter prefikset kan man skrive hva man vil, vanligvis navnet pÃ¥ branchen i git som er deployed her. Dette kan vÃ¦re nyttig om man Ã¸nsker Ã¥ deploye en mer stabil main branch deployed i tillegg til Ã¥ deploye pull requests som testes live fÃ¸r de merges.  NivÃ¥ 3, altsÃ¥ innholdet av mappen over, er et sett med en eller flere manifestfiler som beskriver applikasjonen. I eksempelet over vil app.yaml inneholde en Skiperator Application manifest som for eksempel kan se slik ut:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: foo-frontend spec: image: kartverket/example port: 8080     NÃ¥r vi putter hele dette eksemplet sammen vil fÃ¸lgende skje:  Produktteamet gjÃ¸r en endring i apps-repoetArgo CD vil etter kort tid lese apps-repoet og finne den endrede app.yaml filenArgo CD ser at den er plassert i dev og foo-main mappene og oppretter foo-main namespacet pÃ¥ dev-clusteretArgo CD legger Application definisjonen inn i namespacet pÃ¥ KubernetesSkiperator plukker opp endringen i namespacet og bygger ut Kubernetes-definisjonen for en applikasjon som skal kjÃ¸re kartverket/example imagetKubernetes puller container imaget og starter podder som kjÃ¸rer applikasjonen  ","version":"Next","tagName":"h2"},{"title":"Gjenbruke konfigurasjonâ€‹","type":1,"pageTitle":"Hva er et apps-repo","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo#gjenbruke-konfigurasjon","content":" Man vil ofte fÃ¥ gjentagende konfigurasjon nÃ¥r man fÃ¥r flere applikasjoner, namespacer og miljÃ¸er. Det finnes metoder i Argo CD for Ã¥ gjÃ¸re konfigurasjonen gjenbrukbar, og du vil finne dokumentasjon om disse pÃ¥ Argo CD Tools .  Flere produktteam har lÃ¸st gjenbruk ved Ã¥ bruke http://jsonnet.org/ som er stÃ¸ttet ut av boksen med Argo. Man kan se et eksempel av dette pÃ¥ eiet-apps . SKIP jobber med et bibliotek med gjenbrukbare jsonnet-objekter .  Vi pÃ¥ SKIP anbefaler at dere starter med Ã¥ sjekke inn vanlige YAML-filer mens dere lÃ¦rer dere systemet. NÃ¥r dere blir komfortable med Argo kan dere se pÃ¥ alternativene som er beskrevet over, da blir ikke lÃ¦ringskurven brattere enn nÃ¸dvendig.  ","version":"Next","tagName":"h2"},{"title":"Kildekode-repoerâ€‹","type":1,"pageTitle":"Hva er et apps-repo","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo#kildekode-repoer","content":" Apps-repoer skal ikke inneholde kildekode. Apps-repoer har kun metadata om applikasjonen i form av manifest-filer. Dette kan man ogsÃ¥ lese om i Best Practices for Argo CD.  Dette gjÃ¸r at man fÃ¥r et tydelig skille mellom kildekoderepoer og apps-repoer. Kildekoderepoer har ansvaret for Ã¥ lagre kode, bygge artefakter og container-imager. Apps-repoer beskriver den Ã¸nskede staten til applikasjonen pÃ¥ clusteret og Argo jobber mot Ã¥ bringe clusteret i synk med denne staten. Dette gjÃ¸r det ogsÃ¥ enkelt Ã¥ forholde seg til apps-repoene som en â€œsingle source of truthâ€ til applikasjonsstaten pÃ¥ clusteret.  ","version":"Next","tagName":"h2"},{"title":"Deploye automatisk ved pushâ€‹","type":1,"pageTitle":"Hva er et apps-repo","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo#deploye-automatisk-ved-push","content":"   Man Ã¸nsker ofte Ã¥ deploye ut nye versjoner av applikasjoner ved push til kildekoderepoer. Hvordan kan man gjÃ¸re dette med Argo CD?  Ved hvert push til et kildekoderepo kjÃ¸res et bygg for Ã¥ bygge et byggartefakt og bygge et container image. SÃ¥ snart dette imaget er pushet til et registry som ghcr.io vil man at dette skal legges ut pÃ¥ clusteret, og da mÃ¥ man oppdatere manifest-filene i apps-repoet. Man kan oppdatere disse filene manuelt for Ã¥ trigge en synk, men det er ogsÃ¥ mulig Ã¥ gjÃ¸re dette automatisk som en del av samme pipeline.  Etter imaget er publisert til ghcr.io puller bygget apps-repoet ved Ã¥ bruke https://github.com/actions/checkout. Deretter endres filene til Ã¥ inneholde referansen til det nye imaget, og disse filene commites lokalt. Hvordan disse filene endres er opp til produktteamet, men et forslag ligger i Automation from CI Pipelines. Til slutt pushes filene til repoet som vil trigge en synk med de oppdaterte manifestene.  Dette kan ogsÃ¥ gjÃ¸res med en PR istedenfor Ã¥ pushe rett til apps-repoet om man vil ha en godkjenning fÃ¸r deploy.  For Ã¥ logge inn pÃ¥ apps-repoet brukes metoden som beskrives i Tilgang til repoer med tokens fra GitHub Actions.  info Dersom man bruker Argo CD til Ã¥ opprette namespacer for alle branches og pull requests er det viktig Ã¥ slette branchene nÃ¥r de ikke lenger er i bruk. Det er begrenset med kapasitet pÃ¥ clusterene og Ã¥ anskaffe hardware, bÃ¥de on-prem og i sky, er ekstremt kostbart. Det holder Ã¥ slette filene i apps-repoet for Ã¥ rydde opp, noe som kan gjÃ¸res automatisk ved sletting av branches.  ","version":"Next","tagName":"h2"},{"title":"Eksempel pÃ¥ Github Actionsâ€‹","type":1,"pageTitle":"Hva er et apps-repo","url":"/docs/applikasjon-utrulling/argo-cd/hva-er-et-apps-repo#eksempel-pÃ¥-github-actions","content":" name: build-and-deploy on: pull_requests: target: - main workflow_dispatch: push: branches: - main env: prefix: prefix jobs: build: # Her bygges et artefakt og et container image pushes til ghcr.io deploy-argo: needs: build runs-on: ubuntu-latest strategy: matrix: env: ['dev', 'test', 'prod'] steps: - uses: octo-sts/action@6177b4481c00308b3839969c3eca88c96a91775f # v1.0.0 id: octo-sts with: scope: kartverket/example-apps identity: example_name - name: Checkout apps repo uses: actions/checkout@v3 with: repository: kartverket/example-apps token: ${{ steps.octo-sts.outputs.token }} - name: Deploy to ${{ matrix.version }} run: | namespace=&quot;${{ env.prefix }}-${{ github.ref_name }}&quot; mkdir -p ./${{ matrix.version }}/$namespace cp -r templates/frontend.yaml ./${{ matrix.version }}/$namespace/frontend.yaml kubectl patch --local \\ -f ./${{ matrix.version }}/$namespace/frontend.yaml \\ -p '{&quot;spec&quot;:{&quot;image&quot;:&quot;${{needs.build.outputs.new_tag}}&quot;}}' \\ -o yaml git config --global user.email &quot;noreply@kartverket.no&quot; git config --global user.name &quot;GitHub Actions&quot; git commit -am &quot;Deploy ${{ matrix.version }} version ${{github.ref_name}}&quot; git push   name: clean-up-deploy on: delete: env: prefix: prefix jobs: delete-deployment: runs-on: ubuntu-latest strategy: matrix: env: ['dev', 'test', 'prod'] steps: - uses: octo-sts/action@6177b4481c00308b3839969c3eca88c96a91775f # v1.0.0 id: octo-sts with: scope: kartverket/example-apps identity: example_name - name: Checkout apps repo uses: actions/checkout@v3 with: repository: kartverket/example-apps token: ${{ steps.octo-sts.outputs.token }} - name: Delete ${{ matrix.version }} deploy run: | namespace=&quot;${{ env.prefix }}-${{ github.ref_name }}&quot; rm -rfv ./${{ matrix.version }}/$namespace git config --global user.email &quot;noreply@kartverket.no&quot; git config --global user.name &quot;GitHub Actions&quot; git commit -am &quot;Delete ${{ matrix.version }} deploy ${{github.ref_name}}&quot; git push  ","version":"Next","tagName":"h3"},{"title":"Provisjonere infrastruktur med Crossplane","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argo-cd/provisjonere-infrastruktur-med-crossplane","content":"","keywords":"","version":"Next"},{"title":"Hvordan komme i gangâ€‹","type":1,"pageTitle":"Provisjonere infrastruktur med Crossplane","url":"/docs/applikasjon-utrulling/argo-cd/provisjonere-infrastruktur-med-crossplane#hvordan-komme-i-gang","content":" La oss si vi har en applikasjon som er deployed med Argo CD og vi Ã¸nsker Ã¥ sette opp en database for denne applikasjonen med Cloud SQL. Da vil vi ha en mappestruktur i vÃ¥rt apps-repo som ser slik ut:  dev/ namespace/ app.yaml # Skiperator-manifest for applikasjonen db.yaml # Crossplane-manifester for databasen pÃ¥ GCP   Det fÃ¸rste steget er Ã¥ fÃ¥ autentisert mot GCP slik at Crossplane fÃ¥r tilgang til Ã¥ opprette ressurser i prosjektet deres. Dette gjÃ¸res ved Ã¥ kontakte SKIP og fÃ¥ lagt inn mapping for prefikset deres i skip-apps .  Deretter kan man opprette ressurser som er stÃ¸ttet av SKIP dokumentert lenger ned. Crossplane stÃ¸tter mye mer, se CRD-er i GCP provideren , men det mÃ¥ lages stÃ¸tte for disse, se â€œTilgang til ressurserâ€.  For Ã¥ provisjonere opp ressurser oppretter produktteamet manifester pÃ¥ Kubernetes som blir lest av Crossplane. Et eksempel pÃ¥ Ã¥ opprette lagring (bucket).  apiVersion: skip.kartverket.no/v1alpha1 kind: BucketInstance metadata: name: my-bucket spec: parameters: bucket: name: dsa-test-bucket-123 serviceAccount: name: crossplane-test displayName: Testing Crossplane Integration   Etter dette er lagt ut vil man kunne se status pÃ¥ crossplane ressursene som et hvilket som helst annen kubernetes-ressurs.  kubectl get bucketinstance   Man kan ogsÃ¥ bruke kubectl describe for Ã¥ hente ut events pÃ¥ disse ressursene. Events sier mer om hva som skjer og er nyttig til feilsÃ¸king.  Mer om feilsÃ¸king finnes pÃ¥ https://docs.crossplane.io/knowledge-base/guides/troubleshoot/ .  ","version":"Next","tagName":"h2"},{"title":"StÃ¸ttede ressurserâ€‹","type":1,"pageTitle":"Provisjonere infrastruktur med Crossplane","url":"/docs/applikasjon-utrulling/argo-cd/provisjonere-infrastruktur-med-crossplane#stÃ¸ttede-ressurser","content":" FÃ¸lgende ressurser er stÃ¸ttet for Ã¥ provisjoneres med Crossplane i dag:  Buckets (Lagring i Google Cloud Storage)GCP Service AccountsBucket Access (Kubernetes SA to Bucket)Workload Identity (Kubernetes SA to GCP SA)  ","version":"Next","tagName":"h2"},{"title":"Oppsettâ€‹","type":1,"pageTitle":"Provisjonere infrastruktur med Crossplane","url":"/docs/applikasjon-utrulling/argo-cd/provisjonere-infrastruktur-med-crossplane#oppsett","content":" For Ã¥ komme i gang med Crossplane mÃ¥ du gjÃ¸re noe setup. Alle produktteam fÃ¥r automatisk opprettet en servicekonto pÃ¥ GCP som vil brukes av Crossplane til Ã¥ autentisere mot GCP, og for at Crossplane skal fÃ¥ brukt denne mÃ¥ det ligge en secret i namespacet deres. For Ã¥ fÃ¥ inn denne kan dere opprette en secret ved hjelp av en ExternalSecret (se Hente hemmeligheter fra hemmelighetshvelv) som kopierer hemmeligheten fra Google Secret Manager inn i Kubernetes. Dette mÃ¥ dere sette opp for hvert prefiks i &lt;prefix&gt;-main mappen deres i apps-repoet:  apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: crossplane-secret spec: refreshInterval: 1h secretStoreRef: name: gsm kind: SecretStore target: name: crossplane-secret data: - secretKey: creds remoteRef: conversionStrategy: Default decodingStrategy: None key: crossplane-credentials metadataPolicy: None   SKIP setter automatisk opp en ProviderConfig nÃ¥r man fÃ¥r knyttet sitt prefix i Argo CD mot GCP. Denne forutsetter en secret i -main namespacet deres som heter crossplane-secret . Hvis ikke denne secreten blir plukket opp sÃ¥ hÃ¸r med SKIP om knytningen til GCP mangler.  For Ã¸vrig mÃ¥ vi bruke JSON keys for GCP service kontoer her siden crossplane stÃ¸tter ikke Workload Identity on-prem.  ","version":"Next","tagName":"h2"},{"title":"Tilgang til ressurserâ€‹","type":1,"pageTitle":"Provisjonere infrastruktur med Crossplane","url":"/docs/applikasjon-utrulling/argo-cd/provisjonere-infrastruktur-med-crossplane#tilgang-til-ressurser","content":" I utgangspunktet kan ikke produktteamene fÃ¥ tilgang til crossplane CRD-er direkte ettersom disse ikke er namespaced-ressurser og produktteamene kun har tilgang til Ã¥ opprette ressurser i sitt eget namespace. Dette betyr at SKIP mÃ¥ opprette sÃ¥kalte â€œCompositionsâ€ for hver ting som produktteamene skal kunne opprette gjennom Crossplane.  Dersom du som utvikler pÃ¥ et produktteam har et Ã¸nske om Ã¥ f.eks. kunne opprette en database eller provisjonere andre ressurser gjennom Crossplane som ikke allerede er stÃ¸ttet mÃ¥ det bestilles en ny Composition fra SKIP.  For at SKIP skal opprette en ny composition mÃ¥ det lages en XRD og en composition .  Se stÃ¸ttede ressurser over. ","version":"Next","tagName":"h2"},{"title":"ðŸ¦‘ ArgoKit","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit","content":"","keywords":"","version":"Next"},{"title":"Introduksjonâ€‹","type":1,"pageTitle":"ðŸ¦‘ ArgoKit","url":"/docs/applikasjon-utrulling/argokit#introduksjon","content":" Velkommen til ArgoKit! Her fÃ¥r du en introduksjon til hva ArgoKit er, og hvorfor det er nyttig ved utrulling av applikasjoner. Du bÃ¸r helst allerede ha lest om utrulling til SKIP ved hjelp av Skiperator og Argo CD. Hvis ikke anbefales fÃ¸lgende ressurser fÃ¸rst:  Argo CD-dokumentasjonSkiperatorSKIP â€“ kom i gang  Skiperator stÃ¸tter bÃ¥de YAML og JSON. I Kartverket brukes ofte Jsonnet, et konfigurasjonssprÃ¥k som utvider JSON med funksjoner, uttrykk og mulighet for gjenbruk. Jsonnet reduserer duplisering og gjÃ¸r komplekse manifest enklere Ã¥ vedlikeholde.  ArgoKit tilbyr et sett med gjenbrukbare Jsonnet-maler (bibliotek) som gjÃ¸r det raskere og mer konsistent Ã¥ definere Skiperator-applikasjoner. Under ser du to eksempler som genererer identisk manifest,fÃ¸rst en Â«rÃ¥Â» Jsonnet-funksjon, deretter en som bruker ArgoKit sine byggesteiner.  ","version":"Next","tagName":"h2"},{"title":"Eksemplerâ€‹","type":1,"pageTitle":"ðŸ¦‘ ArgoKit","url":"/docs/applikasjon-utrulling/argokit#eksempler","content":" ","version":"Next","tagName":"h2"},{"title":"Uten ArgoKit-malerâ€‹","type":1,"pageTitle":"ðŸ¦‘ ArgoKit","url":"/docs/applikasjon-utrulling/argokit#uten-argokit-maler","content":" function(name='foo-frontend', env, version, CLIENT_ID) [ { apiVersion: 'skiperator.kartverket.no/v1alpha1', kind: 'Application', metadata: { name: name, }, spec: { image: version, port: 3000, ingresses: ['foo.example-' + env + '.cloud.com'], accessPolicy: { outbound: { rules: [ { application: 'foo-backend' }, ], external: [ { host: 'graph.microsoft.com' }, { host: 'login.microsoftonline.com' }, ], }, }, env: [ { name: 'CLIENT_ID', value: CLIENT_ID }, { name: 'AUTHORITY', value: 'https://login.microsoftonline.com/abcdefg' }, { name: 'LOGIN_REDIRECT_URI', value: 'https://foo.example-' + env + '.cloud.com' }, { name: 'BACKEND_URL', value: 'https://api.foo.example-' + env + '.cloud.com' }, { name: 'FRONTEND_URL', value: 'https://frontend.example-' + env + '.cloud.com' }, { name: 'SERVICE_CLIENT_ID', value: if env == 'dev' then 'abcdefg' else if env == 'prod' then 'hijklmnop', }, ], }, }, ]   ","version":"Next","tagName":"h3"},{"title":"Med ArgoKit-malerâ€‹","type":1,"pageTitle":"ðŸ¦‘ ArgoKit","url":"/docs/applikasjon-utrulling/argokit#med-argokit-maler","content":" local argokit = import '../../jsonnet/argokit.libsonnet'; local app = argokit.appAndObjects.application; function(name='foo-frontend', env, version, CLIENT_ID) app.new(name, version, 3000) + app.withOutboundSkipApp('foo-backend') + app.withOutboundHttp('graph.microsoft.com') + app.withOutboundHttp('login.microsoftonline.com') + app.forHostnames('foo.example-' + env + '.cloud.com') + app.withVariable('CLIENT_ID', CLIENT_ID) + app.withVariable('AUTHORITY', 'https://login.microsoftonline.com/abcdefg') + app.withVariable('LOGIN_REDIRECT_URI', 'https://foo.example-' + env + '.cloud.com') + app.withVariable('BACKEND_URL', 'https://api.foo.example-' + env + '.cloud.com') + app.withVariable('FRONTEND_URL', 'https://frontend.example-' + env + '.cloud.com') + app.withVariable( 'SERVICE_CLIENT_ID', if env == 'dev' then 'abcdefg' else if env == 'prod' then 'hijklmnop' )   Begge disse eksemplene rendrer ut samme JSON-manifest som er godkjent av Skiperator. Den siste bruker ArgoKit sine gjenbrukbare maler i mye stÃ¸rre grad enn det fÃ¸rste. Dette gjÃ¸r filen mere lesbar og lar deg lettere legge til flere spesifikasjoner og resursser.  ","version":"Next","tagName":"h3"},{"title":"Oversikt over annen dokumentasjon du finner herâ€‹","type":1,"pageTitle":"ðŸ¦‘ ArgoKit","url":"/docs/applikasjon-utrulling/argokit#oversikt-over-annen-dokumentasjon-du-finner-her","content":" Tema\tSide\tInformasjonInstallasjon\tArgoKit/Installasjon\tHvordan installere og oppdatere ArgoKit Komme i gang med ArgoKit\tArgoKit/komme-i-gang\tHvordan komme i gang med ArgoKit, mend vanlige eksempler og bruk AppAndObjects konseptet\tArgoKit/AppAndObjects\tInformasjon om ArgoKit sin appAndObjects bruk ArgoKit V1 API Reference\tArgoKit/ArgoKit V1\tInformasjon om ArgoKit V1 sine templates ArgoKit V2 API Reference\tArgoKit/ArgoKit V2\tInformasjon om ArgoKit V2 sine templates ","version":"Next","tagName":"h2"},{"title":"AppAndObjects Konseptet","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit/appAndObjects","content":"","keywords":"","version":"Next"},{"title":"Motivasjonâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#motivasjon","content":" NÃ¥r du skal skrive mer komplekse manifester for applikasjoner med ekstra ressursser (som ConfigMap, ExternalSecret eller AzureAdApplication), mÃ¥ du som regel legge til variabler, secrets, access policies eller annen konfigurasjon pÃ¥ applikasjonsobjektet ditt. Dette kan vÃ¦re vanskelig Ã¥ koordinere, da ofte navn mÃ¥ stemme pÃ¥ tvers av flere ressursser, og du mÃ¥ huske pÃ¥ sette krevd koknfigurasjon. AppAndObjects lÃ¸ser dette ved at du kan legge til ekstra ressursser til din applikasjon og riktig konfigurasjon blir lagt til applikasjonsobjektet ditt automatisk.  ","version":"Next","tagName":"h2"},{"title":"Introduksjonâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#introduksjon","content":" AppAndObjects er et abstraksjonslag i ArgoKit over applikasjonsobjektet som lar deg legge til ekstra ressurser samtidig som du manipulerer applikasjonen.Samler applikasjon og relaterte ressurser i ett wrapper-objekt som renderes til en Kubernetes List.Denne siden forklarer hva AppAndObjects er, hvorfor det finnes, hvordan det fungerer pÃ¥ et overordnet nivÃ¥, og nÃ¥r du bÃ¸r bruke det.  ","version":"Next","tagName":"h2"},{"title":"Innholdâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#innhold","content":" I stedet for Ã¥ jobbe direkte pÃ¥ ett objekt, jobber vi nÃ¥ pÃ¥ et slags wrapper-objekt med to felter: application og objects. Derav navnet AppAndObjects.  // uten AppAndObjects { apiVersion: 'skiperator.kartverket.no/v1alpha1', kind: 'Application', metadata: { name: 'test-app', }, } // med AppAndObjects { application: { apiVersion: 'skiperator.kartverket.no/v1alpha1', kind: 'Application', metadata: { name: 'test-app', }, }, objects: [] // ekstra Kubernetes-ressurser legges her }   NB! application-feltet kan ogsÃ¥ inneholde et SKIPJob objekt.  ","version":"Next","tagName":"h2"},{"title":"Hovedtemaerâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#hovedtemaer","content":" ","version":"Next","tagName":"h2"},{"title":"NÃ¥r bÃ¸r du bruke AppAndObjectsâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#nÃ¥r-bÃ¸r-du-bruke-appandobjects","content":" NÃ¥r du vil knytte applikasjonen din til Ã©n eller flere relaterte ressurser (for eksempel Azure AD, ConfigMap, ExternalSecret) uten Ã¥ koordinere navn, secrets og policies manuelt.NÃ¥r du Ã¸nsker en konsistent mÃ¥te Ã¥ legge til og fjerne integrasjoner pÃ¥, slik at relevant konfigurasjon fÃ¸lger med automatisk.  ","version":"Next","tagName":"h3"},{"title":"NÃ¥r trenger du ikke Ã¥ bruke AppAndObjectsâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#nÃ¥r-trenger-du-ikke-Ã¥-bruke-appandobjects","content":" NÃ¥r du skal ha en enkel applikasjon uten tilleggsressurser (men AppAndObjects kan godt brukes her ogsÃ¥)  ","version":"Next","tagName":"h3"},{"title":"Konseptuell modellâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#konseptuell-modell","content":" Wrapper-objektet  AppAndObjects representerer applikasjonen som et wrapper-objekt med to felter: application og objects.application er selve applikasjonsobjektet (Skiperator Application eller SKIPJob).objects er en liste med tilleggsressurser som hÃ¸rer til applikasjonen (for eksempel AzureAdApplication, ConfigMap, ExternalSecret).  Utvidelser med .with*  .with*-funksjoner utvider modellen ved Ã¥ oppdatere application og samtidig legge til matchende ressurser i objects der dette er relevant.Referanser som f.eks. secrets og policies koordineres i samme operasjon for Ã¥ redusere feil og duplisering.  Transformasjon ved rendering  Ved rendering transformeres wrapper-objektet til en Kubernetes List med application og alle elementer i objects som separate itemsDette gjÃ¸r at du kan â€œapplyeâ€ hele applikasjonen med tilhÃ¸rende ressurser i Ã©n operasjon.  AppAndObjects funksjoner bruker .with prefiks som betyr at du har en applikasjon med noe ekstra. For eksempel .withAzureAdApplication. Se eksempelet under for hvordan dette ser ut i praksis:  ","version":"Next","tagName":"h3"},{"title":"Eksempel med Azure AD Applicationâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#eksempel-med-azure-ad-application","content":" Si at du Ã¸nsker Ã¥ legge til Azure AD i applikasjonen din, da er det et par ting du mÃ¥ gjÃ¸re:  Lage AzureAdApplication-ressursenSette access policies i applikasjonen som skal bruke ADSette secret Uten AppAndObjects mÃ¥ du koordinere navn/namespace/secret manuelt. Med AppAndObjects hÃ¥ndteres dette av .withAzureAdApplication.  ","version":"Next","tagName":"h2"},{"title":"Uten App And Objectsâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#uten-app-and-objects","content":" Her definerer vi fÃ¸rst en ny Skiperator Application med tilhÃ¸rende access policies for Microsoft, i tillegg til Ã¥ legge inn env fra secret som matcher Azure AD Application. Deretter definerer vi en ny AzureAdApplication-ressurs med matchende name og secretPrefix som i steget over.  local argokit = import '../jsonnet/argokit.libsonnet'; local application = argokit.application; [ application.new('foo-backend') + application.withOutboundHttp('login.microsoftonline.com') + application.withSecret('foosecrets-foo-ad'), argokit.azureAdApplication.new( name='foo-ad', namespace='foo-team-main', secretPrefix='foosecrets', ), ]   ","version":"Next","tagName":"h3"},{"title":"Med App And Objectsâ€‹","type":1,"pageTitle":"AppAndObjects Konseptet","url":"/docs/applikasjon-utrulling/argokit/appAndObjects#med-app-and-objects","content":" NÃ¥r vi har AppAndObjects-abstraksjonslaget kan vi fÃ¸rst definere en applikasjon, deretter kalle.withAzureAdApplication pÃ¥ dette objektet. Det vil gjÃ¸re to ting: opprette et AzureAdApplication-objekt, helt likt som i eksempelet over, og legge det til i objects-lista. Deretter vil access policies og env fra secret bli satt med riktig navn. Fordelen er at all konfigurasjon som trengs for Ã¥ legge til Azure AD i applikasjonen din, er bakt inn i .withAzureAdApplication(), sÃ¥ du slipper Ã¥ tenke pÃ¥ det. Det vil ogsÃ¥ fÃ¸re til at dersom du bytter ut/fjerner Azure AD, kan du fjerne ett funksjonskall, sÃ¥ vil annen sammenhengende konfigurasjon ogsÃ¥ bli fjernet.  local argokit = import '../jsonnet/argokit.libsonnet'; local application = argokit.appAndObjects.application; // bruk appAndObjects application.new('foo-backend') + application.withAzureAdApplication( name='foo-ad', namespace='foo-team-main', secretPrefix='foosecrets', )  ","version":"Next","tagName":"h3"},{"title":"ArgoKit v1 API Reference","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit/argokit-v1","content":"","keywords":"","version":"Next"},{"title":"âš ï¸ dette api-et er deprikert âš ï¸â€‹","type":1,"pageTitle":"ArgoKit v1 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v1#ï¸-dette-api-et-er-deprikert-ï¸","content":"   ","version":"Next","tagName":"h3"},{"title":"jsonnet argokit APIâ€‹","type":1,"pageTitle":"ArgoKit v1 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v1#jsonnet-argokit-api","content":" FÃ¸lgende templates er tilgjengelige for bruk i argokit.libsonnet-filen:  Template\tBeskrivelse\tEksempelargokit.Application\tOppretter en Skiperator-applikasjon\tSe ovenfor argokit.GSMSecretStore\tOppretter en Google Secret Manager External Secrets SecretStore\texamples/jsonnet/secretstore-gsm.jsonnet argokit.GSMSecret\tOppretter en Google Secret Manager External Secrets Secret\texamples/jsonnet/secretstore-gsm.jsonnet argokit.Roles\tOppretter et sett med RBAC-roller for dette navnerommet\texamples/jsonnet/roles.jsonnet  FÃ¸lgende templates er tilgjengelige for bruk i dbArchive.libsonnet-filen:  Template\tBeskrivelse\tEksempeldbArchive.dbArchiveJob\tOppretter en SKIPJob som lager en sql-dump og lagrer den i S3\texamples/jsonnet/dbArchive.jsonnet  ","version":"Next","tagName":"h3"},{"title":"Input parametreâ€‹","type":1,"pageTitle":"ArgoKit v1 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v1#input-parametre","content":" dbArchiveJobâ€‹  Parameter\tType\tStandardverdi\tBeskrivelseinstanceName\tString\t-\tPÃ¥krevd. Et unikt navn for jobben og relaterte ressurser. Dette navnet brukes som base for SKIPJob og hemmeligheter. schedule\tString\t-\tPÃ¥krevd. En cron uttrykk som definerer nÃ¥r jobben skal kjÃ¸re (f.eks. &quot;0 2 * * *&quot; for Ã¥ kjÃ¸re kl. 02:00 hver natt). databaseIP\tString\t-\tPÃ¥krevd. IP-adressen til PostgreSQL-databasen som skal arkiveres. gcpS3CredentialsSecret\tString\t-\tPÃ¥krevd. Navn pÃ¥ hemmeligheten i GSM som inneholder S3-hemmeligheter (AWS_ACCESS_KEY_ID og AWS_SECRET_ACCESS_KEY). databaseName\tString\t-\tPÃ¥krevd. Navn pÃ¥ databasen som skal arkiveres. archiveUser\tString\t'postgres'\tDatabasebrukeren jobben skal bruke for Ã¥ koble til. serviceAccount\tString\t'dummyaccount@gcp.iam'\tGCP Service Account som brukes av Kubernetes-jobben for Ã¥ autentisere mot Google Cloud (f.eks. for Ã¥ hente hemmeligheter fra GSM). cloudsqlInstanceConnectionName\tString\t-\tPÃ¥krevd. Tilkoblingsnavnet til Cloud SQL-instansen (format: project:region:instance). NÃ¸dvendig for Cloud SQL Auth Proxy. port\tInteger\t5432\tPortnummeret til PostgreSQL-databasen. S3Host\tString\t's3-rin.statkart.no'\tHostnavnet til S3-endepunktet hvor arkivet skal lagres. S3DestinationPath\tString\t-\tPÃ¥krevd. Full S3-sti hvor databasearkivet skal plasseres (f.eks. s3://my-bucket/archive/database/). fullDump\tBool\tfalse\tFlagg for Ã¥ inkludere databaseroller uten passord i dumpen.  ","version":"Next","tagName":"h3"},{"title":"Bidragâ€‹","type":1,"pageTitle":"ArgoKit v1 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v1#bidrag","content":" Bidrag er velkomne! Vennligst Ã¥pne et issue eller PR hvis du Ã¸nsker Ã¥ se noe endret eller lagt til. ","version":"Next","tagName":"h2"},{"title":"Kom i gang med ArgoKit","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit/getting-started","content":"","keywords":"","version":"Next"},{"title":"Installer ArgoKit i ditt apps reopâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#installer-argokit-i-ditt-apps-reop","content":" Om du ikke har installert argokit enda, ser du hvordan her!  ","version":"Next","tagName":"h3"},{"title":"Importer ArgoKit V2â€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#importer-argokit-v2","content":" Import path er relativ til hvord du befinner deg i koden.  local argokit = import '../argokit/v2/jsonnet/argokit.libsonnet';   ","version":"Next","tagName":"h3"},{"title":"Definer en applikasjonâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#definer-en-applikasjon","content":" Lag en ny Skiperator-applikasjon med ArgoKit appAndObjects-abstraksjonen:  Tips! Lag en ny variabel for application for Ã¥ fÃ¥ kortere uttrykk.  local application = argokit.appAndObjects.application; application.new('app-name', 'test-image', 3000)   ðŸŽ‰ SÃ¥nn! Der har du en minimal applikasjon som kan kjÃ¸res pÃ¥ SKIP!  ðŸ¤” Lurer du pÃ¥ om manifestet ditt er gyldig? Installer skipctl og kjÃ¸r:  skipctl manifests validate --path=&lt;ditt-manifest.jsonnet&gt;   sÃ¥ slipper du Ã¥ lure. ðŸ˜Ž    ","version":"Next","tagName":"h3"},{"title":"Bygge spec-enâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#bygge-spec-en","content":" ","version":"Next","tagName":"h2"},{"title":"MiljÃ¸variablerâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#miljÃ¸variabler","content":" Med ArgoKit kan du legge til variabler med withEnvironmentVariable funksjonen  application.new('app-name', 'test-image', 3000) + application.withEnvironmentVariable('NAME', value)   Du kan ogsÃ¥ legge til miljÃ¸variabler fra secrets:  application.new('app-name', 'test-image', 3000) + application.withEnvironmentVariablesFromSecret('API_KEY', 'secretRef')   ","version":"Next","tagName":"h3"},{"title":"Access Policiesâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#access-policies","content":" Det finnes en rekke funksjoner for Ã¥ sette access policies i ArgoKit, her kan vi sette opp tilgang til en Postgres-database fra en SKIP-app:  application.new('app-name', 'test-image', 3000) + application.withOutboundPostgres(host='database-host.com', ip='10.0.0.1') + application.withInboundSkipApp(appname='other-app', namespace='other-namespace')   ","version":"Next","tagName":"h3"},{"title":"Ingressâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#ingress","content":" Konfigurering av ingress gjÃ¸res slik:  application.new('app-name', 'test-image', 3000) + application.forHostnames('public-api-url.com')   ","version":"Next","tagName":"h3"},{"title":"Replicasâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#replicas","content":" Replicas settes enkelt opp slik:  application.new('app-name', 'test-image', 3000) + application.withReplicas(initial=2, max=10)   ","version":"Next","tagName":"h3"},{"title":"Probesâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#probes","content":" Probes for startup, liveness og readiness legges til slik:  local livenessProbe = application.probe( path='/health', port=8080, failureThreshold=5, timeout=0, initialDelay=5 ); local readinessProbe = application.probe(path='/health', port=8080); application.new('app-name', 'test-image', 3000) + application.withLiveness(livenessProbe) + application.withStartup(livenessProbe) + application.withReadiness(readinessProbe)     ","version":"Next","tagName":"h3"},{"title":"Legge til flere ressursserâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#legge-til-flere-ressursser","content":" ","version":"Next","tagName":"h2"},{"title":"Azure AD Applicationâ€‹","type":1,"pageTitle":"Kom i gang med ArgoKit","url":"/docs/applikasjon-utrulling/argokit/getting-started#azure-ad-application","content":" Azure AD kan legges til slik, dette vil legge AzureAdApplication til som en kubernetes ressurss i manifestet ditt, i tillegg til Ã¥ legge til access policies og en secret i applikasjonen din.  application.new('app-name', 'test-image', 3000) + application.withAzureAdApplication( name='app-name-ad', namespace='team-namespace', groups=['12345-12345-12345-12345'], logoutUrl='some-url.com', )  ","version":"Next","tagName":"h3"},{"title":"ArgoKit v2 API Reference","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit/argokit-v2","content":"","keywords":"","version":"Next"},{"title":"jsonnet ArgoKit APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#jsonnet-argokit-api","content":" Template\tDescription\tExampleargokit.appAndObjects.application.new()\tOppretter en Skiperatorâ€‘applikasjon ved Ã¥ bruke appAndObjectsâ€‘konvensjonen (dette er standard).\tSee above  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's Replicas APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-replicas-api","content":" NOTE! Det anbefales ikke Ã¥ kjÃ¸re med fÃ¦rre enn 2 replikaer...  Template\tDescription\tExampleargokit.appAndObjects.application.withReplicas\tOpprett replikaer for en applikasjon med fornuftige standardverdier\texamples/replicas.jsonnet argokit.appAndObjects.application.withReplicas\tOpprett replikaer for en applikasjon med minneovervÃ¥king\texamples/replicasets-with-memory.jsonnet argokit.appAndObjects.application.withReplicas\tOppretter en statisk replika uten CPUâ€‘ og minneovervÃ¥king\texamples/replicasets-static.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's Environment APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-environment-api","content":" Template\tDescription\tExampleargokit.appAndObjects.application.withEnvironmentVariable\tOppretter miljÃ¸variabler for en app\texamples/environment.jsonnet argokit.appAndObjects.application.withEnvironmentVariables\tOppretter flere miljÃ¸variabler for en app\texamples/environment.jsonnet argokit.appAndObjects.application.withEnvironmentVariableFromSecret\tOppretter miljÃ¸variabel fra en secret\texamples/environment.jsonnet argokit.appAndObjects.application.withEnvironmentVariableFromSecret\tOppretter miljÃ¸variabel fra en secret\texamples/environment.jsonnet    ","version":"Next","tagName":"h2"},{"title":"ArgoKit's Ingress APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-ingress-api","content":" Template\tDescription\tExampleargokit.appAndObjects.application.forHostname\tOppretter ingress for en app\texamples/ingress.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's accessPolicies APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-accesspolicies-api","content":" Du kan definere hvilke eksterne tjenester (verter/IPâ€‘er) og interne SKIPâ€‘applikasjoner appen din kan kommunisere med.  Template\tDescription\tExampleargokit.appAndObjects.application.withOutboundPostgres(host, ip)\tTillat utgÃ¥ende trafikk til en Postgresâ€‘instans\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withOutboundOracle(host, ip)\tTillat utgÃ¥ende trafikk til en Oracleâ€‘database\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withOutboundSsh(host, ip)\tTillat utgÃ¥ende SSH\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withOutboundLdaps(host, ip)\tTillat utgÃ¥ende sikker LDAPâ€‘port\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withOutboundHttp(host, portname='', port=443, protocol='')\tTillat utgÃ¥ende HTTPS/HTTP til en vert\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withOutboundSkipApp(appname, namespace='')\tTillat utgÃ¥ende trafikk til en annen SKIPâ€‘applikasjon (utgÃ¥ende regel)\texamples/accessPolicies.jsonnet argokit.appAndObjects.application.withInboundSkipApp(appname, namespace='')\tTillat en annen SKIPâ€‘applikasjon Ã¥ nÃ¥ denne (inngÃ¥ende regel)\texamples/accessPolicies.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's Probe APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-probe-api","content":" Konfigurer helseprober for applikasjoner.  Template\tDescription\tExampleargokit.appAndObjects.application.probe(path, port, failureThreshold=3, timeout=1, initialDelay=0)\tBygger et probeâ€‘objekt (sti, port, terskler)\t- argokit.appAndObjects.application.withReadiness(probe)\tLegger til en readinessâ€‘probe (styrer nÃ¥r trafikk sendes til poden)\texamples/probes argokit.appAndObjects.application.withLiveness(probe)\tLegger til en livenessâ€‘probe (restarter container ved feil)\texamples/probes argokit.appAndObjects.application.withStartup(probe)\tLegger til en startupâ€‘probe (blokkerer andre prober til den lykkes)\texamples/probes  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's routing APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-routing-api","content":" Konfigurer ruting for applikasjoner pÃ¥ SKIP.  Template\tDescription\tExampleargokit.routing.new(name, hostname, redirectToHTTPS)\tBygger et ruteâ€‘objekt\texamples/routing.jsonnet argokit.routing.withRoute(pathPrefix, targetApp, rewriteUri, port)\tLegg til rute i ruteâ€‘objektet\texamples/routing.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's Rolebinding APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-rolebinding-api","content":" Konfigurer rolebindingâ€‘ressurser for applikasjoner pÃ¥ SKIP. Opprett ressursen med funksjonen new(), og legg deretter til enten brukere eller en gruppe som subject.  template\tDescription\tExampleargokit.k8s.rolebinding.new()\tOpprett en ny rolebindingâ€‘ressurs\texamples/rolebinding.jsonnet argokit.k8s.rolebinding.withUsers(users)\tLegg til en liste over brukere som subjects\texamples/rolebinding.jsonnet argokit.k8s.rolebinding.withNamespaceAdminGroup(groupname)\tLegg til en namespaceâ€‘adminâ€‘gruppe som subject\texamples/rolebinding.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's ExternalSecret APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-externalsecret-api","content":" Konfigurer eksterne secrets og stores.  template\tDescription\tExampleargokit.externalSecrets.secret.new()\tOpprett en ny ekstern secret\texamples/externalSecrets.jsonnet argokit.externalSecrets.store.new()\tOpprett en ny ekstern store\texamples/externalSecrets.jsonnet  ","version":"Next","tagName":"h2"},{"title":"ArgoKit's ConfigMap APIâ€‹","type":1,"pageTitle":"ArgoKit v2 API Reference","url":"/docs/applikasjon-utrulling/argokit/argokit-v2#argokits-configmap-api","content":" Konfigurer ConfigMapâ€‘ressurser for applikasjoner pÃ¥ SKIP. Alle metoder har parameteren addHashToName for Ã¥ opprette ConfigMap med et unikt navn (hashet suffiks).  template\tDescription\tExampleargokit.k8s.configMap.new(name, data, addHashToName)\tOpprett en ny ConfigMap\texamples/configMap.jsonnet argokit.appAndObjects.application.withConfigMapAsEnv(name, data, addHashToName)\tOpprett en ny ConfigMap og legg innholdet som env i applikasjonen\texamples/withConfigMap.jsonnet argokit.appAndObjects.application.withConfigMapAsMount(name, mountPath, data, addHashToName)\tOpprett en ny ConfigMap og monter den som en fil i applikasjonens filsystem\texamples/withConfigMap.jsonnet ","version":"Next","tagName":"h2"},{"title":"Installasjon","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/argokit/installation-guide","content":"","keywords":"","version":"Next"},{"title":"Automatiske versjonsoppdateringerâ€‹","type":1,"pageTitle":"Installasjon","url":"/docs/applikasjon-utrulling/argokit/installation-guide#automatiske-versjonsoppdateringer","content":" Det anbefales sterkt Ã¥ bruke dependabot for Ã¥ automatisk oppdatere ArgoKit-versjonen nÃ¥r en ny versjon blir utgitt. For Ã¥ gjÃ¸re dette, legg til fÃ¸lgende i din .github/dependabot.yml fil:  version: 2 updates: - package-ecosystem: git-submodules directory: / schedule: interval: daily   Med denne konfigurasjonen vil dependabot sjekke Ã©n gang om dagen om det finnes en ny versjon av ArgoKit. Hvis den finner en ny versjon, oppretter den automatisk en PR for Ã¥ oppdatere versjonen. ","version":"Next","tagName":"h3"},{"title":"ðŸ§° GitHub Actions","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions","content":"","keywords":"","version":"Next"},{"title":"Genereltâ€‹","type":1,"pageTitle":"ðŸ§° GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions#generelt","content":" GitHub actions er GitHubs CI/CD-system. Med dette systemet kan man kjÃ¸re bygg som er tett integrert med kodebasen og bruke et Ã¸kosystem av integrasjoner og ferdiglagde actions via GitHub Marketplace .  Dere kommer til Ã¥ mÃ¸te pÃ¥ en del forskjellige verktÃ¸y nÃ¥r dere skal deploye til SKIP:  SKIP er kjÃ¸remiljÃ¸et for containere i Kartverket. Vi regner ikke GitHub som en del av SKIP, men det er en sÃ¥ sentral komponent i Ã¥ deploye til SKIP-teamet er med Ã¥ drifte GitHub-organisasjonen til KartverketGitHub Actions som er CI/CD-miljÃ¸et for Ã¥ kjÃ¸re jobber som Ã¥ bygge containere fra kildekode og kjÃ¸re terraform plan og applyTerraform som er IaC -verktÃ¸yet som lar oss beskrive det Ã¸nskede miljÃ¸et i kode og eksekverer kommandoer for Ã¥ modifisere miljÃ¸et slik at det blir slik som beskrevetgithub-workflows som er gjenbrukbare jobber man kan bruke i sine pipelines for Ã¥ gjÃ¸re oppsettet lettere. Denne inneholder hovedsakelig den gjenbrukbare jobben â€œrun-terraformâ€. Denne kan benyttes for Ã¥ enkelt autentisere seg mot GCP og bruke terraform pÃ¥ en sikker mÃ¥te.Google Cloud og Google Anthos som er miljÃ¸et som kjÃ¸rer Kubernetes -miljÃ¸et hvor containerene kjÃ¸rerskiperator er en operator som gjÃ¸r det enklere Ã¥ sette opp en applikasjon som fÃ¸lger best practices. Skiperator definerer en Application custom resource som blir fylt ut av produktteamene og deployet med TerraformNacho SKIP signerer container images med en kryptografisk signatur etter de er bygget  GitHub Actions er et CI-systemet som SKIP legger opp til at alle produktteam skal kunne bruke for Ã¥ automatisere bygging av Docker-images i tillegg til muligheter for Ã¥ opprette infrastruktur i skyen ved hjelp av Terraform pÃ¥ en automatisert mÃ¥te.Actions lages ved Ã¥ skrive YAML-filer i .github/workflows -mappa i roten av repoet. Man kan ogsÃ¥ trykke pÃ¥ â€œActionsâ€ og â€œNew workflowâ€ i GitHub og fÃ¥ opp dialogen over. Der kan man velge fra et eksisterende bibliotek med eksempler pÃ¥ Actions som kan hjelpe med Ã¥ komme i gang med en action. For eksempel kan man trykke â€œView allâ€ pÃ¥ â€œContinous Integrationâ€ for Ã¥ finne eksempler pÃ¥ hvordan man bygger med java eller node.js. DIsse er ofte gode utgangspunkt nÃ¥r man skal sette opp et nytt bygg.  Les https://docs.github.com/en/actions/learn-github-actions/understanding-github-actions for en introduksjon til Actions.  Se https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions for referanse av mulige verdier.  ","version":"Next","tagName":"h2"},{"title":"Lagring av imagesâ€‹","type":1,"pageTitle":"ðŸ§° GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions#lagring-av-images","content":" Det anbefalte mÃ¥ten Ã¥ publisere images er nÃ¥ til GitHub Container Registry (ghcr.io). Dette kan gjÃ¸res enkelt ved hjelp av GitHub Actions.  Se denne artikkelen for mer informasjon om ghcr: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-container-registry .  Eksempler for publisering av container images til GitHub finnes her .  Dersom dere bruker metoden over vil dere merke at dere ikke trenger Ã¥ sette tags pÃ¥ docker imaget dere bygger. Dette vil settes automatisk basert pÃ¥ en â€œsane defaultâ€ ut i fra hvilke branch man er pÃ¥ og hvilke kontekst bygget gjÃ¸res i (commit, PR, tag). De resulterende taggene er dokumentert her . Tags kan ogsÃ¥ tilpasses om ikke default er passende for prosjektet.  Resultatet blir Ã¥ finne pÃ¥ GitHub repositoriet til koden og ser slik ut:    Det er anbefalt Ã¥ kjÃ¸re skannere pÃ¥ images som bygges fÃ¸r de deployes. Da vil sÃ¥rbarheter kunne vises i Utviklerportalen. Se Pharos for Ã¥ komme i gang med kodeskanning.  ","version":"Next","tagName":"h2"},{"title":"Deploymentâ€‹","type":1,"pageTitle":"ðŸ§° GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions#deployment","content":" For deployment brukes Argo CD som det dedikert deployment-verktÃ¸y. Se Argo CD for mer informasjon om hvordan man tar i bruk dette.  Det vil finnes prosjekter som bruker Terraform, enten fordi de hadde oppstart fÃ¸r Argo CD eller fordi de har spesielle behov som tilsier at de trenger Terraform. Disse prosjektene kan se pÃ¥ Bruk av Terraform for videre dokumentasjon. For nye prosjekter anbefaler vi Argo CD. ","version":"Next","tagName":"h2"},{"title":"Bruk av Terraform","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/bruk-av-terraform","content":"","keywords":"","version":"Next"},{"title":"Lagring av stateâ€‹","type":1,"pageTitle":"Bruk av Terraform","url":"/docs/applikasjon-utrulling/github-actions/bruk-av-terraform#lagring-av-state","content":" Terraform bruker state for Ã¥ kontrollere og sammenlikne den nÃ¥vÃ¦rende konfigurasjonen mot det som kjÃ¸rer, staten mÃ¥ lagres lokalt eller ekstern. PÃ¥ SKIP bruker vi Google Cloud Storage til Ã¥ lagre state, og oppsettet for dette kan man se under.  State bucket opprettes i repoet https://github.com/kartverket/gcp-service-accounts.  terraform { backend &quot;gcs&quot; { bucket = &quot;terraform_state_foobar_1e8e&quot; prefix = &quot;foobar-frontend&quot; } }   For at backenden over skal kunne nÃ¥ denne bucketen mÃ¥ service-kontoen den kjÃ¸rer som vÃ¦re autentisert mot Google Cloud med riktige tilganger. Dette gjÃ¸res i byggelÃ¸ypa fÃ¸r Terraform blir kjÃ¸rt, se avsnittet under for hvordan man autentiserer med Google Cloud som en del av Github Actionen.  ","version":"Next","tagName":"h2"},{"title":"KjÃ¸re Terraform i GitHub Actionsâ€‹","type":1,"pageTitle":"Bruk av Terraform","url":"/docs/applikasjon-utrulling/github-actions/bruk-av-terraform#kjÃ¸re-terraform-i-github-actions","content":" Se https://github.com/kartverket/github-workflows for hvordan man bruker Terraform som en del av GitHub Actions. ","version":"Next","tagName":"h2"},{"title":"Dependency review pÃ¥ PR","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/dependency-review","content":"","keywords":"","version":"Next"},{"title":"Internal actionsâ€‹","type":1,"pageTitle":"Dependency review pÃ¥ PR","url":"/docs/applikasjon-utrulling/github-actions/dependency-review#internal-actions","content":" Vi har noen internal actions i Kartverket, som ikke vil fungere med Dependency Review, siden repoene ikke er public. Det kan dere lÃ¸se med Ã¥ legge actionen inn i allowlisten til dependency review slik:   - name: Perform dependency review uses: actions/dependency-review-action@v4 if: github.event_name == 'pull_request' with: comment-summary-in-pr: always fail-on-severity: moderate allow-dependencies-licenses: | pkg:github/kartverket/repo-navn pkg:github/kartverket/en-annen-action   Interne repoer blir kontinuerlig oppdatert av dependabot, og med Github Advanced Security sÃ¥ fÃ¥r vi varsler dersom actionen skulle vÃ¦re sÃ¥rbar, det burde derfor ikke vÃ¦re noe problem Ã¥ allowliste disse. ","version":"Next","tagName":"h2"},{"title":"Sikkerhetsscanning med Pharos","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/pharos","content":"","keywords":"","version":"Next"},{"title":"Eksemplerâ€‹","type":1,"pageTitle":"Sikkerhetsscanning med Pharos","url":"/docs/applikasjon-utrulling/github-actions/pharos#eksempler","content":" ","version":"Next","tagName":"h2"},{"title":"KjÃ¸r skannere en gang i dÃ¸gnetâ€‹","type":1,"pageTitle":"Sikkerhetsscanning med Pharos","url":"/docs/applikasjon-utrulling/github-actions/pharos#kjÃ¸r-skannere-en-gang-i-dÃ¸gnet","content":" Scanning en gang i dÃ¸gnet kan se ut som eksempelet under. Merk at matrix er brukt for Ã¥ scanne flere images i parallel, men det er ikke nÃ¸dvendig for repoer med kun ett image:  name: Sikkerhetsscanning av images on: schedule: - cron: '00 5 * * *' # 05:00 UTC each day. env: registry: ghcr.io jobs: pharos: name: Run Pharos runs-on: ubuntu-latest strategy: fail-fast: false # De andre jobbene i matrisen vil kjÃ¸re selv om en av dem feiler matrix: package-name: [ 'image1', 'image2', 'image3', 'image4' ] # Permissions pÃ¥krevd av pharos permissions: actions: read packages: read contents: read security-events: write steps: - name: Run Pharos uses: kartverket/pharos@v0.2.5 with: trivy_category: ${{ matrix.package-name }} image_url: ${{ env.registry }}/${{ github.repository_owner }}/${{ matrix.package-name }}:latest   ","version":"Next","tagName":"h3"},{"title":"KjÃ¸r skannere for hver gang et nytt image byggesâ€‹","type":1,"pageTitle":"Sikkerhetsscanning med Pharos","url":"/docs/applikasjon-utrulling/github-actions/pharos#kjÃ¸r-skannere-for-hver-gang-et-nytt-image-bygges","content":" Det er lurt Ã¥ skanne images ved hvert push til hovedbranchen. Da mÃ¥ imaget pushes fÃ¸rst, og sÃ¥ kan det skannes av Pharos. Det er anbefalt Ã¥ kjÃ¸re scanning for push til hovedbranchen, og ikke ved f.eks. push til tag. Om scanning kjÃ¸res ved push til hovebranchen for repoet blir &quot;Code scanning&quot;-oversikten blir intuitiv og resultatene dukker ogsÃ¥ opp i sikkerhetsmetrikkerverktÃ¸yet i Utviklerportalen.  on: push: branches: - main env: image_name: ghcr.io/${{ github.repository }} # ghcr.io/kartverket/repo-name jobs: build: steps: # Most steps skipped for brevity - name: Build and push container image id: build-image uses: docker/build-push-action@v6 with: push: true # Image must be pushed before scanning tags: ${{ env.image_name }}:latest # Remaining properties skipped for brevity outputs: image_digest: ${{ steps.build-image.outputs.image_digest }} run-pharos: name: Run Pharos runs-on: ubuntu-latest # Only run on pushes to default branch if: github.event_name == 'push' &amp;&amp; github.ref_name == github.event.repository.default_branch permissions: actions: read packages: read contents: read security-events: write steps: - name: &quot;Run Pharos&quot; uses: kartverket/pharos@v0.2.5 with: image_url: ${{ env.image_name }}@${{ needs.build.outputs.image_digest }}   ","version":"Next","tagName":"h3"},{"title":"Konfigurasjon av skannereâ€‹","type":1,"pageTitle":"Sikkerhetsscanning med Pharos","url":"/docs/applikasjon-utrulling/github-actions/pharos#konfigurasjon-av-skannere","content":" Konfigurasjonsskanning gjÃ¸res automatisk om det ikke skrus av. Da vil bl.a. Dockerfile og Terraform-kode skannes. Skanning av container images gjÃ¸res automatisk om image_url er spesifisert.  Workflowen vil feile om sÃ¥rbarheter vurdert som high eller critical finnes. Dette kan konfigureres enten ved Ã¥ sette allow_serverity_level til high eller critical, eller med Ã¥ sette disable_serverity_check til false.  For mer informasjon, se pÃ¥ dokumentasjonen for konfigurerbare inputs. ","version":"Next","tagName":"h2"},{"title":"Transitive avhengigheter i Dependency Graph med Gradle","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/gradle-dependency-graph","content":"Transitive avhengigheter i Dependency Graph med Gradle Dependency Graph brukes for Ã¥ fÃ¥ oversikt over avhengigheter og sÃ¥rbarheter. For JVM-prosjekter med Gradle mÃ¥ det settes opp en egen action som sender inn alle transitive avhengigheter. Det kan opprettes en egen action som bÃ¥de sender inn avhengigheter og gjÃ¸r dependency review som i eksempelet under. Dependency sumbission bÃ¸r kun kjÃ¸res fra en enkelt action per repo. Om dependency submission kjÃ¸res fra flere actions vil dette fÃ¸re til uÃ¸nsket oppfÃ¸rsel ved hÃ¥ndtering av sÃ¥rbarheter i Dependency Graph. Se GitHub egne anbefalinger for bruk av dependency submission og dependency review sammen. Merk at oppsett mot private pakkebrÃ¸nner mÃ¥ gjÃ¸res i tillegg (Tailscale eller annet), slik som for vanlige bygg. Java-distribusjon og -versjon mÃ¥ ogsÃ¥ konfigureres til Ã¥ tilsvare det som brukes i kodebasen. name: Publiser Gradle-avhengigheter og PR review on: pull_request: push: branches: - 'main' jobs: dependency-submission: permissions: contents: write # Required for submitting dependencies pull-requests: write # Required for dependency review comments in PR runs-on: ubuntu-latest steps: - uses: actions/checkout@v4 - uses: actions/setup-java@v4 with: # TODO: Update distribution and version if necessary distribution: temurin java-version: 17 - name: Generate and submit dependency graph uses: gradle/actions/dependency-submission@v4 - name: Perform dependency review uses: actions/dependency-review-action@v4 if: github.event_name == 'pull_request' with: comment-summary-in-pr: always fail-on-severity: moderate Dependency review kan fjernes eller konfigureres slik teamet Ã¸nsker det. Se ogsÃ¥ Dependency review.","keywords":"","version":"Next"},{"title":"Autentisering med Workload Identity Federation","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/autentisering-med-workload-identity-federation","content":"","keywords":"","version":"Next"},{"title":"Oppsett av GitHub Actionâ€‹","type":1,"pageTitle":"Autentisering med Workload Identity Federation","url":"/docs/applikasjon-utrulling/github-actions/autentisering-med-workload-identity-federation#oppsett-av-github-action","content":" NÃ¥r man skal sette opp autentisering mot GCP med Workload Identity Federation er det en fordel Ã¥ ha lest gjennom GitHub sin artikkel om https://docs.github.com/en/actions/deployment/security-hardening-your-deployments/configuring-openid-connect-in-google-cloud-platform#updating-your-github-actions-workflow , og spesifikt kapittelet som heter â€œUpdating your GitHub Actions workflowâ€. Her beskriver de de to trinnene man mÃ¥ gjÃ¸re:  Konfigurere tilgang til Ã¥ generere ID-tokensBruke https://github.com/google-github-actions/auth actionen til Ã¥ autentisere mot GCP  SKIP-teamet vil ha konfigurert en workload identity provider og service account som dere kan putte rett inn i provideren over. Disse er ikke hemmelige men vil variere avhengig av miljÃ¸ man skal deploye mot, sÃ¥ det kan vÃ¦re hensiktsmessig Ã¥ ha de som variabler, som vist lenger nede.  permissions: contents: read id-token: write jobs: build: runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - id: auth name: Authenticate to GCP uses: google-github-actions/auth@v0 with: workload_identity_provider: projects/your-project-number/locations/global/workloadIdentityPools/your-pool/providers/your-provider service_account: your-account@your-project.iam.gserviceaccount.com project_id: kubernetes-dev-94b9   Eventuelt kan du ha en egen setup-env jobb som lager outputs du kan bruke senere, slik at provider, service account og project id er variabler i stedet for hardkodede strings.  Eksempel:  permissions: contents: read id-token: write env: PROJECT_ID: kubernetes-dev-94b9 SERVICE_ACCOUNT: your-account@your-project.iam.gserviceaccount.com WORKLOAD_IDENTITY_PROVIDER: projects/your-project-number/locations/global/workloadIdentityPools/your-pool/providers/your-provider jobs: setup-env: runs-on: ubuntu-latest outputs: project_id: ${{ steps.set-output.outputs.project_id }} service_account: ${{ steps.set-output.outputs.service_account }} workload_identity_provider: ${{ steps.set-output.outputs.workload_identity_provider }} steps: - name: Set outputs id: set-output run: | echo &quot;project_id=$PROJECT_ID&quot; &gt;&gt; $GITHUB_OUTPUT echo &quot;service_account=$SERVICE_ACCOUNT&quot; &gt;&gt; $GITHUB_OUTPUT echo &quot;workload_identity_provider=$WORKLOAD_IDENTITY_PROVIDER&quot; &gt;&gt; $GITHUB_OUTPUT build: needs: [setup_env] runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - id: auth name: Authenticate to GCP uses: google-github-actions/auth@v0 with: workload_identity_provider: ${{ needs.setup-env.outputs.workload_identity_provider }} service_account: ${{ needs.setup-env.outputs.service_account }} project_id: ${{ needs.setup-env.outputs.project_id }} build-again: needs: [setup_env] runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v2 - id: auth name: Authenticate to GCP uses: google-github-actions/auth@v0 with: workload_identity_provider: ${{ needs.setup-env.outputs.workload_identity_provider }} service_account: ${{ needs.setup-env.outputs.service_account }} project_id: ${{ needs.setup-env.outputs.project_id }}  ","version":"Next","tagName":"h2"},{"title":"Kubectl fra GitHub Actions","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/kubectl-fra-github","content":"","keywords":"","version":"Next"},{"title":"Oppsettâ€‹","type":1,"pageTitle":"Kubectl fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/kubectl-fra-github#oppsett","content":" FÃ¸r du kan bruke denne actionen mÃ¥ du gjÃ¸re noen endringer i gcp-service-accounts og i ditt teams apps-repo.  ","version":"Next","tagName":"h2"},{"title":"1. Legg til ekstra permissions til deploy service accountenâ€‹","type":1,"pageTitle":"Kubectl fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/kubectl-fra-github#1-legg-til-ekstra-permissions-til-deploy-service-accounten","content":" run-kubectl tar i bruk Workload Identity Federation som du kan lese mer om her, men den krever ogsÃ¥ ekstra tilganger for Ã¥ kunne koble til clusteret. I gcp-service-accounts har du sannsynligvis definert opp ditt gcp project for Ã¥ kunne bruke det i GitHub Actions, og dermed fÃ¥tt laget en deploy service account og et workload identity pool. Da mÃ¥ du bare legge til en ekstra rolle i modul-definisjonen slik:  module &quot;utviklerportal&quot; { source = &quot;./project_team&quot; team_name = &quot;utviklerportal&quot; repositories = [ &quot;kartverket/kartverket.dev&quot;, ] env = var.env project_id = var.utviklerportal_project_id kubernetes_project_id = var.kubernetes_project_id extra_kubernetes_sa_roles = [ &quot;roles/container.clusterViewer&quot;, # &lt;--- Legg til denne linjen i extra_kubernetes_sa_roles ] }   NÃ¥ skal deploy kontoen kunne koble seg til clusteret.  ","version":"Next","tagName":"h3"},{"title":"2. Legg til role og rolebinding i ditt apps-repoâ€‹","type":1,"pageTitle":"Kubectl fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/kubectl-fra-github#2-legg-til-role-og-rolebinding-i-ditt-apps-repo","content":" For at man skal kunne f.eks restarte et deployment, sÃ¥ mÃ¥ vi legge til en kubernetes rbac rolle som gir kontoen tilgang til dette.  I apps repoet, legg til:  kind: Role apiVersion: rbac.authorization.k8s.io/v1 metadata: name: deployment-restart-role rules: - apiGroups: [&quot;apps&quot;] resources: [&quot;deployments&quot;] verbs: [&quot;get&quot;, &quot;patch&quot;] --- kind: RoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: deploy-sa-rolebinding subjects: - kind: User name: your-project-deploy@your-project-id.iam.gserviceaccount.com roleRef: kind: Role name: deployment-restart-role apiGroup: rbac.authorization.k8s.io   navn pÃ¥ service accounten er &quot;modulnavn&quot;-deploy, hvor modulnavn finnes i gcp-service-accounts. du kan ogsÃ¥ finne den med gcloud config set project &lt;projectid&gt; &amp;&amp; gcloud iam service-accounts list | grep deploy  ","version":"Next","tagName":"h3"},{"title":"3. Legg til GitHub workflowâ€‹","type":1,"pageTitle":"Kubectl fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/kubectl-fra-github#3-legg-til-github-workflow","content":" NÃ¥ skal alt vÃ¦re konfigurert og du kan legge til en GitHub workflow som kjÃ¸rer run-kubectl workflow.  eksempel:  name: Get pods on: push jobs: sandbox: name: get pods uses: kartverket/github-workflows/.github/workflows/run-kubectl.yaml@v4.2.2 with: cluster_name: atgcp1-sandbox service_account: test-deploy@test-sandbox-5cx6.iam.gserviceaccount.com kubernetes_project_id: kube-sandbox-6e32 project_number: 833464945837 namespace: default commands: | get pods get pods -l app=nginx   Forklaring:  cluster_name: navnet pÃ¥ clusteret du vil koble til, dette kan du finne med gcloud container fleet memberships list. mer herservice_account: navnet pÃ¥ service accounten som skal brukes. denne blir opprettet i gcp-service-accounts, og slutter pÃ¥ -deploykubernetes_project_id: id til prosjektet som clusteret ligger i, finnes med gcloud projects list | grep kubernetesproject_number: nummeret til prosjektet som service accounten ligger i, dette er produkt prosjektet, finnes med gcloud projects list | grep produktcommands: kubectl kommandoene du vil kjÃ¸re, uten kubectl foran. husk Ã¥ bruk multiline string.namespace: namespace du vil kjÃ¸re kommandoen ikubectl_version: versjonen av kubectl du vil bruke, default er latest stable. format: v1.30.0 ","version":"Next","tagName":"h3"},{"title":"Tilgang til on-prem infrastruktur fra GitHub Actions","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-on-prem-infrastruktur-fra-github-actions","content":"","keywords":"","version":"Next"},{"title":"Bakgrunnâ€‹","type":1,"pageTitle":"Tilgang til on-prem infrastruktur fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-on-prem-infrastruktur-fra-github-actions#bakgrunn","content":" warning Tailscale i denne konteksten er ment som et hjelpemiddel for Ã¥ migrere pakker ut til et ekstern pakkeregister, og som et verktÃ¸y for Ã¥ bli kvitt interne avhengigheter. Anbefales ikke for allmenn bruk.  For Ã¥ understÃ¸tte produktteamene med Ã¥ migrere bort fra intern kode- og artifakthosting, samt avhengigheter pÃ¥ interne databaser har SKIP introdusert Tailscale.  Tailscale er en mesh-basert peer-to-peer VPN-lÃ¸sning, som du kan lese mer om i deres egen dokumentasjon .  ","version":"Next","tagName":"h2"},{"title":"Komme i gangâ€‹","type":1,"pageTitle":"Tilgang til on-prem infrastruktur fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-on-prem-infrastruktur-fra-github-actions#komme-i-gang","content":" Kontakt en GitHub-administrator for Ã¥ be om tilgang for ditt repository  Hei $NAVN! Teamet mitt trenger tilgang til Ã¥ benytte Tailscale pÃ¥ repoet https://github.com/kartverket/mittRepo . Jeg trenger at du granter organisasjonshemmelighetene TS_OAUTH_CLIENT_ID og TS_OAUTH_SECRET (+ tilsvarende for Dependabot org-wide) pÃ¥ repoet, sÃ¥ klarer vi resten selv.  PÃ¥ forhÃ¥nd takk ðŸ™Œ  Etter du har fÃ¥tt tilgang til hemmelighetene, legg til fÃ¸lgende i din GitHub workflow  - name: Tailscale uses: tailscale/github-action@v2 with: oauth-client-id: ${{ secrets.TS_OAUTH_CLIENT_ID }} oauth-secret: ${{ secrets.TS_OAUTH_SECRET }} tags: tag:github-runner   Du kan nÃ¥ benytte deg av utvalgte interne tjenester. Lykke til!  Vil du vite hvilke tjenester du fÃ¥r tilgang til eller behov for flere tjenester enn dagens utvalg? Ta kontakt med SKIP pÃ¥ Slack. ","version":"Next","tagName":"h2"},{"title":"Vedlikehold av applikasjoner","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/maintenance-of-apps","content":"","keywords":"","version":"Next"},{"title":"Stoppe kjÃ¸rende applikasjon i ArgoCDâ€‹","type":1,"pageTitle":"Vedlikehold av applikasjoner","url":"/docs/applikasjon-utrulling/maintenance-of-apps#stoppe-kjÃ¸rende-applikasjon-i-argocd","content":" For Ã¥ kunne stoppe en kjÃ¸rende applikasjon som er administrert av ArgoCD mÃ¥ man fÃ¸rst vÃ¦re sikker pÃ¥ at autosync/self heal er deaktivert for produktteamet som eier applikasjonen. Hvis ikke vil bare applikasjonen spinne opp igjen automatisk.  Se denne filen for Ã¥ sjekke hva som er status, eventuelt spÃ¸r noen pÃ¥ SKIP hvis du er usikker. Hvis ikke annet er satt kan du gÃ¥ ut i fra at autosync er skrudd pÃ¥ i dev og test, men avslÃ¥tt i prod.  For Ã¥ stoppe en applikasjon trykker du pÃ¥ menyen til en application-ressurs og velger â€œStopâ€. Dette vil midlertidig sette antall kopier til 0 slik at skiperator skalerer ned applikasjonen. Du vil da kunne se at pods forsvinner fra grensesnittet, og â€œSync Statusâ€ for applikasjonen vil stÃ¥ som â€œOutOfSyncâ€NÃ¥r man er ferdig med vedlikeholdet og Ã¸nsker Ã¥ gjennopprette tidligere konfigurasjon trenger man bare Ã¥ trykke â€œSyncâ€ for at applikasjonen skal spinne opp igjen.  ","version":"Next","tagName":"h2"},{"title":"Stoppe kjÃ¸rende applikasjon manueltâ€‹","type":1,"pageTitle":"Vedlikehold av applikasjoner","url":"/docs/applikasjon-utrulling/maintenance-of-apps#stoppe-kjÃ¸rende-applikasjon-manuelt","content":" For Ã¥ stoppe en applikasjon som kjÃ¸rer pÃ¥ SKIP mÃ¥ man i praksis skalere ned antallet kjÃ¸rende kopier til 0. Den stÃ¸rste hindringen ved dette er en policy som vi hÃ¥ndhever i prod-miljÃ¸et, som heter â€œK8sReplicaLimitsâ€. Denne krever at en applikasjon skal ha mellom 2 og 30 kjÃ¸rende kopier til en hver tid.  For Ã¥ manuelt stoppe en skiperator-applikasjon er det to ting man mÃ¥ gjÃ¸re:  Sette en annotation for Ã¥ ignorere k8sReplicaLimits policySette antall replicas til 0  Se fÃ¸lgende eksempel pÃ¥ manifest som skalerer til 0  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: some-app annotations: skip.kartverket.no/k8sReplicaLimits: ignore spec: replicas: 0  ","version":"Next","tagName":"h2"},{"title":"Oppsett og bruk av Google Secret Manager","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/oppsett-og-bruk-av-secret-manager","content":"","keywords":"","version":"Next"},{"title":"Hvordan komme i gang?â€‹","type":1,"pageTitle":"Oppsett og bruk av Google Secret Manager","url":"/docs/applikasjon-utrulling/oppsett-og-bruk-av-secret-manager#hvordan-komme-i-gang","content":" GSM fungerer ganske likt Vault. Vault har noe mer funksjonalitet for avansert bruk, men vi bruker for det meste som et KV secret store. For Ã¥ bruke GSM mÃ¥ det opprettes en secret, og denne secreten mÃ¥ tilgangsstyres.  ","version":"Next","tagName":"h2"},{"title":"Hvordan opprette Secretâ€‹","type":1,"pageTitle":"Oppsett og bruk av Google Secret Manager","url":"/docs/applikasjon-utrulling/oppsett-og-bruk-av-secret-manager#hvordan-opprette-secret","content":"   Velg Security under navigasjonsmenyen (de tre strekene ved Google Cloud i hÃ¸yre hjÃ¸rne).Velg Secret Manager i venstre kolonne.Hvis APIâ€™et ikke er skrudd pÃ¥, skru pÃ¥ APIâ€™et ved Ã¥ trykke â€œEnableâ€Trykk pÃ¥ + CREATE SECRET    Name, og Value kan tenkes pÃ¥ som et Key/Value par. Resten av valgene trenger man ikke gjÃ¸re noe med med mindre man har spesielle behov. Noen felter man kan merke seg er:  Replication Policy: Dette er hvor hemmeligheten lagres. Det kan vÃ¦re en fordel Ã¥ lagre hemmeligheter i flere datacenter for redundans, vi har vanligvis holdt oss i europe-north1.  Encryption: Om det er spesielle behov for Ã¥ administrere krypteringsnÃ¸kkel selv er det ogsÃ¥ en mulighet. Dette mÃ¥ produktteamene ta ansvar for selv. SKIP teamet administrerer ikke krypteringsnÃ¸kler.  ","version":"Next","tagName":"h3"},{"title":"Tilgangsstyringâ€‹","type":1,"pageTitle":"Oppsett og bruk av Google Secret Manager","url":"/docs/applikasjon-utrulling/oppsett-og-bruk-av-secret-manager#tilgangsstyring","content":" NÃ¥r en secret er opprettet, kan man klikke seg inn pÃ¥ den, og velge PERMISSIONS fanen. Man fÃ¥r da opp hvem som har tilgang til denne secreten, og hvilke rettigheter de har.    I de fleste tilfeller vil man bruke External Secret til Ã¥ hente ut disse hemmelighetene. Det kan gjÃ¸res ved Ã¥ opprette ExternalSecrets-ressurser i Kubernetes som henter ned hemmeligheten til en Kubernetes Secret. Det stÃ¥r mer om dette inkludert tilgangsstyring pÃ¥ Hente hemmeligheter fra hemmelighetshvelv . ","version":"Next","tagName":"h3"},{"title":"Tilgang til repoer med tokens fra GitHub Actions","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-repoer-med-tokens-fra-github-actions","content":"","keywords":"","version":"Next"},{"title":"Secure Token Service (STS)â€‹","type":1,"pageTitle":"Tilgang til repoer med tokens fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-repoer-med-tokens-fra-github-actions#secure-token-service-sts","content":" En Secure Token Service (STS) er en tjeneste som utsteder sikkerhetstokener som kan brukes til autentisering og autorisering i ulike systemer og applikasjoner. I vÃ¥rt tilfelle Ã¸nsker vi Ã¥ utstede kortlevde tokens som kun er gyldige i perioden de brukes som en erstatning for PAT-er. Vi har derfor implementert et verktÃ¸y som heter Octo STS for Ã¥ levere denne funksjonaliteten.  MÃ¥ten STS fungerer pÃ¥ er at man etablerer tillit mellom to repoer. Dette gjÃ¸res ved Ã¥ legge inn en konfigurasjonsfil i repoet du Ã¸nsker Ã¥ ha tilgang til som sier noe om hvem som skal kunne fÃ¥ tilgang til repoet. Deretter bruker man en ferdig GitHub action i repot som skal fÃ¥ tilgang til Ã¥ etablere et kortlevd tiken via STS-tjenesten.  Les denne artikkelen for mer detaljer om Octo STS.  ","version":"Next","tagName":"h2"},{"title":"Etablere tillitâ€‹","type":1,"pageTitle":"Tilgang til repoer med tokens fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-repoer-med-tokens-fra-github-actions#etablere-tillit","content":" FÃ¸rst mÃ¥ man etablere tillit ved Ã¥ legge inn en config-fil i repoet man skal fÃ¥ tilgang til. Dette legges i mappen .github/chainguard/&lt;navn&gt;.sts.yaml . Erstatt &lt;navn&gt; med identiteten som skal ha tilgang og bruk dette navnet i GitHub actionen senere.  Eksempelet under viser hvordan man gir tilgang fra GitHub actions som kjÃ¸rer pÃ¥ repoet kartverket/mittrepo pÃ¥ branchen main .  issuer: https://token.actions.githubusercontent.com subject: repo:kartverket/mittrepo:ref:refs/heads/main permissions: contents: write   Dersom du Ã¸nsker Ã¥ bruke et wildcard til Ã¥ gi tilgang, for eksempel dersom det deployes ved hjelp av â€œenvironmentsâ€ i GitHub slik at dette blir subjektet ditt kan man bruke et subject_pattern . Dette er et regex.  issuer: https://token.actions.githubusercontent.com subject_pattern: repo:kartverket\\/mittrepo:environment:(sandbox|prod) permissions: contents: write   ","version":"Next","tagName":"h3"},{"title":"FÃ¥ tilgangâ€‹","type":1,"pageTitle":"Tilgang til repoer med tokens fra GitHub Actions","url":"/docs/applikasjon-utrulling/github-actions/tilgang-til-repoer-med-tokens-fra-github-actions#fÃ¥-tilgang","content":" NÃ¥r man skal ha tilgang til dette repoet sÃ¥ bruker man en GitHub action til Ã¥ snakke med STS-tjenesten og fÃ¥ en kortlevd token som brukes pÃ¥ samme mÃ¥te som en PAT. For en deploy til et apps-repo kan du for eksempel skrive fÃ¸lgende i din GitHub action:  permissions: id-token: write # Required for Octo STS steps: - uses: octo-sts/action@6177b4481c00308b3839969c3eca88c96a91775f # v1.0.0 id: octo-sts with: scope: kartverket/skip-apps identity: utviklerportal - name: Checkout apps repo uses: actions/checkout@v4 with: repository: kartverket/skip-apps token: ${{ steps.octo-sts.outputs.token }}   NÃ¥r dette blir kjÃ¸rt vil det bli gjort en spÃ¸rring til Octo STS-tjenesten, som deretter sjekker filen vi laget i repoet over og om det har blitt etablert tillit. Dersom dette er tilfellet sÃ¥ genereres en token som brukes i dette eksempelet til Ã¥ sjekke ut et annet repo.  Se ogsÃ¥ https://github.com/octo-sts/action for dokumentasjon pÃ¥ GitHub actionen. ","version":"Next","tagName":"h3"},{"title":"ðŸŽ® skipctl","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skipctl","content":"ðŸŽ® skipctl skipctl (SKIP Control) er et kommandolinjeverktÃ¸y som hjelper deg med utvikling og testing mot SKIP. VerktÃ¸yet gir deg enkle kommandoer for Ã¥ teste nettverksÃ¥pninger direkte fra terminalen, i tillegg til en rekke kommandoer for Ã¥ jobbe med Kubernetes-manifester for egne applikasjoner og jobber lokalt. Se repoet pÃ¥ GitHub for mer informasjon.","keywords":"","version":"Next"},{"title":"Sjekkliste fÃ¸r internetteksponering","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/sjekkliste-fÃ¸r-internett-eksponering","content":"Sjekkliste fÃ¸r internetteksponering info Denne siden er under utarbeidelse og er et samarbeid mellom utvikling og sikkerhet For Ã¥ eksponere en applikasjon som kjÃ¸rer pÃ¥ SKIP mot internett mÃ¥ man: Opprette en DNS-record som ikke er under statkart.no-domenet, f.eks. applikasjonX.kartverket.no . Det gjÃ¸res ved Ã¥ opprette en ticket i PureService og be om at dette domenet skal ha et CNAME som peker mot SKIP-lastbalansereren (atkv3-prod.kartverket.cloud for on-prem og atgcp1-prod.kartverket.cloud for sky)Legge til det nye domenenavnet under ingresses i Skiperator-manifestet eller hostname for Routing-manifestet , slik at applikasjonen registrerer seg mot ekstern ingress gateway FÃ¸r dette kan gjÃ¸res mÃ¥ man gÃ¥ igjennom denne sjekklisten: GjÃ¸r dere kjent med Overordnede fÃ¸ringer og spesielt Ansvarsfordeling fra SikkerhetshÃ¥ndboka Opprett metadata i GitHub-repoene tilknyttet applikasjonen i henhold til sikkerhet i repoet. Dette sikrer at applikasjonen blir integrert i Utviklerportalen og fÃ¥r tilgang til sikkerhetsmetrikker. Foranalyse mÃ¥ vÃ¦re gjennomfÃ¸rt (det kommer lÃ¸ype for dette i PureService) Det er gjort IP (Innledende Personvernsvurdering) og eventuelt DPIA. Kopier malen IP, DPIA og ROS-analyse for [det som vurderes] til deres omrÃ¥de og fyll ut informasjonen der. ROS-analyse gjennomfÃ¸rt og godkjent av risikoeier/systemeier Codeowners definert i koderepo CODEOWNERS GjennomfÃ¸r en sikkerhetssjekk Se over hvilke endepunkter som er eksponert og at debug endepunkter og liknende interne endepunkter ikke er eksponertSÃ¸rg for at alle endepunkter som krever autentisering faktisk krever detVi anbefaler i tillegg Ã¥ bruke OWASP ZAP for Ã¥ kjÃ¸re en scan FÃ¸lgende headere blir sendt pÃ¥ alle kall: HTTP Strict Transport SecurityContent Security PolicyX-Frame-OptionsX-Content-Type-OptionsReferrer PolicyPermissions Policy NÃ¥r appen er eksponert skal sikkerhetsheaders testes med https://securityheaders.com og https://observatory.mozilla.org Monitorering og varsling er satt opp i Grafana, og vaktlaget er onboardet disse alarmene Metrics with GrafanaLogs with LokiAlerting with Grafana Denne sjekklisten gjelder eksponering av tjenester som skal vÃ¦re tilgjengelig pÃ¥ internett, uavhengig av miljÃ¸ (prod/dev). Hvis man har behov for Ã¥ eksponere en applikasjon eksternt i dev mÃ¥ man i tillegg kontakte SKIP for Ã¥ sikre at alle sikkerhetskrav overholdes. Navnekonvensjon for eksternt tilgjengelig domenenavn vil i sÃ¥ fall vÃ¦re &lt;applikasjonX&gt;.atkv3-dev.kartverket.cloud","keywords":"","version":"Next"},{"title":"Kom i gang","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skipctl/get-started","content":"","keywords":"","version":"Next"},{"title":"Bruk Homebrew (macOS & Linux)â€‹","type":1,"pageTitle":"Kom i gang","url":"/docs/applikasjon-utrulling/skipctl/get-started#bruk-homebrew-macos--linux","content":" ","version":"Next","tagName":"h2"},{"title":"Installasjonâ€‹","type":1,"pageTitle":"Kom i gang","url":"/docs/applikasjon-utrulling/skipctl/get-started#installasjon","content":" brew tap kartverket/taps &amp;&amp; \\ brew install skipctl   ","version":"Next","tagName":"h3"},{"title":"Oppdateringâ€‹","type":1,"pageTitle":"Kom i gang","url":"/docs/applikasjon-utrulling/skipctl/get-started#oppdatering","content":" Om du allerede har installert skipctl kan du sjekke versjon slik:  skipctl -v   Oppdater til nyeste versjon slik:  brew upgrade kartverket/taps/skipctl   ","version":"Next","tagName":"h3"},{"title":"Windowsâ€‹","type":1,"pageTitle":"Kom i gang","url":"/docs/applikasjon-utrulling/skipctl/get-started#windows","content":" Last ned siste versjon for ditt system her.  ","version":"Next","tagName":"h2"},{"title":"Skipctl serverâ€‹","type":1,"pageTitle":"Kom i gang","url":"/docs/applikasjon-utrulling/skipctl/get-started#skipctl-server","content":" Last ned siste versjon eller bruk det medfÃ¸lgende Docker-imaget (hovedsakelig for Ã¥ kjÃ¸re en server for test-funksjonaliteten). ","version":"Next","tagName":"h2"},{"title":"ðŸ¤– Skiperator","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skiperator","content":"ðŸ¤– Skiperator Skiperator is an operator intended to make the setup of applications simple from the users' point of view. You can look at it as a replacement of Helm, but with a more Kubernetes-native approach. Skiperator is developed by SKIP for the Kubernetes platform and is based on the Operator SDK, which is a framework that uses the controller-runtime library to make writing operators easier. The operator is designed to be used by application developers to deploy their applications and jobs into a Kubernetes cluster. It will create all the necessary resources for the application to run, such as deployments, services, and ingress resources, and also handle security aspects like setting up network policies and service accounts so you as a developer don't have to worry about it. Logs and metrics will be automatically available on monitoring.kartverket.cloud Skiperator offers three CRDs (Custom Resource Definitions) to make it easy to deploy applications and jobs into a Kubernetes cluster: Application - for deploying applicationsSKIPJob - for running jobs and cron jobsRouting - for setting up routing rules, for example frontend and backend services under the same domain To get started check out the Requirements and Getting started pages.","keywords":"","version":"Next"},{"title":"Manifester","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skipctl/manifests","content":"","keywords":"","version":"Next"},{"title":"Globaltâ€‹","type":1,"pageTitle":"Manifester","url":"/docs/applikasjon-utrulling/skipctl/manifests#globalt","content":" Felles for alle manifest-kommandoer.  Flagg  Flagg\tType\tStandardverdi\tTillatte verdier\tEffekt--output, -o\tstring\ttext\ttext, json\tVelger loggformat for logger. --debug\tbool\tfalse\ttrue, false\tAktiverer debug-logging. --path, -p\tstring\t.\tValgfri sti\tAngir hvor manifestene leses fra.    ","version":"Next","tagName":"h2"},{"title":"Diffâ€‹","type":1,"pageTitle":"Manifester","url":"/docs/applikasjon-utrulling/skipctl/manifests#diff","content":" Sammenligner lokale manifest mot en git ref.  Eksempel bruk  Kommando\tHandlingskipctl manifest diff\tDiffâ€™er mot HEAD i pretty/full som default. skipctl manifest diff --diff-format patch --ref main\tPatch-format, automatisk verbosity=chunk. skipctl manifest diff --verbosity minimal --diff-format json\tJSON-format, eksplisitt minimal verbosity. skipctl manifest diff --chunk-size 5\tÃ˜ker kontekst til 5 linjer per side.  Flagg  Flagg\tType\tStandardverdi\tTillatte verdier\tEffekt--ref\tstring\tHEAD\tGyldig git-ref (commit SHA, branch)\tAngir hvilken git-ref det diffes mot. --verbosity\tstring\tfull\tminimal, chunk, full\tStyrer mengde kontekst i diff-output. --chunk-size\tint\t3\tHeltall â‰¥ 0\tAntall linjer kontekst over/under endret linje. --diff-format\tstring\tpretty\tpretty, patch, json\tVelger output-format for diff.  Automatisk standard for --verbosity basert pÃ¥ --diff-format  diff-format\tverbositypretty\tfull patch\tchunk json\tfull  Verbosity nivÃ¥  verbosity\tBeskrivelseminimal\tKun endrede linjer chunk\tEndrede linjer med kontekst (3 linjer over/under som utgangspunkt; pÃ¥virkes av --chunk-size) full\tHele filen  Eksempel bruk  Kommando\tHandlingskipctl manifest diff\tDiffâ€™er mot HEAD i pretty/full som default. skipctl manifest diff --diff-format patch --ref main\tPatch-format, automatisk verbosity=chunk. skipctl manifest diff --verbosity minimal --diff-format json\tJSON-format, eksplisitt minimal verbosity. skipctl manifest diff --chunk-size 5\tÃ˜ker kontekst til 5 linjer per side.    ","version":"Next","tagName":"h2"},{"title":"Validateâ€‹","type":1,"pageTitle":"Manifester","url":"/docs/applikasjon-utrulling/skipctl/manifests#validate","content":" Validerer manifestfiler mot kjente Kubernetes-skjema, oppsummerer resultater og rydder opp midlertidige filer.  Eksempel bruk  Kommando\tHandlingskipctl manifest validate\tValiderer alle manifester i nÃ¥vÃ¦rende katalog. skipctl manifest validate -p ./k8s\tValiderer alle manifester under ./k8s. cat manifest.jsonnet | skipctl manifest validate -\tValiderer manifest fra stdin.  Output (oppsummering)  Felt\tBeskrivelsetotalResources\tTotalt antall ressurser prosessert valid\tAntall gyldige invalid\tAntall ugyldige errors\tAntall feil under validering skipped\tAntall hoppet over    ","version":"Next","tagName":"h2"},{"title":"Renderâ€‹","type":1,"pageTitle":"Manifester","url":"/docs/applikasjon-utrulling/skipctl/manifests#render","content":" Renderer manifestfiler og skriver gyldig output til stdout. Feil gÃ¥r til stderr.  Eksempel bruk  Kommando\tHandlingskipctl manifest render\tRenderer alle manifester i nÃ¥vÃ¦rende katalog. skipctl manifest render -p ./manifests\tRenderer alle manifester under ./manifests. cat manifest.jsonnet | skipctl manifest render -\tLeser manifest fra stdin og renderer til stdout.    ","version":"Next","tagName":"h2"},{"title":"Formatâ€‹","type":1,"pageTitle":"Manifester","url":"/docs/applikasjon-utrulling/skipctl/manifests#format","content":" Formaterer manifestfiler i stedet (â€œin placeâ€) eller fra stdin til stdout.  Eksempel bruk  Kommando\tHandlingskipctl manifest format\tFormaterer alle manifester i nÃ¥vÃ¦rende katalog rekursivt. skipctl manifest format -p ./k8s\tFormaterer alle manifester under ./k8s. cat manifest.jsonnet | skipctl manifest format -\tLeser fra stdin, skriver formatert til stdout. ","version":"Next","tagName":"h2"},{"title":"Nettverkstesting","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skipctl/network-troubleshooting","content":"","keywords":"","version":"Next"},{"title":"Brukâ€‹","type":1,"pageTitle":"Nettverkstesting","url":"/docs/applikasjon-utrulling/skipctl/network-troubleshooting#bruk","content":" De ulike test-kommandoene vil kjÃ¸res mot en API-server. KjÃ¸r skipctl test ping --api-server=something for Ã¥ fÃ¥ en liste over stÃ¸ttede API-servernavn. En API-server representerer et sted som kan kjÃ¸re tester fra sitt perspektiv. All kommunikasjon med API-servere er kryptert over TLS.  â— FÃ¸r du kjÃ¸rer noen kommandoer, mÃ¥ du sÃ¸rge for Ã¥ vÃ¦re autentisert fÃ¸rst (gcloud auth application-default login).  ","version":"Next","tagName":"h2"},{"title":"Pingâ€‹","type":1,"pageTitle":"Nettverkstesting","url":"/docs/applikasjon-utrulling/skipctl/network-troubleshooting#ping","content":" Sjekker om en server svarer pÃ¥ ping (ICMP), sett fra nettverksplasseringen til API-serveren.  skipctl test ping --hostname=kv-vm-0123.statkart.no --api-server=atkv3-dev   ","version":"Next","tagName":"h3"},{"title":"Port probeâ€‹","type":1,"pageTitle":"Nettverkstesting","url":"/docs/applikasjon-utrulling/skipctl/network-troubleshooting#port-probe","content":" Sjekker om en server har en Ã¥pen port, dvs. at det er mulig Ã¥ kommunisere med denne serveren fra miljÃ¸et som API-serveren lever i.  skipctl test probe --hostname=kv-vm-0123.statkart.no --port=5432 --api-server=atkv3-dev  ","version":"Next","tagName":"h3"},{"title":"Requirements","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skiperator/requirements","content":"","keywords":"","version":"Next"},{"title":"Application and job requirementsâ€‹","type":1,"pageTitle":"Requirements","url":"/docs/applikasjon-utrulling/skiperator/requirements#application-and-job-requirements","content":" First of all your applications and jobs need to be containerized. This means that your application or job needs to be packaged in a linux container image that can be run in a Kubernetes cluster. In SKIP we recommend to use the scratch image as a base image for your application or job. This is a minimal image that only contains the necessary files to run your application or job.  Next the image needs to be hosted in a container registry that is accessible from the Kubernetes cluster. In SKIP we use github as our container registry. It doesn't matter if the image is publicly available or private, as long as the repository is under the Kartverket organization.  ","version":"Next","tagName":"h2"},{"title":"CI CD requirementsâ€‹","type":1,"pageTitle":"Requirements","url":"/docs/applikasjon-utrulling/skiperator/requirements#ci-cd-requirements","content":" In order to deploy your application you need to have set up a CI/CD pipeline that builds and pushes your container image to the container registry. As previously mentioned, in SKIP we use github as the repository. You can read more about how to set up a CI/CD pipeline in the github actions documentation.  We also need to set up Argo CD for deployment of the application. You can read more about how to set up Argo CD in the Argo CD documentation.  ","version":"Next","tagName":"h2"},{"title":"Summaryâ€‹","type":1,"pageTitle":"Requirements","url":"/docs/applikasjon-utrulling/skiperator/requirements#summary","content":" So to summarize, in order to use Skiperator and run your applications in SKIP you need to have the following in place:  Your application or job needs to be containerizedThe container image needs to be hosted in a container registry that is accessible from the Kubernetes cluster (github)A CI/CD pipeline that builds and pushes the container image to the container registryArgo CD set up for deployment of the application from a team-apps repository  Now that you have the prerequisites in place you can move on to the Getting started page to learn how to deploy your application or job to SKIP. ","version":"Next","tagName":"h2"},{"title":"ðŸ” Tilgangsstyring pÃ¥ SKIP","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring","content":"","keywords":"","version":"Next"},{"title":"ðŸ§© Forutsetningerâ€‹","type":1,"pageTitle":"ðŸ” Tilgangsstyring pÃ¥ SKIP","url":"/docs/applikasjon-utrulling/tilgangsstyring#-forutsetninger","content":" Du mÃ¥ ha registrert en klient hos en OAuth 2.0-identitetstilbyder.Du mÃ¥ vite hvilket well-known endepunkt, audience og eventuelle claims som gjelder for applikasjonen din.Den beskyttede applikasjonen mÃ¥ kjÃ¸re pÃ¥ SKIP.  FÃ¸r du kan bruke Ztoperator til Ã¥ beskytte tjenesten din, mÃ¥ du registrere en klient hos en relevant identitetstilbyder. Dette er nÃ¸dvendig for Ã¥ instruere Ztoperator i hvem som skal slippes inn og hvem som skal blokkeres. Denne &quot;oversikten&quot; fÃ¥r man ved Ã¥ opprette en klientregistrering hos en OAuth 2.0-identitetstilbyder og knytte den til Ztoperator. ","version":"Next","tagName":"h2"},{"title":"Getting started","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skiperator/get-started","content":"","keywords":"","version":"Next"},{"title":"Applicationâ€‹","type":1,"pageTitle":"Getting started","url":"/docs/applikasjon-utrulling/skiperator/get-started#application","content":" An Application is our abstraction of a deployment. Skiperator will create all the necessary resources for you. Create a file named app.yaml in env/atkv3-dev/myapp with the following content:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: myapp spec: image: ghcr.io/kartverket/myapp:latest port: 8080 ingresses: - myapp.atkv3-dev.kartverket-intern.cloud redirectToHTTPS: true accessPolicy: inbound: rules: - application: myjob-skipjob   You can then go into argo search for myappand sync the application. Skiperator will then read the Application resource and create a bunch of resources for you, like a deployment, service, ingress and network policy. Your app should be reachable from the domain myapp.atkv3-dev.kartverket-intern.cloud.  ","version":"Next","tagName":"h2"},{"title":"SKIPJobâ€‹","type":1,"pageTitle":"Getting started","url":"/docs/applikasjon-utrulling/skiperator/get-started#skipjob","content":" A SKIPJob is our abstraction of a job or a cron job. Skiperator will create all the necessary resources for you. Create a file named job.yaml in env/atkv3-dev/myjob with the following content:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: myjob spec: container: image: ghcr.io/kartverket/myjob:latest command: - &quot;sleep 10&quot; accessPolicy: outbound: rules: - application: myapp cron: schedule: &quot;* * * * *&quot;   This creates a cron job that executes every minute. It also has an access policy that allows it to connect to myapp. Skiperator will create network policies that allow the SKIPJob to connect to the Application. If you look at the application above you can see that it has an access policy that allows myjob to connect to it. SKIPJobs must be postfixed with -skipjob in the access policy. You can also connect to applications in other namespaces, see more in configuring or the api docs.  ","version":"Next","tagName":"h2"},{"title":"Routingâ€‹","type":1,"pageTitle":"Getting started","url":"/docs/applikasjon-utrulling/skiperator/get-started#routing","content":" A Routing is an optional resource that you can use to facilitate path based routing, allowing multiple microservices to share the same hostname. Under the hood it's using Istio to proxy requests based on the http path. By using Routing you should remove the ingresses field in you Application manifest. For example if you have two applications, frontend and backend, you can create a routing rule that routes requests to /api to the backend and everything else to the frontend.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Routing metadata: name: myrouting spec: hostname: kartverket.com routes: - pathPrefix: /api targetApp: backend-app - pathPrefix: / targetApp: frontend-app  ","version":"Next","tagName":"h2"},{"title":"Common Skiperator configuration","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skiperator/configuring","content":"","keywords":"","version":"Next"},{"title":"Applicationâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#application","content":" ","version":"Next","tagName":"h2"},{"title":"Ingressâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#ingress","content":" An ingress is a way to expose your application to the outside world. It is a Kubernetes resource that manages external access to services in a cluster, typically HTTP. This sets up all the necessary configuration behind the scenes to route traffic to your application, and also sets up a lets encrypt certificate for your application.  Simple example of an ingress:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: ingressapp spec: image: image port: 8080 ingresses: - ingressapp.atkv3-dev.kartverket-intern.cloud redirectToHTTPS: true   This sets up an ingress to your application that can be reached from Kartverkets internal network. The redirectToHTTPS field is optional and will redirect all incoming traffic to HTTPS. To make it publicly available you can remove the -intern part of the domain name.  If you want, or already have a different domain name for your application then we most likely need to set up a CNAME record in DNS. You can read more about domain names here.  ","version":"Next","tagName":"h3"},{"title":"Access policyâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#access-policy","content":" In SKIP we run istio as a service mesh. This means that all traffic between services is encrypted by default. All traffic is also blocked with network policies or istio policies by default. To allow traffic between services you need to set up an access policy. This is done by specifying spec.accessPolicy in your application.  ","version":"Next","tagName":"h3"},{"title":"allowing communication between two applications in the same namespaceâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#allowing-communication-between-two-applications-in-the-same-namespace","content":" creates rules to allow traffic between application app1 and app2 in the same namespace on service ports  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: app1 spec: image: image port: 8080 accessPolicy: inbound: rules: - application: app2 outbound: rules: - application: app2 --- apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: app2 spec: image: image port: 8080 accessPolicy: inbound: rules: - application: app1 outbound: rules: - application: app1   allowing in and outbound traffic to an application in a different namespaceâ€‹  creates network policy rules to allow inbound and outbound traffic on service port to application app2 in namespace namespace2  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: app1 spec: image: image port: 8080 accessPolicy: inbound: rules: - application: app2 namespace: namespace2 outbound: rules: - application: app2 namespace: namespace2   allowing outbound traffic to a job in namespaces with labelâ€‹  creates outbound rules to allow traffic to the skipjob job2 in all namespaces with label team: someteam on service port for app2Note that all skipjobs must have the postfix -skipjob in the name when defining the application name in the access policy.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: app1 spec: image: image port: 8080 accessPolicy: outbound: rules: - application: job2-skipjob namespaceByLabel: team: someteam   access policy to allow traffic to a public domainâ€‹  creates istio policies to allow traffic to a public domain on port 443, and different public domain on port 80  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: app1 spec: image: image port: 8080 accessPolicy: outbound: external: - host: kartverket.no - host: google.com ports: - name: http port: 80 protocol: HTTP   ","version":"Next","tagName":"h3"},{"title":"Replicasâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#replicas","content":" you can either specify a fixed number of replicas or let the autoscaler handle it for you.  if not specified skiperator uses autoscaler by default:  minReplicas: 2 maxReplicas: 5   static:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: static-replicas spec: image: image port: 8080 replicas: 2   autoscaler:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: auto-replicas spec: image: image port: 8080 replicas: min: 3 max: 6 targetCpuUtilization: 60   This will always have minimum 3 pods running, and scale up to more pods (max 6) if cpu utilization hits 60%. Only minimum value is required.  ","version":"Next","tagName":"h3"},{"title":"Environment variablesâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#environment-variables","content":" Environment values can be set directly in the application spec with spec.env or by using a secret or config map with spec.envFrom.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: auto-replicas spec: image: image port: 8080 env: - name: ENV_VAR value: &quot;value&quot; envFrom: - configMap: config-map-name - configMap: config-map-name2 - secret: secret-name   ","version":"Next","tagName":"h3"},{"title":"GCPâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#gcp","content":" If your application needs to read a gcp bucket for example you need to set up a service account with the correct permissions and add it to the application spec. Best practice here is to create a service account with the same name as the application, for example myapp@some-project-id.iam.gserviceaccount.com, then give this service account minimal permissions in GCP Console.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: auto-replicas spec: image: image port: 8080 gcp: auth: serviceAccount: myapp@some-project-id.iam.gserviceaccount.com   ","version":"Next","tagName":"h3"},{"title":"SKIPJobâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#skipjob","content":" ","version":"Next","tagName":"h2"},{"title":"Cron - SkipJobâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#cron---skipjob","content":" basic cron job that executes every minute  apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: myjob spec: container: image: image:latest cron: schedule: &quot;* * * * *&quot;   ","version":"Next","tagName":"h3"},{"title":"Commands - SkipJobâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#commands---skipjob","content":" a job that uses a command with a docker image  apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: myjob spec: container: image: &quot;perl:5.34.0&quot; command: - &quot;perl&quot; - &quot;-Mbignum=bpi&quot; - &quot;-wle&quot; - &quot;print bpi(2000)&quot;   ","version":"Next","tagName":"h3"},{"title":"Access policy - SkipJobâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#access-policy---skipjob","content":" This is the same as for applications, except we don't define inbound policies for jobs.  ","version":"Next","tagName":"h3"},{"title":"Routingâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#routing","content":" ","version":"Next","tagName":"h2"},{"title":"Frontend and backend services under the same domainâ€‹","type":1,"pageTitle":"Common Skiperator configuration","url":"/docs/applikasjon-utrulling/skiperator/configuring#frontend-and-backend-services-under-the-same-domain","content":" One thing that is important to remember with routes is that the order of the routes matters. The route that is defined first will be the one that is matched first.  If your backend service expects requests without the leading pathPrefix, you can configure rewriteUri to remove the prefix before it arrives at the backend.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Routing metadata: name: myrouting spec: hostname: kartverket.com routes: - pathPrefix: /api # Highest priority rewriteUri: true targetApp: backend-app - pathPrefix: / # Lowest priority targetApp: frontend-app  ","version":"Next","tagName":"h3"},{"title":"â›”ï¸ Ztoperator","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator","content":"â›”ï¸ Ztoperator Ztoperator er en Kubernetes-operator som lar deg deklarativt definere hvordan tilgang til en applikasjons endepunkter skal styres. Den gir stÃ¸tte for Ã¥: Definere hvilke endepunkter som skal vÃ¦re Ã¥pne.Definere hvilke endepunkter som krever et gyldig OAuth 2.0-token.Definere hvilke endepunkter som krever spesifikke claims.Definere hvilke endepunkter som skal omdirigere brukeren til innlogging. Et fullstendig eksempel pÃ¥ hvordan man kan ta i bruk en AuthPolicy for Ã¥ beskytte en applikasjon finner du under Eksempeloppsett av Ztoperator. Hvilke felter som eksisterer og deres oppfÃ¸rsel er dokumentert i Ztoperator API Reference. Hvordan du kan teste og verifisere oppfÃ¸rselen til en AuthPolicy finner du under Test din AuthPolicy.","keywords":"","version":"Next"},{"title":"Klientregistrering","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering","content":"","keywords":"","version":"Next"},{"title":"ðŸªª Digdiratorâ€‹","type":1,"pageTitle":"Klientregistrering","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering#-digdirator","content":" Digdirator er en Kubernetes-operator utviklet av NAV sitt plattformteam (NAIS) som skal gjÃ¸re det enkelt Ã¥ deklarativt sette opp og vedlikeholde integrasjoner mot Digdir sine systemer. Dette inkluderer ID-Porten-integrasjoner og Maskinporten-integrasjoner.  Digdirator introduserer to CRD-er, IDPortenClient og MaskinportenClient, som automatiserer opprettelse og vedlikehold av integrasjoner mot henholdsvis ID-porten og Maskinporten. Alternativt kan klientregistrering gjÃ¸res direkte i et Skiperator-applikasjonsmanifest. Se her for mer informasjon om hvordan du setter opp ID-porten- og/eller Maskinporten-integrasjoner via Skiperator.  ","version":"Next","tagName":"h2"},{"title":"IDPortenClientâ€‹","type":1,"pageTitle":"Klientregistrering","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering#idportenclient","content":" En IDPortenClient er en CRD som lar brukere deklarativt opprette og vedlikeholde ID-Porten-klientregistreringer.  spec (object, required) â€“ Spesifikasjon til IDPortenClient secretName (string, required) â€“ Navnet pÃ¥ den resulterende Secret-ressursen som vil bli opprettet. integrationType (string, optional) â€“ Definerer integrasjonstypen for klienten. Bestemmer hvilke scopes som kan registreres. Kan ikke endres etter opprettelse. Tillatte verdier: krr, idporten, api_klient. scopes ([]string, optional) â€“ Definerer OAuth2-scopes for klienten. Begrenset basert pÃ¥ integrationType. frontchannelLogoutURI (string, optional) â€“ URL som ID-porten omdirigere til nÃ¥r en utlogging utlÃ¸ses av en annen applikasjon. postLogoutRedirectURIs ([]string, optional) â€“ Liste over gyldige URI-er hvor ID-porten kan omdirigere etter utlogging. redirectURIs ([]string], optional) â€“ Liste over redirect URI-er som skal registreres hos DigDir. accessTokenLifetime (integer, optional) â€“ Maksimal levetid i sekunder for access_token som returneres fra ID-porten. Min: 1, maks: 3600. clientURI (string, optional) â€“ URL til klienten brukt av DigDir nÃ¥r en 'tilbake'-knapp vises eller ved feil. clientName (string, optional) â€“ Navnet pÃ¥ klienten registrert hos DigDir. Vises under innlogging for brukerorienterte flyter. sessionLifetime (integer, optional) â€“ Maksimal Ã¸ktlevetid i sekunder for en innlogget sluttbruker for denne klienten. Min: 3600, maks: 28800. ssoDisabled (bool, optional) â€“ Kontrollerer Single Sign-On-oppsettet for klienten. Hvis satt til true, er SSO deaktivert.  FÃ¸lgende eksempel registrerer en klientintegrasjon mot ID-porten av typen idporten. NÃ¥r registrering er fullfÃ¸rt vil Digdirator opprette Kubernetes-hemmeligheten idporten-secret i namespacet tilgangsstyring-main.  apiVersion: nais.io/v1 kind: IDPortenClient metadata: name: test-client namespace: tilgansstyring-main spec: clientName: Test Application clientURI: https://test-app.atgcp1-sandbox.kartverket-intern.cloud frontchannelLogoutURI: https://test-app.atgcp1-sandbox.kartverket-intern.cloud/oauth2/logout integrationType: idporten redirectURIs: - https://test-app.atgcp1-sandbox.kartverket-intern.cloud/oauth2/callback scopes: - openid - profile secretName: idporten-secret   ","version":"Next","tagName":"h3"},{"title":"MaskinportenClientâ€‹","type":1,"pageTitle":"Klientregistrering","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering#maskinportenclient","content":" En MaskinportenClient er en CRD som lar brukere deklarativt opprette og vedlikeholde Maskinporten-klientregistreringer.  spec (object, required) â€“ Spesifikasjon til MaskinportenClient secretName (string, required) â€“ Navnet pÃ¥ den resulterende Secret-ressursen som vil bli opprettet. clientName (string, optional) â€“ Navnet pÃ¥ klienten registrert hos DigDir. Vises under innlogging for brukerorienterte flyter, og er ellers en lesbar mÃ¥te Ã¥ skille mellom klienter i DigDirs selvbetjeningsportal. scopes ([]object, optional) â€“ Definerer hvilke scopes applikasjonen konsumerer og hvilke den eksponerer. consumes ([]object, optional) â€“ En liste med scopes din klient kan forespÃ¸rre tilgang til. name (string, required) â€“ Scopene som applikasjonen konsumerer for Ã¥ fÃ¥ tilgang til en ekstern organisasjons API. exposes ([]object, optional) â€“ En liste med scopes din applikasjon Ã¸nsker Ã¥ eksponere til andre organisasjoner hvor tilgang er basert pÃ¥ organisasjonsnummer. enabled (bool, required) â€“ Hvis true, sÃ¥ er detkonfigurerte scopet tilgjengelig for bruk og til Ã¥ bli konsumert av organisasjoner som har fÃ¥tt godkjent tilgang. name (string, pÃ¥krevd) â€“ Det faktiske sub-scopet kombinert med product. product (string, valgfritt) â€“ ProduktomrÃ¥de tilknyttet scopet. Dette vil inkluderes i resultatet: org:&lt;product&gt;&lt;name&gt;. atMaxAge (int, valgfritt) â€“ Maksimal tillatt levetid for token i sekunder. Defaulter til 30 sekunder. allowedIntegrations ([]string, valgfritt) â€“ Liste over tillatte integrasjonstyper for dette eksponerte omfanget. Defaulter til maskinporten. consumers ([]object, valgfritt) â€“ Liste over eksterne konsumenter som har tilgang til Ã¥ konsumere dette scopet og som kan forespÃ¸rre access_token. orgno â€“ Det eksterne organisasjonsnummeret. name â€“ Beskrivende felt brukt utelukkende for oversikt. accessibleForAll â€“ Tillater alle organisasjoner Ã¥ fÃ¥ tilgang til scopet. delegationSource â€“ Delegasjonskilde for scopet. Default er tomt, noe som betyr at ingen delegasjon er tillatt. separator â€“ Tegnet som skiller product og name i det endelige scopet. Resultatet blir da &lt;prefix&gt;:&lt;product&gt;&lt;separator&gt;&lt;name&gt;. Defaulter til : med mindre name inneholder /, i det tilfellet defaultes det til /. visibility â€“ Kontrollerer synligheten til scopet. Offentlige scopes er synlige for alle, mens private scopes kun er synlige for organisasjonen som eier scopet og organisasjoner som har fÃ¥tt tilgang som konsumenter. Defaulter til public. Tillatte verdier: private, public.  FÃ¸lgende eksempel oppretter en klientintegrasjon mot Maskinporten og definerer scopet innsyn. Den setter HUSLÃ˜S HURTIG TIGER AS og KOSTBAR LEKKER APE AS som godkjente konsumenter av scopet. NÃ¥r registrering er fullfÃ¸rt vil Digdirator opprette Kubernetes-hemmeligheten maskinporten-secret i namespacet tilgangsstyring-main.  apiVersion: nais.io/v1 kind: MaskinportenClient metadata: name: test-client namespace: tilgangsstyring-main spec: clientName: innsikt-secure-deltashare scopes: exposes: - enabled: true name: &quot;innsyn&quot; product: &quot;ProduktomrÃ¥de&quot; consumers: - name: HUSLÃ˜S HURTIG TIGER AS orgno: &quot;987654321&quot; - name: KOSTBAR LEKKER APE AS orgno: &quot;123456789&quot; secretName: maskinporten-secret   ","version":"Next","tagName":"h3"},{"title":"ðŸ”¹ Azureratorâ€‹","type":1,"pageTitle":"Klientregistrering","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering#-azurerator","content":" Azurerator er en Kubernetes-operator utviklet av NAV sitt plattformteam (NAIS) som skal gjÃ¸re det enkelt Ã¥ deklarativt sette opp og vedlikeholde integrasjoner mot Microsoft Entra ID.  ","version":"Next","tagName":"h2"},{"title":"AzureAdApplicationâ€‹","type":1,"pageTitle":"Klientregistrering","url":"/docs/applikasjon-utrulling/tilgangsstyring/klientregistrering#azureadapplication","content":" Azurerator introduserer CRD-en AzureAdApplication, som hÃ¥ndterer opprettelse og vedlikehold av integrasjoner mot Microsoft Entra ID. Registreringer opprettet med Azureator vil fÃ¥ navn basert pÃ¥ hvor de er plassert i et Kubernetes-cluster, i.e. cluster:namespace:name.  spec (object, required) â€“ Spesifikasjon til AzureAdApplication allowAllUsers (bool, required) â€“ Bestemmer om alle brukere i tenanten som Azurerator er konfigurert mot skal fÃ¥ tilgang. claims (object, optional) â€“ Definerer konfigurasjon av claims som inkluderes i tokenene som returneres til Entra ID applikasjonen. groups ([]object, optional) â€“ En liste over Entra ID gruppe ID-er som skal inkluderes i groups-claimet i tokenene utstedt av Entra ID. Dette tildeler ogsÃ¥ grupper til app-registreringen brukt for tilgangskontroll. Kun direkte medlemmer av gruppene fÃ¥r tilgang. id (string, required) â€“ Objekt-ID-en (OID) til en Entra ID-gruppe. replyUrls ([]object, required) â€“ URL-er som applikasjonen godtar som svaradresser etter autentisering. url (string, required) â€“ En godkjent svaradresse (reply URL) for applikasjonen. logoutUrl (string, optional) â€“ URL-en brukere blir omdirigert til nÃ¥r de logger ut av applikasjonen.. preAuthorizedApplications ([]object, optional) â€“ Definerer andre app-registreringer som er forhÃ¥ndsautorisert til Ã¥ fÃ¥ tilgang til denne applikasjonen. Her refereres det til tilsvarende AzureAdApplication. application (string, required) â€“ Navnet pÃ¥ den forhÃ¥ndsgodkjente applikasjonen. namespace (string, required) â€“ Namespacet hvor den forhÃ¥ndsgodkjente applikasjonen befinner seg. cluster (string, required) â€“ Clusteret hvor den forhÃ¥ndsgodkjente applikasjonen befinner seg. permissions (object, optional) â€“ Spesifiserer hvilke claims den forhÃ¥ndsautoriserte applikasjonen har. scopes ([]string, optional) â€“ Liste med egendefinerte tilgangs-scopes tildelt til den forhÃ¥ndsautoriserte appliaksjonen. roles ([]string, optional) â€“ Liste med egendefinerte tilgangs-roller tildelt til den forhÃ¥ndsautoriserte appliaksjonen. secretName (string, required) â€“ Navnet pÃ¥ den resulterende Secret-ressursen som vil bli opprettet. secretKeyPrefix (string, optional) â€“ Et valgfritt brukerdefinert prefiks som brukes pÃ¥ nÃ¸klene i den genererte hemmeligheten, og erstatter standardprefikset (AZURE). secretProtected (bool, optional) â€“ Angir om hemmeligheten skal tilbaketrekkes selv nÃ¥r den ikke er i bruk. singlePageApplication (bool, optional) â€“ Angir om denne Entra ID-applikasjonen skal registreres som en single-page-application for bruk i klient-side-applikasjoner uten tilgang til hemmeligheter.  FÃ¸lgende eksempel oppretter app-registreringen atgcp1-sandbox:tilgangsstyring-main:test-app. Den gir kun tilgang til direkte medlemmer av gruppene med objekt-ID 2720e397-081d-4d9b-852e-0d81f45a304f eller c3c94454-aefc-44f9-9076-58ea47547941. Den forhÃ¥ndsautoriserer ogsÃ¥ Entra ID klienten atgcp1-dev:other-namespace:other-app. NÃ¥r registrering er fullfÃ¸rt vil Azurerator opprette Kubernetes-hemmeligheten entraid-secret i namespacet tilgangsstyring-main.  apiVersion: nais.io/v1 kind: AzureAdApplication metadata: name: test-app namespace: tilgangsstyring-main spec: allowAllUsers: false secretName: entraid-secret claims: groups: - id: 2720e397-081d-4d9b-852e-0d81f45a304f - id: c3c94454-aefc-44f9-9076-58ea47547941 replyUrls: - url: https://test-app.atgcp1-sandbox.kartverket-intern.cloud/oauth2/callback preAuthorizedApplications: - application: other-app namespace: other-namespace cluster: atgcp1-dev  ","version":"Next","tagName":"h3"},{"title":"Test din Ztoperator-AuthPolicy","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/test-authpolicy","content":"","keywords":"","version":"Next"},{"title":"ðŸ“– Eksempelâ€‹","type":1,"pageTitle":"Test din Ztoperator-AuthPolicy","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/test-authpolicy#-eksempel","content":" For Ã¥ illustrere hvordan test-authpolicy-action fungerer, ser vi pÃ¥ et konkret eksempel.  ","version":"Next","tagName":"h2"},{"title":"ðŸ” AuthPolicyâ€‹","type":1,"pageTitle":"Test din Ztoperator-AuthPolicy","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/test-authpolicy#-authpolicy","content":" FÃ¸lgende AuthPolicy tillater uautentiserte forespÃ¸rsler til URL-stien /public og alle under-stier. Samtidig sikrer den at kun autentiserte forespÃ¸rsler med claimet role: admin fÃ¥r tilgang til /admin og alle under-stier. Alle andre forespÃ¸rsler som ikke omfattes av ignoreAuthRules eller authRules mÃ¥ vÃ¦re autentisert.  apiVersion: ztoperator.kartverket.no/v1alpha1 kind: AuthPolicy metadata: name: auth-policy spec: enabled: true ignoreAuthRules: - paths: - /public* authRules: - paths: - /admin* when: - claim: role values: - admin denyRedirect: true audience: some-audience oAuthCredentials: secretRef: oauth-secret clientIDKey: CLIENT_ID_KEY clientSecretKey: CLIENT_SECRET_SECRET autoLogin: enabled: true loginPath: /login logoutPath: /logout redirectPath: /oauth2/callback scopes: - offline_access - openid wellKnownURI: https://login.microsoftonline.com/7f74c8a2-43ce-46b2-b0e8-b6306cba73a3/v2.0/.well-known/openid-configuration selector: matchLabels: app: application   ","version":"Next","tagName":"h3"},{"title":"ðŸš€ test-authpolicy-actionâ€‹","type":1,"pageTitle":"Test din Ztoperator-AuthPolicy","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/test-authpolicy#-test-authpolicy-action","content":" Du kan teste nevnte AuthPolicy direkte i repoet der den er definert (typisk et apps-repo) ved Ã¥ inkludere den i en GitHub Workflow-jobb. FÃ¸r test-authpolicy-action kjÃ¸res, mÃ¥ setup-skip-action vÃ¦re kjÃ¸rt for Ã¥ sette opp det nÃ¸dvendige miljÃ¸et som kreves for Ã¥ gjennomfÃ¸re testene.  name: Test AuthPolicy runs-on: ubuntu-latest steps: - name: Checkout repo uses: actions/checkout@v3 # ðŸš¨ MÃ¥ kjÃ¸res fÃ¸rst ðŸš¨ - name: Setup SKIP uses: kartverket/setup-skip-action@v0.0.1 - name: Test AuthPolicy uses: kartverket/test-authpolicy-action@v0.0.1 with: test: test.yaml authpolicy: authpolicy.yaml   ","version":"Next","tagName":"h3"},{"title":"ðŸ§ª Test-filâ€‹","type":1,"pageTitle":"Test din Ztoperator-AuthPolicy","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/test-authpolicy#-test-fil","content":" test-authpolicy-action har to input: filstien til AuthPolicy-ressursen som skal testes, og filstien til en testfil som beskriver selve testene. Testfilen mÃ¥ fÃ¸lge JSON-skjemaet definert her.  Testfilen bestÃ¥r av et navn (name) og en samling forespÃ¸rsler (requests). Hver forespÃ¸rsel definerer:  Ã‰n eller flere URL-stier.Ã‰n eller flere HTTP-metoder.En forventet respons (expected_response).  I tillegg kan du angi det boolske feltet auth for at forespÃ¸rselen skal autentiseres, dvs. at en gyldig JWT legges ved i headeren Authorization: Bearer &lt;JWT&gt;. Du kan ogsÃ¥ oppgi en liste med claims som skal inkluderes i JWT-en.  FÃ¸lgende er et eksempel pÃ¥ en test-fil som kan brukes til Ã¥ teste AuthPolicy-ressursen ovenfor. Test-filen vil oversettes til HTTP-forespÃ¸rsler i en hurl-fil, og en hurl-test blir kjÃ¸rt og evaluerer forespÃ¸rslene.  Visste du at... Hvis test-authpolicy-action kjÃ¸res i en pull request sÃ¥ vil den legge ved resultatet av hurl-testen som en kommentar. Den vil der vise hurl-testen som ble opprettet pÃ¥ bakgrunn av test-filen. Hvis testen feiler vil den i tillegg vise hvilken HTTP-forespÃ¸rsel i hurl-filen som feilet, og peke pÃ¥ hvilken forespÃ¸rsel i testen denne stammer fra.  name: Test AuthPolicy requests: # Verifiser at stien /public og alle under-stier er Ã¥pne - paths: - /public - /public123 expected_response: allowed # Verifiser at stien /admin og alle under-stier blir blokkert uten gyldig JWT - paths: - /admin - /admin123 expected_response: denied # Verifiser at stien /admin og alle under-stier ikke slipper gjennom med kun autentisert JWT (krever ogsÃ¥ claimet role: admin) - paths: - /admin - /admin123 auth: true expected_response: denied # Verifiser at stien /admin og alle under-stier er Ã¥pne nÃ¥r autentisert JWT med claimet role: admin legges ved - paths: - /admin - /admin123 auth: true claims: - claim: role values: - admin expected_response: allowed # Verifiser at stier som ikke er nevnt i AuthPolicy-ressursen ikke er Ã¥pne og omdirigerer til innlogging - paths: - /something expected_response: login_redirect # Verifiser at stier som ikke er nevnt i AuthPolicy-ressursen krever autentisert JWT - paths: - /something auth: true expected_response: allowed  ","version":"Next","tagName":"h3"},{"title":"Ztoperator API Reference","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs","content":"","keywords":"","version":"Next"},{"title":"AuthPolicyâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicy","content":" AuthPolicy is the Schema for the authpolicies API.  Name\tType\tDescription\tRequiredapiVersion\tstring\tztoperator.kartverket.no/v1alpha1\ttrue kind\tstring\tAuthPolicy\ttrue metadata\tobject\tRefer to the Kubernetes API documentation for the fields of the metadata field.\ttrue spec\tobject AuthPolicySpec defines the desired state of AuthPolicy. false status\tobject AuthPolicyStatus defines the observed state of AuthPolicy. false  ","version":"Next","tagName":"h2"},{"title":"AuthPolicy.specâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspec","content":" â†© Parent  AuthPolicySpec defines the desired state of AuthPolicy.  Name\tType\tDescription\tRequiredenabled\tboolean Whether to enable JWT validation. If enabled, incoming JWTs will be validated against the issuer specified in the app registration and the generated audience. true selector\tobject The Selector specifies which workload the defined auth policy should be applied to. true wellKnownURI\tstring WellKnownURI specifies the URi to the identity provider's discovery document (also known as well-known endpoint). true acceptedResources\t[]string AcceptedResources is used as a validation field following RFC8707. It defines accepted audience resource indicators in the JWT token. Each resource indicator must be a valid URI, and the indicator must be present as the aud claim in the JWT token. false audience\t[]string Audience defines the accepted audience (aud) values in the JWT. At least one of the listed audience values must be present in the token's aud claim for validation to succeed. false authRules\t[]object AuthRules defines rules for allowing HTTP requests based on conditions that must be met based on JWT claims. API endpoints not covered by AuthRules and/or IgnoreAuthRules requires an authenticated JWT by default. false autoLogin\tobject AutoLogin specifies the required configuration needed to log in users. false forwardJwt\tboolean If set to true, the original token will be kept for the upstream request. Defaults to true. false ignoreAuthRules\t[]object IgnoreAuthRules defines request matchers for HTTP requests that do not require JWT authentication. API endpoints not covered by AuthRules or IgnoreAuthRules require an authenticated JWT by default. false oAuthCredentials\tobject OAuthCredentials specifies a reference to a kubernetes secret in the same namespace holding OAuth credentials used for authentication. false outputClaimToHeaders\t[]object OutputClaimsToHeaders specifies a list of operations to copy the claim to HTTP headers on a successfully verified token. The header specified in each operation in the list must be unique. Nested claims of type string/int/bool is supported as well. If the claim is an object or array, it will be added to the header as a base64-encoded JSON string. false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.selectorâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecselector","content":" â†© Parent  The Selector specifies which workload the defined auth policy should be applied to.  Name\tType\tDescription\tRequiredmatchLabels\tmap[string]string One or more labels that indicate a specific set of pods/VMs on which a policy should be applied. The scope of label search is restricted to the configuration namespace in which the resource is present. Validations: self.all(key, !key.contains('*')): wildcard not allowed in label key matchself.all(key, key.size() != 0): key must not be empty false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.authRules[index]â€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecauthrulesindex","content":" â†© Parent  RequestAuthRule defines a rule for controlling access to HTTP requests using JWT authentication.  Name\tType\tDescription\tRequiredpaths\t[]string Paths specify a set of URI paths that this rule applies to. Each path must be a valid URI path, starting with '/' and not ending with '/'. true denyRedirect\tboolean DenyRedirect specifies whether a denied request should trigger auto-login (if configured) or not when it is denied due to missing or invalid authentication. Defaults to false, meaning auto-login will be triggered (if configured). false methods\t[]string Methods specifies HTTP methods that applies for the defined paths. If omitted, all methods are permitted. Allowed methods: GETPOSTPUTPATCHDELETEHEADOPTIONSTRACECONNECT false when\t[]object When defines additional conditions based on JWT claims that must be met. The request is permitted if at least one of the specified conditions is satisfied. false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.authRules[index].when[index]â€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecauthrulesindexwhenindex","content":" â†© Parent  Condition represents a rule that evaluates JWT claims to determine access control.  This type allows defining conditions that check whether a specific claim in the JWT token contains one of the expected values.  If multiple conditions are specified, all must be met (AND logic) for the request to be allowed.  Name\tType\tDescription\tRequiredclaim\tstring Claim specifies the name of the JWT claim to check. true values\t[]string Values specifies a list of allowed values for the claim. If the claim in the JWT contains any of these values (OR logic), the condition is met. true  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.autoLoginâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecautologin","content":" â†© Parent  AutoLogin specifies the required configuration needed to log in users.  Name\tType\tDescription\tRequiredenabled\tboolean Whether to enable auto login. If enabled, users accessing authenticated endpoints will be redirected to log in towards the configured identity provider. true logoutPath\tstring LogoutPath specifies which URI to redirect the user to when signing out. This will end the session for the application, but not end the session towards the configured identity provider. This feature will hopefully soon be available in later releases of Istio, ref. envoy/envoyproxy. true redirectPath\tstring RedirectPath specifies which path to redirect the user to after completing the OIDC flow. true scopes\t[]string Scopes specifies the OAuth2 scopes used during authorization code flow. true loginPath\tstring LoginPath specifies a list of URI paths that should trigger the auto-login behavior. When a request matches any of these paths, the user will be redirected to log in if not already authenticated. false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.ignoreAuthRules[index]â€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecignoreauthrulesindex","content":" â†© Parent  RequestMatcher defines paths and methods to match incoming HTTP requests.  Name\tType\tDescription\tRequiredpaths\t[]string Paths specify a set of URI paths that this rule applies to. Each path must be a valid URI path, starting with '/' and not ending with '/'. true methods\t[]string Methods specifies HTTP methods that applies for the defined paths. If omitted, all methods are permitted. Allowed methods: GETPOSTPUTPATCHDELETEHEADOPTIONSTRACECONNECT false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.oAuthCredentialsâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecoauthcredentials","content":" â†© Parent  OAuthCredentials specifies a reference to a kubernetes secret in the same namespace holding OAuth credentials used for authentication.  Name\tType\tDescription\tRequiredclientIDKey\tstring ClientIDKey specifies the data key to access the client ID. true clientSecretKey\tstring ClientSecretKey specifies the data key to access the client secret. true secretRef\tstring SecretRef specifies the name of the kubernetes secret. true  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.spec.outputClaimToHeaders[index]â€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicyspecoutputclaimtoheadersindex","content":" â†© Parent  ClaimToHeader specifies a list of operations to copy the claim to HTTP headers on a successfully verified token. The header specified in each operation in the list must be unique. Nested claims of type string/int/bool is supported as well.  Name\tType\tDescription\tRequiredclaim\tstring Claim specifies the name of the claim in the JWT token that will be copied to the header. true header\tstring Header specifies the name of the HTTP header to which the claim value will be copied. true  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.statusâ€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicystatus","content":" â†© Parent  AuthPolicyStatus defines the observed state of AuthPolicy.  Name\tType\tDescription\tRequiredready\tboolean true conditions\t[]object false message\tstring false observedGeneration\tinteger Format: int64 false phase\tstring false  ","version":"Next","tagName":"h3"},{"title":"AuthPolicy.status.conditions[index]â€‹","type":1,"pageTitle":"Ztoperator API Reference","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-api-docs#authpolicystatusconditionsindex","content":" â†© Parent  Condition contains details for one aspect of the current state of this API Resource.  Name\tType\tDescription\tRequiredlastTransitionTime\tstring lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. Format: date-time true message\tstring message is a human readable message indicating details about the transition. This may be an empty string. true reason\tstring reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. true status\tenum status of the condition, one of True, False, Unknown. Enum: True, False, Unknown true type\tstring type of condition in CamelCase or in foo.example.com/CamelCase. Many .condition.type values are consistent across resources like Available, but because arbitrary conditions can be useful (see .node.status.conditions), the ability to deconflict is important. The regex it matches is (dns1123SubdomainFmt/)?(qualifiedNameFmt) true observedGeneration\tinteger observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. Format: int64 Minimum: 0 false ","version":"Next","tagName":"h3"},{"title":"ðŸ“… Jobber pÃ¥ SKIP","type":0,"sectionRef":"#","url":"/docs/jobber-skip","content":"","keywords":"","version":"Next"},{"title":"Konfigurere en SKIPJobâ€‹","type":1,"pageTitle":"ðŸ“… Jobber pÃ¥ SKIP","url":"/docs/jobber-skip#konfigurere-en-skipjob","content":" En SKIPJob konfigureres i stor grad likt som applikasjoner. Inbound access policy og port skal derimot ikke konfigureres for jobber. Mer info om vanlig konfiguration av applikasjoner finner du her.  ","version":"Next","tagName":"h2"},{"title":"One-off jobbâ€‹","type":1,"pageTitle":"ðŸ“… Jobber pÃ¥ SKIP","url":"/docs/jobber-skip#one-off-jobb","content":" apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: min-jobb spec: container: image: &quot;ghcr.io/kartverket/min-jobb:latest&quot;   Denne vil kjÃ¸re docker imaget min-jobb:latest en gang. Den vil kjÃ¸re hver gang den blir syncet i ArgoCD.  ","version":"Next","tagName":"h3"},{"title":"Cron jobb (periodisk)â€‹","type":1,"pageTitle":"ðŸ“… Jobber pÃ¥ SKIP","url":"/docs/jobber-skip#cron-jobb-periodisk","content":" apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: min-cron-jobb spec: container: image: &quot;ghcr.io/kartverket/min-jobb:latest&quot; cron: schedule: &quot;0 * * * *&quot;   Denne vil kjÃ¸re docker imaget min-jobb:latest Ã©n gang hver time. For Ã¥ finne et passende cron-uttrykk anbefales Crontab Guru.NB: Alle jobber vil kjÃ¸re i UTC-tidssonen, med mindre feltet timeZone er spesifisert.  ","version":"Next","tagName":"h3"},{"title":"Kompleks jobbâ€‹","type":1,"pageTitle":"ðŸ“… Jobber pÃ¥ SKIP","url":"/docs/jobber-skip#kompleks-jobb","content":" I dette eksempelet konfigureres en jobb som har tilgang til Ã¥ aksessere ressurser i GCP (f.eks. Blob Storage) og som er avhengig av Ã¥ prate med applikasjonen min-applikasjon i samme namespace. Jobben kjÃ¸rer ukedager (mandag-fredag) kl 21:30 i gjeldende tidssone for Norge.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: SKIPJob metadata: name: min-cron-jobb spec: cron: schedule: &quot;30 21 * * 1-5&quot; timeZone: &quot;Europe/Oslo&quot; container: image: &quot;ghcr.io/kartverket/min-jobb:latest&quot; gcp: auth: serviceAccount: &quot;min-jobb@mitt-prosjekt.iam.gserviceaccount.com&quot; accessPolicy: outbound: rules: - application: &quot;min-applikasjon&quot; env: - name: MIN_ENV_VAR value: &quot;min-env-value&quot; envFrom: - secret: &quot;secret-navn&quot;   ","version":"Next","tagName":"h3"},{"title":"Trigge en jobbâ€‹","type":1,"pageTitle":"ðŸ“… Jobber pÃ¥ SKIP","url":"/docs/jobber-skip#trigge-en-jobb","content":" Spesielt for one-off jobber er det aktuelt Ã¥ trigge jobben manuelt uten at du har gjort endringer. Vi har ingen pen mÃ¥te Ã¥ trigge jobber pÃ¥ ennÃ¥, men du kan likevel trigge en jobb ved Ã¥ gÃ¥ inn i argo og slette Job ressursen (ikke SKIPJob).Trykk pÃ¥ &quot;Delete&quot;, velg &quot;Foreground Delete&quot; (default) og trykk &quot;Ok&quot; sÃ¥ vil Job ressursen opprettes pÃ¥ nytt og jobben kjÃ¸res.  For Ã¥ trigge cron jobber manuelt kan du trykke pÃ¥ kebab meny knappen pÃ¥ &quot;cronjob&quot; ressursen og velge &quot;Create Job&quot;.  Ved Ã¥ sette .spec.job.cron.suspend = true kan du hindre en cron jobb fra Ã¥ kjÃ¸re periodisk og den kan dermed trigges manuelt via kebab meny. SKIPJoben vil da oppfÃ¸re seg som en one-off jobb, men den vil ikke kjÃ¸re nÃ¥r den synces. ","version":"Next","tagName":"h2"},{"title":"ðŸ’¡ Kom i gang","type":0,"sectionRef":"#","url":"/docs/kom-i-gang","content":"","keywords":"","version":"Next"},{"title":"Velkomstord og introduksjonâ€‹","type":1,"pageTitle":"ðŸ’¡ Kom i gang","url":"/docs/kom-i-gang#velkomstord-og-introduksjon","content":" Gratulerer og velkommen! Du har nÃ¥ begynt reisen inn mot vÃ¥r fantastiske infrastrukturplattform SKIP og de omliggende systemer.  Under finner du en presentasjon som gir en introduksjon til SKIP. Presentasjonen er laget av Eline Henriksen, som var en av utviklerne bak SKIP. Thomas Berg har nÃ¥ overtatt vedlikeholdet av den. Trykk pÃ¥ pilene for Ã¥ gÃ¥ gjennom presentasjonen.   ","version":"Next","tagName":"h2"},{"title":"Eksempeloppsett av Ztoperator","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example","content":"","keywords":"","version":"Next"},{"title":"ðŸ”¹ AzureAdApplicationâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#-azureadapplication","content":" FÃ¸r man gÃ¥r i gang med Ã¥ sette opp en Ztoperator-AuthPolicy mÃ¥ man ha en klienregistrering opprettet hos en OAuth 2.0 identitetstilbyder. Ettersom demo-app er ment for intern bruk av Kartverket-ansatte, sÃ¥ er Microsoft Entra ID en passende identitetstilbyder. En AzureAdApplication kan brukes for Ã¥ opprette klientregistreringen, og fÃ¸lgende manifest oppretter en. Den er konfigurert til Ã¥ tillate alle brukere innenfor Kartverket's Entra ID tenant, og har en redirect-url som peker til applikasjonen sin konfiguererte redirect-url. Dette er noe vi senere konfigurerer i Ztoperator-AuthPolicyen, og Ztoperator hÃ¥ndterer dette endepunktet for oss. Etter Ã¥ ha opprettet en klientregistrering i Microsoft Entra ID oppretter Azurerator ogsÃ¥ en Kubernetes-hemmelighet kalt entraid-secret. Klientregistreringen kan ses i Azure Portal.  note Redirect-url er noe demo-app ikke trenger Ã¥ forholde seg til. Ztoperator-AuthPolicy konfigures med en redirect-url nÃ¥r man konfigurerer innlogging av brukere, og hÃ¥ndterer callbacks i authorization code flow.  azureadapplication.yaml apiVersion: nais.io/v1 kind: AzureAdApplication metadata: name: entraid-reg namespace: ztoperator-demo spec: claims: groups: - id: a6578085-e0ee-4168-bf97-1b3026f6f3bd # Kartverket@kartverket.no replyUrls: - url: https://demo-app.atgcp1-sandbox.kartverket.cloud/oauth2/callback secretName: entraid-secret   Resulterende hemmelighet opprettet av Azurerator apiVersion: v1 kind: Secret metadata: name: entraid-secret namespace: ztoperator-demo type: Opaque data: AZURE_APP_CERTIFICATE_KEY_ID: ++++++++ AZURE_APP_CLIENT_ID: ++++++++ AZURE_APP_CLIENT_SECRET: ++++++++ AZURE_APP_JWK: ++++++++ AZURE_APP_JWKS: ++++++++ AZURE_APP_NEXT_CERTIFICATE_KEY_ID: ++++++++ AZURE_APP_NEXT_CLIENT_SECRET: ++++++++ AZURE_APP_NEXT_JWK: ++++++++ AZURE_APP_NEXT_PASSWORD_KEY_ID: ++++++++ AZURE_APP_PASSWORD_KEY_ID: ++++++++ AZURE_APP_PRE_AUTHORIZED_APPS: ++++++++ AZURE_APP_TENANT_ID: ++++++++ AZURE_APP_WELL_KNOWN_URL: ++++++++ AZURE_OPENID_CONFIG_ISSUER: ++++++++ AZURE_OPENID_CONFIG_JWKS_URI: ++++++++ AZURE_OPENID_CONFIG_TOKEN_ENDPOINT: ++++++++   ","version":"Next","tagName":"h2"},{"title":"ðŸ¤– Skiperator-Applicationâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#-skiperator-application","content":" demo-app er bygget til et Docker-image og lastet opp pÃ¥ GitHub Container Registry med fÃ¸lgende image-url: ghcr.io/kartverket/skip-tilgangsstyring-demo. Den kan da deployes pÃ¥ SKIP med fÃ¸lgende manifest og nÃ¥s pÃ¥ https://demo-app.atgcp1-sandbox.kartverket.cloud.  Den uthevede delen av koden er viktig for at innlogging av sluttbrukere skal fungere. Hvorfor denne konfigurasjonen er viktig etterlates som en oppgave for leseren. Det brukeren mÃ¥ forholde seg til er hvilket secretName det skal refereres til. Dette mÃ¥ matche en Kuberenetes-hemmelighet som Ztoperator oppretter som har navneformatet &lt;NAVN PÃ… AUTHPOLICY&gt;-envoy-secret. Ettersom demo-app sin Ztoperator-AuthPolicy heter auth-policy, blir det korrekt med &quot;secretName&quot;: &quot;auth-policy-envoy-secret&quot;.  demo-app.yaml apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: demo-app namespace: ztoperator-demo spec: podSettings: annotations: sidecar.istio.io/userVolume: '[ { &quot;name&quot;: &quot;istio-oauth2&quot;, &quot;secret&quot;: { &quot;secretName&quot;: &quot;auth-policy-envoy-secret&quot; # ðŸ‘ˆ MÃ¥ matche &lt;NAVN PÃ… AUTHPOLICY&gt;-envoy-secret } } ]' sidecar.istio.io/userVolumeMount: '[ { &quot;name&quot;: &quot;istio-oauth2&quot;, &quot;mountPath&quot;: &quot;/etc/istio/config&quot;, &quot;readonly&quot;: true } ]' image: ghcr.io/kartverket/skip-tilgangsstyring-demo@sha256:cde1805d4e87b99a6d8d73fd6ed6666eaef1691a598f0377d3a716366cc4c9e8 port: 5000 ingresses: - demo-app.atgcp1-sandbox.kartverket.cloud   ","version":"Next","tagName":"h2"},{"title":"â›”ï¸ Ztoperator-AuthPolicyâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#ï¸-ztoperator-authpolicy","content":" Vi har nÃ¥ registrert en klient hos Microsoft Entra ID ved hjelp av Azurerator, og spunnet opp demo-appsom en Skiperator-Application. Det siste steget er nÃ¥ Ã¥ beskytte applikasjonen med en Ztoperator-AuthPolicy. FÃ¸lgende manifest beskytter demo-app og hÃ¥ndterer innlogging av brukere opp mot Microsoft Entra ID. Under gÃ¥r vi gjennom hvordan og hvorfor vi har konfigurert Ztoperator-AuthPolicy som vi har gjort.  auth-policy.yaml apiVersion: ztoperator.kartverket.no/v1alpha1 kind: AuthPolicy metadata: name: auth-policy namespace: ztoperator-demo spec: enabled: true selector: matchLabels: app: demo-app wellKnownURI: https://login.microsoftonline.com/7f74c8a2-43ce-46b2-b0e8-b6306cba73a3/v2.0/.well-known/openid-configuration audience: - dcc29452-1fbc-4805-aeb9-cdb8f4e62147 ignoreAuthRules: - paths: - /* authRules: - paths: - /api/beskyttet* methods: - POST denyRedirect: true - paths: - /beskyttet autoLogin: enabled: true loginPath: /login logoutPath: /logout redirectPath: /oauth2/callback scopes: - dcc29452-1fbc-4805-aeb9-cdb8f4e62147/.default oAuthCredentials: clientIDKey: AZURE_APP_CLIENT_ID clientSecretKey: AZURE_APP_CLIENT_SECRET secretRef: entraid-secret outputClaimToHeaders: - claim: preferred_username header: x-email - claim: name header: x-name   ","version":"Next","tagName":"h2"},{"title":"spec.enabledâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specenabled","content":" spec.enabled lar deg toggle om tilgangsstyring skal vÃ¦re aktivert eller ikke.  ","version":"Next","tagName":"h3"},{"title":"spec.selectorâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specselector","content":" spec.selector spesifiserer hvilke pod-er som skal beskyttes. NÃ¥r man deployer en applikasjon med Skiperator sÃ¥ vil alle pod-er fÃ¥ labelen app: &lt;NAVN PÃ… SKIPERTOR-APPLICATION&gt;.  ","version":"Next","tagName":"h3"},{"title":"spec.wellKnownURIâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specwellknownuri","content":" spec.wellKnownURI trengs for Ã¥ utfÃ¸re OpenID Connect Discovery og hente ut relevant informasjon om identitetstilbyderren brukt under autentisering. Det er her man knytter Ztoperator-AuthPolicy til en identitetstilbyder.  ","version":"Next","tagName":"h3"},{"title":"spec.audienceâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specaudience","content":" spec.audience spesifiserer tiltenkt mottaker av aksess-tokenet. Dette er typisk en klient-ID eller en annen unik identifikator knyttet til klientregistreringen utfÃ¸rt tidligere. Dette feltet et viktig Ã¥ inkludere for Ã¥ skille klientregistreringer hos en identitetstilbyder fra andre. spec.audience sikrer at kun din klientregistrering kan bruke tokenet til Ã¥ aksessere applikasjonens beskyttede endepunkter.  ","version":"Next","tagName":"h3"},{"title":"spec.ignoreAuthRulesâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specignoreauthrules","content":" I utgangspunktet er alle endepunkter mot demo-app Ã¥pne, noe som angis med paths: [/*]. NÃ¥r HTTP-verb ikke er spesifisert, gjelder regelen for alle metoder. Dersom et endepunkt ikke er eksplisitt definert â€“ eller det finnes overlapp mellom spec.ignoreAuthRules og spec.authRules â€“ vil Ztoperator alltid falle tilbake til Ã¥ beskytte endepunktet.  ","version":"Next","tagName":"h3"},{"title":"spec.authRulesâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specauthrules","content":" POST mot endpunktene /api/beskyttet* (/api/beskyttet og alle under-stier) skal vÃ¦re beskyttet. Ettersom kall mot /api/beskyttet* gjÃ¸res av en Single Page Application i en AJAX-request, har man ikke muligheten til Ã¥ fÃ¸lge 302 Redirect og logge inn brukeren automatisk. For Ã¥ lÃ¸se dette kan man spesifisere denyRedirect: true for Ã¥ forhindre at Ztoperator returnerer en 302 Redirect (den sender da en 401 Unauthorized i stedet), og heller omdirigere brukeren selv i frontend-koden til den konfigurerte innloggingsstien (/login i dette tilfellet). Stien /beskyttet skal ogsÃ¥ beskyttes, og ettersom det ikke spesifiseres denyRedirect: true vil uautentiserte brukere automatisk bli omdirigert til innlogging mot Microsoft Entra ID.  ","version":"Next","tagName":"h3"},{"title":"spec.autoLoginâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specautologin","content":" spec.autoLogin lar deg konfigurere innlogging mot identitetstilbyderen. Innlogging vil bli gjort automatisk hvis brukere aksesserer beskyttede endepunkt uten en sesjon (med mindre spec.authRules[].denyRedirect er satt til true). I tillegg konfigureres det en dedikert innloggingssti som brukere kan navigeres til for Ã¥ starte en inlogget sesjon.  spec.autoLogin.enabled lar deg toggle om innlogging skal vÃ¦re aktivert eller ikke.spec.autoLogin.loginPath spesifiserer hvilken sti man skal aksessere for Ã¥ starte en innlogget sesjon. Etter vellykket innlogging vil en forespÃ¸rsel sendes til den konfigurerte innloggingsstien i applikasjonen din, og det er da opp til deg Ã¥ hÃ¥ndtere hva som skal skje.spec.autoLogin.logoutPath spesifiserer hvilken sti man skal aksessere for Ã¥ logge ut brukeren lokalt og opp mot den konfigurerte identitetstilbyderen (RP-initiated logout). Etter vellykket utlogging vil brukeren bli omdirigert til nettsiden sin rotsti (dvs. https://&lt;HOST&gt;/).spec.autoLogin.redirectPath spesifiserer omdirigeringssti brukt under Authorization Code Flow. Dette er en sti som du ikke tregner Ã¥ hÃ¥ndtere i applikasjonskoden din, men den mÃ¥ samsvare med en av de konfigurerte omdirigeringsstiene i klientregistreringen din.spec.autoLogin.scopes spesifiserer hvilke scopes som skal brukes i under Authorization Code Flow. I dette eksempelet er det spesifisert som &lt;CLIENT ID&gt;/.default, som er et scope Microsoft Entra ID tilbyr som implisitt inneholder alle tilgjengelige scopes for klientregistreringen.  warning Ztoperator-AuthPolicy benytter seg av cookies for Ã¥ lagre innlogget sesjon i nettleseren. OIDC Single Logout (SLO) benytter seg av iframe for Ã¥ logge brukeren ut av alle nettstedene som brukeren har en aktiv SSO-sesjon hos. Ettersom cookies som Ztoperator-AuthPolicy setter er HTTP-only sÃ¥ vil de ikke kunne aksesseres i en iframe, og SLO er derfor ikke stÃ¸ttet av Ztoperator-AuthPolicy.  ","version":"Next","tagName":"h3"},{"title":"spec.oAuthCredentialsâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specoauthcredentials","content":" spec.oAuthCredentials spesifiserer hvilken klient-ID og klient-hemmelighet som skal brukes under innlogging av brukere.  spec.oAuthCredentials.secretRef spesifiserer hvilken Kubernetes-hemmelighet som har hemmelightene.spec.oAuthCredentials.clientIDKey spesifiserer hvilken data-nÃ¸kkel i Kuberenetes-hemmeligheten som har klient-IDen.spec.oAuthCredentials.clientSecretKey spesifiserer hvilken data-nÃ¸kkel i Kuberenetes-hemmeligheten som har klient-hemmeligheten.  ","version":"Next","tagName":"h3"},{"title":"spec.outputClaimToHeadersâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#specoutputclaimtoheaders","content":" spec.outputClaimToHeaders spesifiserer hvilke claims i access_token som skal sendes som HTTP-headers til applikasjonen.  ","version":"Next","tagName":"h3"},{"title":"ðŸ‘€ Lett Ã¥ overseâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#-lett-Ã¥-overse","content":" Selv om Ztoperator-AuthPolicy skal gjÃ¸re det lettere Ã¥ sikre appllikasjonen sin med OAuth 2.0 og OIDC, sÃ¥ er det fortsatt enkelte ting man lett kan overse.  ","version":"Next","tagName":"h2"},{"title":"Audience-begrensing i ID-porten og Maksinportenâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#audience-begrensing-i-id-porten-og-maksinporten","content":" BÃ¥de ID-porten og Maksinporten benytter seg av audience-begrensing, en mekanisme basert pÃ¥ RFC 8707 Resource Indicators for Oauth2, som motvirker at tokens kan misbrukes mot andre APIer enn de som er tiltenkt. En konsekvens av dette er at det er klienten sitt ansvar Ã¥ be om et audience-begrenset token. Dette er stÃ¸ttet i Ztoperator-AuthPolicy med feltet spec.acceptedResources. Dette feltet spesifiserer hvilke APIer tokenet skal kunne brukes mot.  ","version":"Next","tagName":"h3"},{"title":"Client authenticationâ€‹","type":1,"pageTitle":"Eksempeloppsett av Ztoperator","url":"/docs/applikasjon-utrulling/tilgangsstyring/ztoperator/ztoperator-example#client-authentication","content":" Per nÃ¥ stÃ¸tter Ztoperator kun Ã¥ autentisere klienter ved bruk av client_secret_post. Selve klient-autentiseringen gjÃ¸res av Ztoperator, men det er viktig at det er konfigurert i klientregistreringen mot identitetstilbyderen at man bruker client_secret_post.  caution Klientregistrering med Digdirator antar at klienten kun benytter seg av private_key_jwt som klient-autentiseringsmetode, noe som gjÃ¸r at klientintegrasjoner satt opp med Digdirator per nÃ¥ ikke er kompatibelt med Ztoperator-AuthPolicy. ","version":"Next","tagName":"h3"},{"title":"Kompetanse for bruk av SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/kompetanse","content":"","keywords":"","version":"Next"},{"title":"LÃ¦ringsressurserâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#lÃ¦ringsressurser","content":" Vi lenker til Pluralsight-kurs der det er relevant, men vÃ¦r oppmerksom pÃ¥ at ikke alt innhold er like viktig. Mange kurs pÃ¥ Pluralsight er rettet mot administrasjon fremfor praktisk bruk.  I noen tilfeller har vi allerede god brukerinformasjon i dokumentasjonen, mens andre ganger vil det vÃ¦re nÃ¸dvendig Ã¥ konsultere offisiell dokumentasjon. Vi oppfordrer deg til Ã¥ finne egne ressurser for Ã¥ supplere kunnskapen. Hvis du finner noe ekstra relevant, kan du gjerne gi beskjed til SKIP-teamet sÃ¥ vi kan legge inn lenke her.  info Tidligere hadde Kartverket lisenser til Pluralsight pÃ¥ rotasjon, men dette er det nÃ¥ slutt pÃ¥. Du kan fortsatt bruke Pluralsight, men du mÃ¥ nÃ¥ kjÃ¸pe lisens selv og utgiftsfÃ¸re den etter avklaring med leder.  ","version":"Next","tagName":"h2"},{"title":"Grunnkompetanse for Ã¥ ta i bruk dev-miljÃ¸etâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#grunnkompetanse-for-Ã¥-ta-i-bruk-dev-miljÃ¸et","content":" For Ã¥ komme i gang med utvikling i SKIP-plattformen er det viktig Ã¥ ha grunnleggende forstÃ¥else for fÃ¸lgende temaer:  ","version":"Next","tagName":"h2"},{"title":"Kubernetes og orkestreringâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#kubernetes-og-orkestrering","content":" Kubernetes - Container-orkestrering og deployment (Pluralsight | Offisiell Intro)Argo CD - GitOps og continuous delivery (Pluralsight | Offisiell Intro)Skiperator - VÃ¥r egen Kubernetes-operator  ","version":"Next","tagName":"h3"},{"title":"Google Cloud Platform (GCP)â€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#google-cloud-platform-gcp","content":" Det finnes mange GCP-kurs pÃ¥ Pluralsight  GCP Secrets - HÃ¥ndtering av hemmeligheter (GCP Docs)Service Accounts - Tilgangsstyring for tjenesterIAM &amp; Permissions - Rettigheter og tilganger (IAM Docs | WIF Docs)CloudSQL - Relasjonell database  ","version":"Next","tagName":"h3"},{"title":"Infrastruktur og containereâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#infrastruktur-og-containere","content":" Terraform - Infrastructure as Code (Pluralsight)Helm - Kubernetes package manager (Offisiell Intro)Docker - Containerteknologi (Offisiell Intro)  ","version":"Next","tagName":"h3"},{"title":"CI/CD og GitHub Actionsâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#cicd-og-github-actions","content":" GitHub Actions - Automatisering og deployment, CI/CD  ","version":"Next","tagName":"h3"},{"title":"Ekstra kompetanse for Ã¥ ta i bruk prod-miljÃ¸etâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#ekstra-kompetanse-for-Ã¥-ta-i-bruk-prod-miljÃ¸et","content":" Prodklare apper pÃ¥ SKIP forventes Ã¥ implementere grunnleggende sikkerhet og overvÃ¥kning.  ","version":"Next","tagName":"h2"},{"title":"Sikkerhet og eksponeringâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#sikkerhet-og-eksponering","content":" Internetteksponering - Sjekkliste og retningslinjer for ekstern tilgangSikkerhet - Sikkerhetsprinsipper og best practices Network Policies Docs  ","version":"Next","tagName":"h3"},{"title":"OvervÃ¥kning og driftâ€‹","type":1,"pageTitle":"Kompetanse for bruk av SKIP","url":"/docs/kom-i-gang/kompetanse#overvÃ¥kning-og-drift","content":" Monitoring - Observabilitet og overvÃ¥kningAlarmer - Konfigurering av alarmer og varslingKostnadsoversikt - Kostnadsstyring og budsjettering ","version":"Next","tagName":"h3"},{"title":"Oversikt over tjenester SKIP tilbyr","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr","content":"","keywords":"","version":"Next"},{"title":"FormÃ¥l med dokumentâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#formÃ¥l-med-dokument","content":" Dette dokumentet er ment som en teknisk introduksjon til nye utviklere pÃ¥ SKIP-plattformen. I stedet for Ã¥ skrive en full manual om alle de tjenestene og programvarene som SKIP tilbyr og er basert pÃ¥, har vi skrevet litt kort om hver tjeneste du som utvikler kan benytte deg av, og hvordan den ser ut under panseret. Hvis det finnes mer dokumentasjon fra SKIP om tjenesten vil det vÃ¦re linket til her, men hvis du Ã¸nsker et skikkelig dypdykk vil det som regel vÃ¦re like greit Ã¥ sÃ¸ke pÃ¥ nettet etter mer dokumentasjon - det er ikke noe vi har som ambisjon Ã¥ produsere selv.  ","version":"Next","tagName":"h2"},{"title":"GKE Enterprise / Anthosâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#gke-enterprise--anthos","content":" GKE Enterprise er Googles hybridplatformslÃ¸sning for Ã¥ kunne kjÃ¸re et Kubernetes cluster on-premise, men likevel vÃ¦re administrert via et sky-interface. GKE Enterprise fÃ¸lger med en rekke verktÃ¸y som gjÃ¸r det enkelt for brukere Ã¥ fÃ¥ innsyn i egne applikasjoner, hÃ¥ndheve policyer som skal virke pÃ¥ tvers av multisky-implementasjoner og gir oss mulighet til Ã¥ integrere sikkerhet gjennom en &quot;develop-build-run cycle&quot;.  ","version":"Next","tagName":"h2"},{"title":"Logging, metrikker, tracing og alarmerâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#logging-metrikker-tracing-og-alarmer","content":" SKIP tilbyr innsyn i applikasjoners metrikker og logger ved hjelp av Grafana. Dette kan nÃ¥s pÃ¥ https://monitoring.kartverket.cloud .  ","version":"Next","tagName":"h2"},{"title":"Grafanaâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#grafana","content":" Grafana Loki er et logglagringsverktÃ¸y som brukes som datakilde for Grafana.  Grafana Mimir lagrer metrikker fra appliasjoner, og brukes som datakilde for Grafana.  Grafana Tempo lagrer tracing for applikasjoner, og brukes som datakilde for Grafana  Brukes for Ã¥ sende ut varslinger basert pÃ¥ data i grafana.  ","version":"Next","tagName":"h3"},{"title":"Google Secret Managerâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#google-secret-manager","content":" For hemmelighetshÃ¥ndtering anbefaler vi bruk av Google Secret Manager (GSM). Her har vi solid adgangskontroll og kan enkelt hente hemmeligheter bÃ¥de i build time og run time til applikasjoner vi kjÃ¸rer i Kubernetes.  I GSM opprettes hemmeligheter per prosjekt, og man kan adgangskontrollere bÃ¥de for et helt prosjekt og for individuelle hemmeligheter. Hemmeligheter kan versjoneres og rulleres automatisk.  Ved hjelp av et system kalt External Secrets er det enkelt Ã¥ hente disse hemmelighetene til build time. Se Hente hemmeligheter fra hemmelighetshvelv.  For Ã¥ hente hemmeligheter fra GSM under run time, se Autentisering mot GCP fra Applikasjon .  ","version":"Next","tagName":"h3"},{"title":"GitHubâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#github","content":" GitHub er en skybasert git-repository-tjeneste som vi bruker til Ã¥ lagre kildekoden til Kartverkets prosjekter. Med GitHub fÃ¥r vi ogsÃ¥ mye annet ogsÃ¥ som kontinuerlig integrasjon, kodescanning.  ","version":"Next","tagName":"h3"},{"title":"Objektlagringâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#objektlagring","content":" SKIP tilbyr flere objektlagringstjenester som blant annet gir deg mulighet Ã¥ lagre filer i sky eller on-prem.  For Ã¥ lagre filer i sky anbefaler vi Ã¥ benytte Google cloud storage . Dette er en lagringstjeneste som fÃ¸lger med Google Cloud Platform. Her kan du f. eks provisjonere bÃ¸tter via terraform, og laste opp filer til denne bÃ¸tten via en applikasjon pÃ¥ et Kubernetes cluster. Se Autentisering mot GCP fra Applikasjonfor Ã¥ koble seg til GCP via en applikasjon.  I tillegg til lagring med Google cloud storage sÃ¥ har man mulighet til Ã¥ benytte Scality on-prem som er et AWS S3-kompatibel lÃ¸sning.  ","version":"Next","tagName":"h3"},{"title":"Continuous Deploymentâ€‹","type":1,"pageTitle":"Oversikt over tjenester SKIP tilbyr","url":"/docs/kom-i-gang/oversikt-over-tjenester-SKIP-tilbyr#continuous-deployment","content":" ArgoCD er et deklarativt, GitOps-kontinuerlig leveranseverktÃ¸y for Kubernetes-applikasjoner. Det automatiserer distribusjon og administrasjon av applikasjoner i Kubernetes ved Ã¥ synkronisere den Ã¸nskede tilstanden som er definert i Git-repositorier med den faktiske cluster konfigurasjonen. ","version":"Next","tagName":"h3"},{"title":"ðŸ“‹ Praktisk intro til SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro","content":"ðŸ“‹ Praktisk intro til SKIP Github 101Sett opp apps repoKjÃ¸r en applikasjon pÃ¥ SKIPOvervÃ¥k applikasjonen pÃ¥ SKIP","keywords":"","version":"Next"},{"title":"Bruk av GitHub med Jenkins","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/bruk-av-github-med-jenkins","content":"","keywords":"","version":"Next"},{"title":"ðŸ“š Autentisering ðŸ“šâ€‹","type":1,"pageTitle":"Bruk av GitHub med Jenkins","url":"/docs/kom-i-gang/praktisk-intro/github/bruk-av-github-med-jenkins#-autentisering-","content":" Det er flere mÃ¥ter Ã¥ autentisere Jenkins mot GitHub pÃ¥, blant annet; deploy keys, personal access tokens, GitHub App. Vi vil se at GitHub Apps er valget vi gÃ¥r for nÃ¥r vi autentiserer.   Deploy keys er enkle men;  ðŸ‘ Eies av repoet og Jenkins (priv + pub nÃ¸kler)ðŸ‘Š Kan kun brukes som â€œGitâ€ source pÃ¥ JenkinsðŸ‘Ž Snakker ikke med GitHub sitt API - kun pulle / pushe kode   Personal access tokens **** (PAT) gir mer;  ðŸ‘ Kan brukes gjennom â€œGitHubâ€ plugin pÃ¥ Jenkins (source)ðŸ‘ Snakker med GitHub APIâ€™et - PR/Commit status triggere etc.ðŸ‘Ž NÃ¸kkelen fÃ¸lger brukeren, selv etter vedkommende bytter team eller slutter (kan slettes fra bruker)ðŸ‘Ž Ikke i utgangspunktet gjenbrukbar (beta- fine grained PATâ€™er kan tilegnes flere repo pr. nÃ¸kkel)   GitHub Apps er litt mer Ã¥ konfigurere, men er en kombinasjon av de over;  ðŸ‘ Gjenbrukbare, som flere repoer kan bruke gjennom Ã©n privat nÃ¸kkel pÃ¥ Jenkins.ðŸ‘ Eies av â€œOrganisasjonenâ€ Kartverket pÃ¥ Github, som da ikke er bundet til en GitHub bruker.ðŸ‘ Kan brukes gjennom â€œGitHubâ€ plugin pÃ¥ Jenkins (source)ðŸ‘ Snakker med GitHub APIâ€™et - PR/Commit status triggere etc.ðŸ‘Ž Ratelimit (men skal ikke vÃ¦re et problem)  ","version":"Next","tagName":"h2"},{"title":"ðŸ§‘â€ðŸš’ Brannmurer ðŸ§‘â€ðŸš’â€‹","type":1,"pageTitle":"Bruk av GitHub med Jenkins","url":"/docs/kom-i-gang/praktisk-intro/github/bruk-av-github-med-jenkins#-brannmurer-","content":" I utgangspunktet sÃ¥ skal portene til ditt Jenkins miljÃ¸ vÃ¦re Ã¥pnet, slik at Jenkins nÃ¥r ut til GitHub. Men hvis det dette er fÃ¸rste gang sÃ¥ mÃ¥ de Ã¥pnes for trafikk mot GitHub. PrimÃ¦rt er det HTTPs og SSH trafikk som mÃ¥ tilgjengeliggjÃ¸res pÃ¥ port 443 og 22. Dette mÃ¥ bestilles hos drift.  ","version":"Next","tagName":"h2"},{"title":"ðŸª Webhook ðŸªâ€‹","type":1,"pageTitle":"Bruk av GitHub med Jenkins","url":"/docs/kom-i-gang/praktisk-intro/github/bruk-av-github-med-jenkins#-webhook-","content":" Work in progress. Er ikke ferdig testet enda.  For Ã¥ fÃ¥ status pÃ¥ PR/Commits i GitHub sÃ¥ mÃ¥ GitHub ha en vei inn til Jenkins. Dette gjÃ¸res pÃ¥ et webhook endepunkt typisk seende slik ut https://&lt;jenkins-host&gt;/github-webhook/ . Dette er noe som mÃ¥ Ã¥pnes fra drift og spesifiseres inne i GitHub Appen.  âš™ï¸ Legg til hvordan det er med webhook secret.  ","version":"Next","tagName":"h2"},{"title":"ðŸ“ Oppsett av GitHub App ðŸ“â€‹","type":1,"pageTitle":"Bruk av GitHub med Jenkins","url":"/docs/kom-i-gang/praktisk-intro/github/bruk-av-github-med-jenkins#-oppsett-av-github-app-","content":" SKIP kontaktes og de setter opp en App for ditt behov. Er denne som fÃ¸lges: Using GitHub App authentication .  info Oppsettet av nÃ¸klen mÃ¥ du gjÃ¸re selv! Og dette FÃ˜R du fÃ¥r brukt Appen, men ETTER at SKIP setter igang med oppsett av app. SKIP sender melding nÃ¥r du mÃ¥ gjÃ¸re dette. nb: skal Appen ha flere/mindre rettigheter enn i oppskriften mÃ¥ du spesifisere dette  NÃ¥r SKIP har satt opp Appen, mÃ¥ du sette den private nÃ¸kkelen, som senere skal deles med Jenkins. Dette gjÃ¸res slik som beskrevet i punktet Generating a private key for authenticating to the GitHub App .  Det er fÃ¸rst nÃ¥r dette er gjort, at SKIP kan installere Appen pÃ¥ organisasjonen. Send en heads-up at du har lagret nÃ¸kkelen.  Hvis Appen er installert i org. og linket til ditt repo, og nÃ¸kkelen er satt opp i App og Jenkins sÃ¥ skal alt vÃ¦re pÃ¥ plass! ðŸŽ‰ ","version":"Next","tagName":"h2"},{"title":"ðŸ—ƒï¸ GitHub","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github","content":"ðŸ—ƒï¸ GitHub Kartverket lagrer kildekode pÃ¥ github.com, og gjennom organisasjonen vÃ¥r distribuerer vi tilgang ved Ã¥ fordele lisensene vi har kjÃ¸pt inn. For Ã¥ fÃ¥ tilgang fÃ¸lg sjekklisten under. info Ved spÃ¸rsmÃ¥l vedrÃ¸rende tilgang eller behov for stÃ¸tte, ta kontakt pÃ¥ #gen-github pÃ¥ slack Kom igang ved Ã¥ sjekke ut lenkene under: Tilgang til GitHubAutentisering til GitHub i terminalen (git clone / push med SSH)Opprette nytt repo pÃ¥ GitHubGitHub Actions som CI/CDHÃ¥ndtering av sensitiv data som er kommet pÃ¥ repositorietBruk av GitHub med JenkinsTilgang til on-prem infrastruktur fra GitHub ActionsTilgang til repoer med tokens fra GitHub Actions","keywords":"","version":"Next"},{"title":"Autentisering til GitHub i terminalen","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen","content":"","keywords":"","version":"Next"},{"title":"Oppdater Gitâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#oppdater-git","content":" warning Ikke hopp over dette steget . Du finner oversikt over sÃ¥rbare versjoner av git her: https://github.com/git/git/security/advisories  Velg ditt operativsystem og fÃ¸lg instruksene for Ã¥ installere den nyeste versjonen av Git.  Oppdater Git for LinuxOppdater Git for macOSOppdater Git for Windows  Du kan sjekke hvilken versjon du har med denne kommandoen:  git --version   ","version":"Next","tagName":"h2"},{"title":"Generer SSH nÃ¸kkelâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#generer-ssh-nÃ¸kkel","content":" Du kan velge mellom ed25519 og RSA-4096.  (det finnes flere alternativer, men disse er vurdert som akseptable)  Bruk ssh-keygen for Ã¥ generere en ny nÃ¸kkel lokalt pÃ¥ din maskin. Husk Ã¥ bytt ut â€œDINEPOSTâ€ med Kartverket eposten din (f.eks. &quot;jell.fjell@kartverket.no&quot; ).  ssh-keygen -a 50 -t ed25519 -f ~/.ssh/github -C â€œDINEPOSTâ€   Alternativt kan du bruke RSA-4096 ssh-keygen -t rsa -b 4096 -f ~/.ssh/github -C &quot;DINEPOST&quot;   warning NB! Husk Ã¥ sette passord nÃ¥r du blir spurt. Ikke la passordfeltet stÃ¥ tomt.  ","version":"Next","tagName":"h2"},{"title":"Sett lokale rettigheter pÃ¥ SSH nÃ¸kkelenâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#sett-lokale-rettigheter-pÃ¥-ssh-nÃ¸kkelen","content":" SSH nÃ¸kkelen er privat for din bruker, og skal kun leses av din bruker.  chmod 600 ~/.ssh/github   ","version":"Next","tagName":"h3"},{"title":"Legg til nÃ¸kkelen (public key) i GitHubâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#legg-til-nÃ¸kkelen-public-key-i-github","content":" Vis og kopier din public key fra~/.ssh/github.pubfra terminalen.  cat ~/.ssh/github.pub   Marker utskriften og kopier innholdet.  Logg inn pÃ¥ GitHub.com med Kartverket kontoen din.Trykk pÃ¥ profilbildet ditt, Ã¸verst i hÃ¸yre hjÃ¸rne.Velg Â« Settings Â».Naviger deg til Â« SSH and GPG keys Â» (under kategorien Â«AccessÂ») i venstre kolonne.Trykk pÃ¥ den grÃ¸nne Â« New SSH key Â» knappen.Skriv inn en passelig tittel (f.eks. â€œMin private SSH nÃ¸kkelâ€).Kopier og lim inn innholdet fra~/.ssh/github.pub(ikke private key), som vist i fÃ¸rste steg.Trykk pÃ¥ Â« Add SSH key Â».Du skal nÃ¥ se oversikten over dine nÃ¸kler, med den nye nÃ¸kkelen i listen.For Ã¥ bruke kartverket nÃ¸kkelen mÃ¥ man bekrefte nÃ¸kkelen med SSO. Dette gjÃ¸res ved Ã¥ trykke configure SSO pÃ¥ nÃ¸kkelen.  ","version":"Next","tagName":"h2"},{"title":"Test nÃ¸kkelenâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#test-nÃ¸kkelen","content":" Du kan raskt teste nÃ¸kkelen din mot GitHub ved Ã¥ kjÃ¸re:  ssh -T git@github.com -i ~/.ssh/github   Du skal fÃ¥ tilbakemelding om vellykket autentisering:  Hi! You've successfully authenticated, but GitHub does not provide shell access.   ","version":"Next","tagName":"h2"},{"title":"Automatisk bruk av nÃ¸kkelen dinâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#automatisk-bruk-av-nÃ¸kkelen-din","content":" note Det finnes flere mÃ¥ter Ã¥ ta i bruk nÃ¸kkelen din. Dette er et eksempel pÃ¥ hvordan, men du stÃ¥r fritt til Ã¥ bruke andre lÃ¸sninger.  Opprett filen~/.ssh/configog fyll den ut med innholdet for GitHub med nÃ¸kkelen din:  Host github HostName github.com User git IdentityFile ~/.ssh/github   ","version":"Next","tagName":"h2"},{"title":"Ta i bruk nÃ¸kkelen nÃ¥r du kloner et repoâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#ta-i-bruk-nÃ¸kkelen-nÃ¥r-du-kloner-et-repo","content":" Du kan ta i bruk nÃ¸kkelen din ved Ã¥ refere til github nÃ¥r du skal klone et repo. Husk Ã¥ bytt ut â€œDITTREPOâ€ med navnet pÃ¥ repoet du prÃ¸ver Ã¥ klone.  git clone github:kartverket/DITTREPO.git   NÃ¥r du kloner repoet pÃ¥ denne mÃ¥ten vil Git automatisk ta i bruk remote med din konfigurasjon (tar automatisk i bruk nÃ¸kkelen din ved git pull / push ).  ","version":"Next","tagName":"h3"},{"title":"Legg til navn og epost for riktig eier av commitsâ€‹","type":1,"pageTitle":"Autentisering til GitHub i terminalen","url":"/docs/kom-i-gang/praktisk-intro/github/autentisering-til-github-i-terminalen#legg-til-navn-og-epost-for-riktig-eier-av-commits","content":" For at commits du gjÃ¸r pÃ¥ din maskin skal stemme overens med GitHub brukeren din mÃ¥ du sette brukernavn og epost i Git. Husk Ã¥ bytt ut â€œDITT NAVNâ€ med github brukernavnet ditt (f.eks. â€œjellfjellâ€œ) og â€œDINEPOSTâ€ med Kartverket eposten din (f.eks. &quot;jell.fjell@kartverket.no&quot; ).  git config --global user.name &quot;DITT NAVN&quot; git config --global user.email &quot;DINEPOST&quot;   TLDR For deg som ikke leste i gjennom og vil rett pÃ¥ sak uten forklaring. Oppdater Git: https://git-scm.com/downloads - IKKE HOPP OVER DETTE STEGET ssh-keygen -a 50 -t ed25519 -f ~/.ssh/github -C â€œDINEPOSTâ€ chmod 600 ~/.ssh/github cat ~/.ssh/github.pub Kopier og lim inn public key pÃ¥ GitHub https://github.com/settings/ssh/new ssh -T git@github.com -i ~/.ssh/github git config --global user.name &quot;DITT NAVN&quot; git config --global user.email &quot;DINEPOST&quot; git clone URL --config core.sshCommand=&quot;ssh -i ~/.ssh/github&quot; NÃ¥ er du klar for Ã¥ begi deg ut pÃ¥ eventyr. ","version":"Next","tagName":"h2"},{"title":"HÃ¥ndtering av sensitiv data som er kommet pÃ¥ repositoriet","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/hÃ¥ndtering-av-sensitiv-data-som-er-kommet-pÃ¥-repositoriet","content":"","keywords":"","version":"Next"},{"title":"ðŸ“˜ Instruksjonerâ€‹","type":1,"pageTitle":"HÃ¥ndtering av sensitiv data som er kommet pÃ¥ repositoriet","url":"/docs/kom-i-gang/praktisk-intro/github/hÃ¥ndtering-av-sensitiv-data-som-er-kommet-pÃ¥-repositoriet#-instruksjoner","content":" for Ã¥ se om secret scanning har avduket noen sensitive data i repositoriet gÃ¥ inn pÃ¥ repositorierts forside og klikk deg inn pÃ¥ security-fanen og deretter trykk deg inn pÃ¥ sidemeny-valget â€œSecret scanning alertsâ€trykk deg inn pÃ¥ det varselet for det sensitive dataen du skal lÃ¸seher fÃ¥r du vite hvilke filer det er snakk om og akkurat hvilken linje det er snakk om.Deretter er det Ã¥ fÃ¸lge denne guiden, Fjerne sensitive data fra repositorier for selve fjerningen av de sensitive dataenenÃ¥r fjerningen er gjor kan man lukke varslet  ","version":"Next","tagName":"h2"},{"title":"ðŸ“‹ Relaterte artiklerâ€‹","type":1,"pageTitle":"HÃ¥ndtering av sensitiv data som er kommet pÃ¥ repositoriet","url":"/docs/kom-i-gang/praktisk-intro/github/hÃ¥ndtering-av-sensitiv-data-som-er-kommet-pÃ¥-repositoriet#-relaterte-artikler","content":" Fjerne sensitive data fra repositorier  Secret Scanning ","version":"Next","tagName":"h2"},{"title":"Dependabot","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot","content":"","keywords":"","version":"Next"},{"title":"Skru pÃ¥ automatiske versjonsoppdateringerâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#skru-pÃ¥-automatiske-versjonsoppdateringer","content":" Automatiske versjonsoppdateringer mÃ¥ skrus pÃ¥ av en bruker med &quot;Admin&quot;-rolle i repoet. For det aktuelle repoet kan du gÃ¥ til &quot;Settings &gt; Code security &gt; Dependabot &gt; Dependabot version updates&quot; og trykke pÃ¥ &quot;Enable&quot;.  Dersom dette ikke er gjort fra fÃ¸r mÃ¥ du sette opp en initiell versjon av filen .github/dependabot.yml. Det er anbefalt Ã¥ sette opp for oppdatering av GitHub Actions for alle repoer som et minimum:  version: 2 updates: - package-ecosystem: &quot;github-actions&quot; directory: &quot;.github/workflows&quot; schedule: interval: &quot;daily&quot;   I tillegg bÃ¸r det settes opp for de ulike sprÃ¥kene/Ã¸kosystemene som ligger i repoet. Se eksemplene i avsnittet Eksempelkonfigurasjoner.  ","version":"Next","tagName":"h2"},{"title":"FeilsÃ¸king av Dependabotâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#feilsÃ¸king-av-dependabot","content":" For Ã¥ se Dependabot-feil i et repo kan man gÃ¥ til &quot;Insights &gt; Dependency graph &gt; Dependabot&quot; for Ã¥ se feil, status og logger fra siste kjÃ¸ringer.  Se ogsÃ¥ GitHub-dokumentasjonen for mer detaljert beskrivelse av feilsÃ¸king.  ","version":"Next","tagName":"h2"},{"title":"Konfigurasjon av Dependabotâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#konfigurasjon-av-dependabot","content":" ","version":"Next","tagName":"h2"},{"title":"Begrense antallet pull requests fra Dependabotâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#begrense-antallet-pull-requests-fra-dependabot","content":" Antallet PR-er er begrenset til 5 for vanlige versjonsoppdateringer og 10 for sikkerhetsoppdateringer. Antallet Ã¥pne PR-er kan konfigureres med open-pull-requests-limit for hvert Ã¸kosystem. F.eks.:   - package-ecosystem: &quot;&lt;ecosystem&gt;&quot; open-pull-requests-limit: 20 # ... More config ...   ","version":"Next","tagName":"h3"},{"title":"Oppdateringsintervallâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#oppdateringsintervall","content":" Man kan styre Dependabot kjÃ¸rer ved Ã¥ konfigurere schedule for hvert package-ecosystem.  For Ã¥ kjÃ¸re oppdateringer hver morgen i ukedagene:   - package-ecosystem: &quot;pip&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot; time: &quot;07:00&quot; timezone: &quot;Europe/Oslo&quot;   For Ã¥ kjÃ¸re oppdateringer hver mandag morgen:   - package-ecosystem: &quot;pip&quot; directory: &quot;/&quot; schedule: interval: &quot;weekly&quot; day: &quot;monday&quot; time: &quot;07:00&quot; timezone: &quot;Europe/Oslo&quot;   ","version":"Next","tagName":"h3"},{"title":"Innlogging til private registriesâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#innlogging-til-private-registries","content":" For at Dependabot skal kunne oppdatere dependencies som ligger i private/internal repoer (eks. actions), pakker i private package registries (npm, maven) elle  Merk at dette krever PATs eller access tokens som mÃ¥ ligge som en Dependabot repository secret i repoet.  Private registries mÃ¥ legges i registries-listen, og mÃ¥ i tillegg refereres til i updates-listen for relevante Ã¸kosystemer. Eks.:  version: 2 registries: npm-github: type: npm-registry url: https://npm.pkg.github.com token: ${{ secrets.PAT_GHCR_READ }} updates: - package-ecosystem: npm # Check also for updates in GitHub Maven Package frontend-aut-lib registries: - npm-github # Remaining configuration skipped   NPMâ€‹  Se ogsÃ¥ dokumentasjonen.  registries: npm-github: type: npm-registry url: https://npm.pkg.github.com token: ${{ secrets.PAT_GHCR_READ }}   GitHubâ€‹  Denne brukes typisk for actions som ligger i private/interne repoer. Dependabot mÃ¥ bli gitt eksplisitt tilgang for Ã¥ lese nye private/interne repoer (spÃ¸r om hjelp i #gen-github pÃ¥ Slack). Se ogsÃ¥ dokumentasjonen.  registries: github-repo-name: type: git url: https://github.com username: x-access-token password: ${{ secrets.PAT_READ_REPO_NAME }}   Mavenâ€‹  Denne brukes for Ã¥ lese Maven-pakker som er publisert i et gitt repo. Se ogsÃ¥ dokumentasjonen.  registries: maven-repo-name: type: maven-repository url: https://maven.pkg.github.com/kartverket/repo-name username: ${{ secrets.GH_USERNAME }} password: ${{ secrets.PAT_GHCR_READ }}   ","version":"Next","tagName":"h3"},{"title":"Eksempelkonfigurasjonerâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#eksempelkonfigurasjoner","content":" De ulike Ã¸kosystemene fungerer litt ulikt, og stÃ¸tte kan variere. For mer informasjon se dokumentasjonen for Ã¸kosystemer.  Under fÃ¸lger noen vanlige konfigurasjoner som flere team bruker. Disse er et gir et godt utgangspunkt men mÃ¥ i noen tilfeller konfigureres mer for Ã¥ fungere.  ","version":"Next","tagName":"h2"},{"title":"GitHub Actionsâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#github-actions","content":"  - package-ecosystem: &quot;github-actions&quot; directory: &quot;.github/workflows&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"Git submodulesâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#git-submodules","content":" Denne kan legges til i repoer som bruker git submodules, eks. apps-repoer som benytter argokit.   - package-ecosystem: &quot;gitsubmodule&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"Dockerâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#docker","content":" Pass pÃ¥ at directory peker til mappen som inneholder Dockerfile.   - package-ecosystem: &quot;docker&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"Gradleâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#gradle","content":"  - package-ecosystem: &quot;gradle&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"NPM eksempelâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#npm-eksempel","content":"  - package-ecosystem: &quot;npm&quot; directory: &quot;/&quot; schedule: interval: &quot;weekly&quot;   For Ã¥ unngÃ¥ for mange PR-er for minor- og patchversjoner er det i mange tilfeller ok Ã¥ gruppere disse for NPM:   - package-ecosystem: &quot;npm&quot; directory: &quot;/&quot; schedule: interval: &quot;weekly&quot; groups: minor-and-patch-dependencies: patterns: - &quot;*&quot; update-types: - &quot;minor&quot; - &quot;patch&quot;   ","version":"Next","tagName":"h3"},{"title":"Goâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#go","content":"  - package-ecosystem: &quot;gomod&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"Terraformâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#terraform","content":" Oppdater directory med riktig filsti.   - package-ecosystem: &quot;terraform&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;   Dersom det er flere mapper som inneholder Terraform kan directories brukes:   - package-ecosystem: &quot;terraform&quot; directories: - &quot;dev&quot; - &quot;prod&quot; schedule: interval: &quot;daily&quot;   ","version":"Next","tagName":"h3"},{"title":"Pythonâ€‹","type":1,"pageTitle":"Dependabot","url":"/docs/kom-i-gang/praktisk-intro/github/dependabot#python","content":"  - package-ecosystem: &quot;pip&quot; directory: &quot;/&quot; schedule: interval: &quot;daily&quot;  ","version":"Next","tagName":"h3"},{"title":"Tilgang til GitHub","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/tilgang-til-github","content":"","keywords":"","version":"Next"},{"title":"Bistand og diskusjon rundt GitHubâ€‹","type":1,"pageTitle":"Tilgang til GitHub","url":"/docs/kom-i-gang/praktisk-intro/github/tilgang-til-github#bistand-og-diskusjon-rundt-github","content":" Logg pÃ¥ slack ved Ã¥ laste ned programmet fra http://slack.com og bruk kartverketgroup.slack.com som workspaceTa kontakt med SKIP pÃ¥ slack i #gen-github for Ã¥ fÃ¥ en invitasjon til GitHub-organisasjonen til Kartverket (send github-brukernavnet ditt). Dersom du vet pÃ¥ forhÃ¥nd at du jobber som del av et team sÃ¥ fortell oss hvilke team dette er sÃ¥ fÃ¥r vi lagt deg i tilsvarende team i GitHub   ","version":"Next","tagName":"h2"},{"title":"âš™ï¸ Kubernetes","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes","content":"âš™ï¸ Kubernetes","keywords":"","version":"Next"},{"title":"Opprette nytt repo pÃ¥ Github","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/github/opprette-nytt-repo-pÃ¥-github","content":"","keywords":"","version":"Next"},{"title":"Merknad for produkter som ikke er pÃ¥ SKIPâ€‹","type":1,"pageTitle":"Opprette nytt repo pÃ¥ Github","url":"/docs/kom-i-gang/praktisk-intro/github/opprette-nytt-repo-pÃ¥-github#merknad-for-produkter-som-ikke-er-pÃ¥-skip","content":" Merk at det meste av dette dokumentet ogsÃ¥ er gyldig for prosjekter som ikke er pÃ¥ SKIP-plattformen - men at det likevel er skrevet for SKIP-teams, sÃ¥ sikkerhetsreglene kan sees pÃ¥ som gode rÃ¥d dersom du ikke skal bruke SKIP.  For ikke Ã¥ snakke om at du dersom du fÃ¸lger disse sikkerhetsreglene vil fÃ¥ en mye enklere jobb hvis du skal flytte prosjektet over til SKIP i fremtiden   ","version":"Next","tagName":"h2"},{"title":"Hvordan opprette et nytt GitHub Repositoryâ€‹","type":1,"pageTitle":"Opprette nytt repo pÃ¥ Github","url":"/docs/kom-i-gang/praktisk-intro/github/opprette-nytt-repo-pÃ¥-github#hvordan-opprette-et-nytt-github-repository","content":" Logg inn pÃ¥ GitHubOpprett et nytt repository ved Ã¥ trykke pÃ¥ pluss-ikonet Ã¸verst til hÃ¸yre pÃ¥ https://github.com og velge â€œNew repositoryâ€. Dette gjelder uansett om du skal lage et nytt prosjekt eller importere et eksisterende prosjekt, siden du ikke vil kunne bruke â€œImportâ€-funksjonaliteten pÃ¥ vanlig mÃ¥te.Dersom du skal importere et eksisterende git-repository, fÃ¸lg denne tutorialen.Fyll ut skjemaet med riktig informasjon. Huskeregler: Alle prosjekter som ikke skal vÃ¦re Ã¥pne skal vÃ¦re Internal . Det er likevel mulig Ã¥ invitere eksterne utviklere. Mer informasjon: https://docs.github.com/en/repositories/creating-and-managing-repositories/about-repositories#about-repository-visibilityPass pÃ¥ at Owner er satt til kartverket , og ikke din private bruker.Ikke velg en lisens med mindre du faktisk skal lage et open-source prosjekt. Ã… velge en Ã¥pen kildekode-lisens her kan Ã¸delegge for sikkerhetsverktÃ¸yene i Kartverket og i siste instans skape legale problemer for Kartverket. Hvis du er i tvil, ta kontakt med SKIP-teamet. Dokumenter hvilket team som er ansvarlig for repositoriet ved Ã¥ opprette en Codeowners fil.Dette er dokumentert her. Som regel er det nok med en linje - slik (bytt ut skip med ditt eget team).Gi teamet ditt rettigheter til repoet. Dette er dokumentert her. Det er vanlig Ã¥ sette Tech Lead som eier for repositoriet, men dette bestemmer dere selv.  ","version":"Next","tagName":"h2"},{"title":"Opprett tilganger til Google Cloud for Github Actionsâ€‹","type":1,"pageTitle":"Opprette nytt repo pÃ¥ Github","url":"/docs/kom-i-gang/praktisk-intro/github/opprette-nytt-repo-pÃ¥-github#opprett-tilganger-til-google-cloud-for-github-actions","content":" Dersom du har behov til Ã¥ autentisere deg mot GCP kan du legge til at ditt repo GitHub kan autentisere seg mot Google Cloud med en bestemt bruker. Da mÃ¥ man sette opp Workload Identity Federation. Dette er noe SKIP ordner for produktteamene pÃ¥ en automatisert mÃ¥te ved hjelp av Terraform.  Ã˜nsker du Ã¥ legge til et nytt repo kan du opprette en Pull Request for dette repoet: https://github.com/kartverket/gcp-service-accounts  Eksempel pÃ¥ liste over GitHub repoer for KomReg: https://github.com/kartverket/gcp-service-accounts/blob/main/modules.tf  module &quot;komreg&quot; { source = &quot;./project_team&quot; team_name = &quot;KomReg&quot; repositories = [ &quot;kartverket/komreg-frontend&quot;, &quot;kartverket/komreg-backend&quot;, &quot;kartverket/komreg-frontend-api&quot;, # Legg til flere repoer i denne listen ] env = var.env project_id = var.komreg_project_id kubernetes_project_id = var.kubernetes_project_id can_manage_log_alerts_and_metrics = true can_manage_sa = true extra_team_sa_roles = [ &quot;roles/resourcemanager.projectIamAdmin&quot;, &quot;roles/secretmanager.admin&quot;, &quot;roles/storage.admin&quot; ] }   NÃ¥r PRâ€™en merges inn vil det ved et nytt team bli opprettet en deploy-servicekonto, som heter &lt;teamnavn&gt;-deploy@&lt;prosjekt-id&gt;.iam.gserviceaccount.com . Denne servicekontoen tillater at github-repoene i listen har lov til Ã¥ etterligne den og dens tilganger.  Mer informasjon om Github Actions: GitHub Actions som CI/CD ","version":"Next","tagName":"h2"},{"title":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager","content":"","keywords":"","version":"Next"},{"title":"Innledningâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#innledning","content":" For Ã¥ effektivisere og sikre prosessen med sertifikathÃ¥ndtering har vi valgt Ã¥ bruke ACME (Automatic Certificate Management Environment) og cert-manager. Her er hovedgrunnene til vÃ¥rt valg:  ","version":"Next","tagName":"h2"},{"title":"Automatisering og effektivitetâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#automatisering-og-effektivitet","content":" Redusert risiko for utlÃ¸pte sertifikater: ACME automatiserer fornyelsen av sertifikater, noe som sikrer at de alltid er gyldige og reduserer risikoen for tjenesteavbrudd pÃ¥ grunn av utlÃ¸pte sertifikater. Minimert menneskelig feil: Ved Ã¥ automatisere sertifikathÃ¥ndteringen med cert-manager, reduserer vi sannsynligheten for menneskelige feil som kan oppstÃ¥ ved manuell hÃ¥ndtering, som feilkonfigurasjoner eller glemte fornyelser.  ","version":"Next","tagName":"h2"},{"title":"Forbedret sikkerhetâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#forbedret-sikkerhet","content":" Hyppige fornyelser: ACME muliggjÃ¸r hyppigere fornyelser av sertifikater, noe som reduserer vinduet for potensielle angrep dersom et sertifikat skulle bli kompromittert. Automatisert oppdagelse og revokasjon: Cert-manager overvÃ¥ker kontinuerlig sertifikatenes status og kan automatisk oppdage og revokere kompromitterte sertifikater.  ","version":"Next","tagName":"h2"},{"title":"Skalerbarhet og fleksibilitetâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#skalerbarhet-og-fleksibilitet","content":" HÃ¥ndtering av store volumer: Med ACME og cert-manager kan vi effektivt hÃ¥ndtere et stort antall sertifikater uten Ã¥ Ã¸ke arbeidsbelastningen pÃ¥ teamene. Antallet tjenester i Kartverket gjÃ¸r det vanskelig Ã¥ hÃ¥ndtere uten automasjon, eller fellessertifikater som benyttes pÃ¥ mange tjenester, noe som gjÃ¸r de mer sÃ¥rbare. Integrasjon med Kubernetes: Cert-manager integreres sÃ¸mlÃ¸st med Kubernetes, noe som gjÃ¸r det enkelt Ã¥ administrere sertifikater i vÃ¥re containeriserte applikasjoner, og sikre at de alltid er oppdaterte.  ","version":"Next","tagName":"h2"},{"title":"Overholdelse og beste-praksisâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#overholdelse-og-beste-praksis","content":" Samsvar med industristandarder: Ved Ã¥ bruke ACME og cert-manager, sikrer vi at vi overholder bransjestandarder og forskrifter som krever hyppige fornyelser og sikker hÃ¥ndtering av digitale sertifikater. Sentralisert kontroll og synlighet: Cert-manager gir oss en sentralisert plattform for Ã¥ administrere alle vÃ¥re sertifikater, noe som gir bedre kontroll og synlighet over hele sertifikatbeholdningen.  ","version":"Next","tagName":"h2"},{"title":"Konklusjonâ€‹","type":1,"pageTitle":"Valg av ACME og cert-manager for sertifikathÃ¥ndtering","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-acme-og-certmanager#konklusjon","content":" Valget av ACME og cert-manager for sertifikathÃ¥ndtering gir oss en sikker, effektiv og skalerbar lÃ¸sning som reduserer risikoen for menneskelige feil, forbedrer sikkerheten og sikrer samsvar med bransjestandarder. Ved Ã¥ automatisere sertifikathÃ¥ndteringen kan vi fokusere pÃ¥ strategiske initiativer og opprettholde en sterk sikkerhetsstilling. ","version":"Next","tagName":"h2"},{"title":"API Reference","type":0,"sectionRef":"#","url":"/docs/applikasjon-utrulling/skiperator/api-docs","content":"","keywords":"","version":"Next"},{"title":"Applicationâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#application","content":" Application  Root object for Application resource. An application resource is a resource for easily managing a Dockerized container within the context of a Kartverket cluster. This allows product teams to avoid the need to set up networking on the cluster, as well as a lot of out of the box security features.  Name\tType\tDescription\tRequiredapiVersion\tstring\tskiperator.kartverket.no/v1alpha1\ttrue kind\tstring\tApplication\ttrue metadata\tobject\tRefer to the Kubernetes API documentation for the fields of the metadata field.\ttrue spec\tobject false status\tobject SkiperatorStatus A status field shown on a Skiperator resource which contains information regarding deployment of the resource. false  ","version":"Next","tagName":"h2"},{"title":"Application.specâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspec","content":" â†© Parent  Name\tType\tDescription\tRequiredimage\tstring The image the application will run. This image will be added to a Deployment resource true port\tinteger The port the deployment exposes true accessPolicy\tobject The root AccessPolicy for managing zero trust access to your Application. See AccessPolicy for more information. false additionalPorts\t[]object An optional list of extra port to expose on a pod level basis, for example so Instana or other APM tools can reach it false appProtocol\tenum Protocol that the application speaks. Enum: http, tcp, udp Default: http false authorizationSettings\tobject Used for allow listing certain default blocked endpoints, such as /actuator/ end points false command\t[]string Override the command set in the Dockerfile. Usually only used when debugging or running third-party containers where you don't have control over the Dockerfile false enablePDB\tboolean Whether to enable automatic Pod Disruption Budget creation for this application. Default: true false env\t[]object Environment variables that will be set inside the Deployment's Pod. See https://pkg.go.dev/k8s.io/api/core/v1#EnvVar for examples. false envFrom\t[]object Environment variables mounted from files. When specified all the keys of the resource will be assigned as environment variables. Supports both configmaps and secrets. For mounting as files see FilesFrom. false filesFrom\t[]object Mounting volumes into the Deployment are done using the FilesFrom argument FilesFrom supports ConfigMaps, Secrets and PVCs. The Application resource assumes these have already been created by you, and will fail if this is not the case. For mounting environment variables see EnvFrom. false gcp\tobject GCP is used to configure Google Cloud Platform specific settings for the application. false idporten\tobject Settings for IDPorten integration with Digitaliseringsdirektoratet false ingresses\t[]string Any external hostnames that route to this application. Using a skip.statkart.no-address will make the application reachable for kartverket-clients (internal), other addresses make the app reachable on the internet. Note that other addresses than skip.statkart.no (also known as pretty hostnames) requires additional DNS setup. The below hostnames will also have TLS certificates issued and be reachable on both HTTP and HTTPS. Ingresses must be lowercase, contain no spaces, be a non-empty string, and have a hostname/domain separated by a period They can optionally be suffixed with a plus and name of a custom TLS secret located in the istio-gateways namespace. E.g. &quot;foo.atkv3-dev.kartverket-intern.cloud+env-wildcard-cert&quot; false istioSettings\tobject IstioSettings are used to configure istio specific resources such as telemetry. Currently, adjusting sampling interval for tracing is the only supported option. By default, tracing is enabled with a random sampling percentage of 10%. Default: map[telemetry:map[tracing:[map[randomSamplingPercentage:10]]]] false labels\tmap[string]string Labels can be used if you want every resource created by your application to have the same labels, including your application. This could for example be useful for metrics, where a certain label and the corresponding resources liveliness can be combined. Any amount of labels can be added as wanted, and they will all cascade down to all resources. false liveness\tobject Liveness probes define a resource that returns 200 OK when the app is running as intended. Returning a non-200 code will make kubernetes restart the app. Liveness is optional, but when provided, path and port are required See Probe for structure definition. false maskinporten\tobject Settings for Maskinporten integration with Digitaliseringsdirektoratet false podSettings\tobject PodSettings are used to apply specific settings to the Pod Template used by Skiperator to create Deployments. This allows you to set things like annotations on the Pod to change the behaviour of sidecars, and set relevant Pod options such as TerminationGracePeriodSeconds. false priority\tenum An optional priority. Supported values are 'low', 'medium' and 'high'. The default value is 'medium'. Most workloads should not have to specify this field. If you think you do, please consult with SKIP beforehand. Enum: low, medium, high Default: medium false prometheus\tobject Optional settings for how Prometheus compatible metrics should be scraped. false readiness\tobject Readiness probes define a resource that returns 200 OK when the app is running as intended. Kubernetes will wait until the resource returns 200 OK before marking the pod as Running and progressing with the deployment strategy. Readiness is optional, but when provided, path and port are required false redirectToHTTPS\tboolean Controls whether the application will automatically redirect all HTTP calls to HTTPS via the istio VirtualService. This redirect does not happen on the route /.well-known/acme-challenge/, as the ACME challenge can only be done on port 80. Default: true false replicas\tJSON The number of replicas can either be specified as a static number as follows: replicas: 2 Or by specifying a range between min and max to enable HorizontalPodAutoscaling. The default value for replicas is: replicas: min: 2 max: 5 targetCpuUtilization: 80 Using autoscaling is the recommended configuration for replicas. false resourceLabels\tmap[string]map[string]string ResourceLabels can be used if you want to add a label to a specific resources created by the application. One such label could for example be set on a Deployment, such that the deployment avoids certain rules from Gatekeeper, or similar. Any amount of labels may be added per ResourceLabels item. false resources\tobject ResourceRequirements to apply to the deployment. It's common to set some of these to prevent the app from swelling in resource usage and consuming all the resources of other apps on the cluster. false startup\tobject Kubernetes uses startup probes to know when a container application has started. If such a probe is configured, it disables liveness and readiness checks until it succeeds, making sure those probes don't interfere with the application startup. This can be used to adopt liveness checks on slow starting containers, avoiding them getting killed by Kubernetes before they are up and running. Startup is optional, but when provided, path and port are required false strategy\tobject Defines an alternative strategy for the Kubernetes deployment. This is useful when the default strategy, RollingUpdate, is not usable. Setting type to Recreate will take down all the pods before starting new pods, whereas the default of RollingUpdate will try to start the new pods before taking down the old ones. Valid values are: RollingUpdate, Recreate. Default is RollingUpdate false team\tstring Team specifies the team who owns this particular app. Usually sourced from the namespace label. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicyâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicy","content":" â†© Parent  The root AccessPolicy for managing zero trust access to your Application. See AccessPolicy for more information.  Name\tType\tDescription\tRequiredinbound\tobject Inbound specifies the ingress rules. Which apps on the cluster can talk to this app? false outbound\tobject Outbound specifies egress rules. Which apps on the cluster and the internet is the Application allowed to send requests to? false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.inboundâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyinbound","content":" â†© Parent  Inbound specifies the ingress rules. Which apps on the cluster can talk to this app?  Name\tType\tDescription\tRequiredrules\t[]object The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces namespace is required true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.inbound.rules[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyinboundrulesindex","content":" â†© Parent  InternalRule  The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces, namespace is required.  Name\tType\tDescription\tRequiredapplication\tstring The name of the Application you are allowing traffic to/from. If you wish to allow traffic from a SKIPJob, this field should be suffixed with -skipjob true namespace\tstring The namespace in which the Application you are allowing traffic to/from resides. If unset, uses namespace of Application. false namespacesByLabel\tmap[string]string Namespace label value-pair in which the Application you are allowing traffic to/from resides. If both namespace and namespacesByLabel are set, namespace takes precedence and namespacesByLabel is omitted. false ports\t[]object The ports to allow for the above application. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.inbound.rules[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyinboundrulesindexportsindex","content":" â†© Parent  NetworkPolicyPort describes a port to allow traffic on  Name\tType\tDescription\tRequiredendPort\tinteger endPort indicates that the range of ports from port to endPort if set, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined or if the port field is defined as a named (string) port. The endPort must be equal or greater than port. Format: int32 false port\tint or string port represents the port on the given protocol. This can either be a numerical or named port on a pod. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched. false protocol\tstring protocol represents the protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.outboundâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyoutbound","content":" â†© Parent  Outbound specifies egress rules. Which apps on the cluster and the internet is the Application allowed to send requests to?  Name\tType\tDescription\tRequiredexternal\t[]object External specifies which applications on the internet the application can reach. Only host is required unless it is on another port than HTTPS port 443. If other ports or protocols are required then ports must be specified as well false rules\t[]object Rules apply the same in-cluster rules as InboundPolicy false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.outbound.external[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyoutboundexternalindex","content":" â†© Parent  ExternalRule  Describes a rule for allowing your Application to route traffic to external applications and hosts.  Name\tType\tDescription\tRequiredhost\tstring The allowed hostname. Note that this does not include subdomains. true ip\tstring Non-HTTP requests (i.e. using the TCP protocol) need to use IP in addition to hostname Only required for TCP requests. Note: Hostname must always be defined even if IP is set statically false ports\t[]object The ports to allow for the above hostname. When not specified HTTP and HTTPS on port 80 and 443 respectively are put into the allowlist false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.outbound.external[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyoutboundexternalindexportsindex","content":" â†© Parent  ExternalPort  A custom port describing an external host  Name\tType\tDescription\tRequiredname\tstring Name is required and is an arbitrary name. Must be unique within all ExternalRule ports. true port\tinteger The port number of the external host true protocol\tenum The protocol to use for communication with the host. Supported protocols are: HTTP, HTTPS, TCP and TLS. Enum: HTTP, HTTPS, TCP, TLS true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.outbound.rules[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyoutboundrulesindex","content":" â†© Parent  InternalRule  The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces, namespace is required.  Name\tType\tDescription\tRequiredapplication\tstring The name of the Application you are allowing traffic to/from. If you wish to allow traffic from a SKIPJob, this field should be suffixed with -skipjob true namespace\tstring The namespace in which the Application you are allowing traffic to/from resides. If unset, uses namespace of Application. false namespacesByLabel\tmap[string]string Namespace label value-pair in which the Application you are allowing traffic to/from resides. If both namespace and namespacesByLabel are set, namespace takes precedence and namespacesByLabel is omitted. false ports\t[]object The ports to allow for the above application. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.accessPolicy.outbound.rules[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecaccesspolicyoutboundrulesindexportsindex","content":" â†© Parent  NetworkPolicyPort describes a port to allow traffic on  Name\tType\tDescription\tRequiredendPort\tinteger endPort indicates that the range of ports from port to endPort if set, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined or if the port field is defined as a named (string) port. The endPort must be equal or greater than port. Format: int32 false port\tint or string port represents the port on the given protocol. This can either be a numerical or named port on a pod. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched. false protocol\tstring protocol represents the protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.additionalPorts[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecadditionalportsindex","content":" â†© Parent  Name\tType\tDescription\tRequiredname\tstring true port\tinteger Format: int32 true protocol\tenum Protocol defines network protocols supported for things like container ports. Enum: TCP, UDP, SCTP true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.authorizationSettingsâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecauthorizationsettings","content":" â†© Parent  Used for allow listing certain default blocked endpoints, such as /actuator/ end points  Name\tType\tDescription\tRequiredallowAll\tboolean Allows all endpoints by not creating an AuthorizationPolicy, and ignores the content of AllowList. If field is false, the contents of AllowList will be used instead if AllowList is set. Default: false false allowList\t[]string Allows specific endpoints. Common endpoints one might want to allow include /actuator/health, /actuator/startup, /actuator/info. Note that endpoints are matched specifically on the input, so if you allow /actuator/health, you will not allow /actuator/health/ false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindex","content":" â†© Parent  EnvVar represents an environment variable present in a Container.  Name\tType\tDescription\tRequiredname\tstring Name of the environment variable. May consist of any printable ASCII characters except '='. true value\tstring Variable references $(VAR_NAME) are expanded using the previously defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. &quot;$$(VAR_NAME)&quot; will produce the string literal &quot;$(VAR_NAME)&quot;. Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to &quot;&quot;. false valueFrom\tobject Source for the environment variable's value. Cannot be used if value is not empty. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFromâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefrom","content":" â†© Parent  Source for the environment variable's value. Cannot be used if value is not empty.  Name\tType\tDescription\tRequiredconfigMapKeyRef\tobject Selects a key of a ConfigMap. false fieldRef\tobject Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels['&lt;KEY&gt;'], metadata.annotations['&lt;KEY&gt;'], spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs. false fileKeyRef\tobject FileKeyRef selects a key of the env file. Requires the EnvFiles feature gate to be enabled. false resourceFieldRef\tobject Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported. false secretKeyRef\tobject Selects a key of a secret in the pod's namespace false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFrom.configMapKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefromconfigmapkeyref","content":" â†© Parent  Selects a key of a ConfigMap.  Name\tType\tDescription\tRequiredkey\tstring The key to select. true name\tstring Name of the referent. This field is effectively required, but due to backwards compatibility is allowed to be empty. Instances of this type with an empty value here are almost certainly wrong. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names Default: `` false optional\tboolean Specify whether the ConfigMap or its key must be defined false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFrom.fieldRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefromfieldref","content":" â†© Parent  Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels['&lt;KEY&gt;'], metadata.annotations['&lt;KEY&gt;'], spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.  Name\tType\tDescription\tRequiredfieldPath\tstring Path of the field to select in the specified API version. true apiVersion\tstring Version of the schema the FieldPath is written in terms of, defaults to &quot;v1&quot;. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFrom.fileKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefromfilekeyref","content":" â†© Parent  FileKeyRef selects a key of the env file. Requires the EnvFiles feature gate to be enabled.  Name\tType\tDescription\tRequiredkey\tstring The key within the env file. An invalid key will prevent the pod from starting. The keys defined within a source may consist of any printable ASCII characters except '='. During Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters. true path\tstring The path within the volume from which to select the file. Must be relative and may not contain the '..' path or start with '..'. true volumeName\tstring The name of the volume mount containing the env file. true optional\tboolean Specify whether the file or its key must be defined. If the file or key does not exist, then the env var is not published. If optional is set to true and the specified key does not exist, the environment variable will not be set in the Pod's containers. If optional is set to false and the specified key does not exist, an error will be returned during Pod creation. Default: false false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFrom.resourceFieldRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefromresourcefieldref","content":" â†© Parent  Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.  Name\tType\tDescription\tRequiredresource\tstring Required: resource to select true containerName\tstring Container name: required for volumes, optional for env vars false divisor\tint or string Specifies the output format of the exposed resources, defaults to &quot;1&quot; false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.env[index].valueFrom.secretKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvindexvaluefromsecretkeyref","content":" â†© Parent  Selects a key of a secret in the pod's namespace  Name\tType\tDescription\tRequiredkey\tstring The key of the secret to select from. Must be a valid secret key. true name\tstring Name of the referent. This field is effectively required, but due to backwards compatibility is allowed to be empty. Instances of this type with an empty value here are almost certainly wrong. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names Default: `` false optional\tboolean Specify whether the Secret or its key must be defined false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.envFrom[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecenvfromindex","content":" â†© Parent  Name\tType\tDescription\tRequiredconfigMap\tstring Name of Kubernetes ConfigMap in which the deployment should mount environment variables from. Must be in the same namespace as the Application false secret\tstring Name of Kubernetes Secret in which the deployment should mount environment variables from. Must be in the same namespace as the Application false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.filesFrom[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecfilesfromindex","content":" â†© Parent  FilesFrom  Struct representing information needed to mount a Kubernetes resource as a file to a Pod's directory. One of ConfigMap, Secret, EmptyDir or PersistentVolumeClaim must be present, and just represent the name of the resource in question NB. Out-of-the-box, skiperator provides a writable 'emptyDir'-volume at '/tmp'  Name\tType\tDescription\tRequiredmountPath\tstring The path to mount the file in the Pods directory. Required. true configMap\tstring false defaultMode\tinteger defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. false emptyDir\tstring false persistentVolumeClaim\tstring false secret\tstring false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.gcpâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecgcp","content":" â†© Parent  GCP is used to configure Google Cloud Platform specific settings for the application.  Name\tType\tDescription\tRequiredauth\tobject Configuration for authenticating a Pod with Google Cloud Platform For authentication with GCP, to use services like Secret Manager and/or Pub/Sub we need to set the GCP Service Account Pods should identify as. To allow this, we need the IAM role iam.workloadIdentityUser set on a GCP service account and bind this to the Pod's Kubernetes SA. Documentation on how this is done can be found here (Closed Wiki):https://kartverket.atlassian.net/wiki/spaces/SKIPDOK/pages/422346824/Autentisering+mot+GCP+som+Kubernetes+SA false cloudSqlProxy\tobject CloudSQL is used to deploy a CloudSQL proxy sidecar in the pod. This is useful for connecting to CloudSQL databases that require Cloud SQL Auth Proxy. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.gcp.authâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecgcpauth","content":" â†© Parent  Configuration for authenticating a Pod with Google Cloud Platform For authentication with GCP, to use services like Secret Manager and/or Pub/Sub we need to set the GCP Service Account Pods should identify as. To allow this, we need the IAM role iam.workloadIdentityUser set on a GCP service account and bind this to the Pod's Kubernetes SA. Documentation on how this is done can be found here (Closed Wiki):https://kartverket.atlassian.net/wiki/spaces/SKIPDOK/pages/422346824/Autentisering+mot+GCP+som+Kubernetes+SA  Name\tType\tDescription\tRequiredserviceAccount\tstring Name of the service account in which you are trying to authenticate your pod with Generally takes the form of some-name@some-project-id.iam.gserviceaccount.com true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.gcp.cloudSqlProxyâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecgcpcloudsqlproxy","content":" â†© Parent  CloudSQL is used to deploy a CloudSQL proxy sidecar in the pod. This is useful for connecting to CloudSQL databases that require Cloud SQL Auth Proxy.  Name\tType\tDescription\tRequiredconnectionName\tstring Connection name for the CloudSQL instance. Found in the Google Cloud Console under your CloudSQL resource. The format is &quot;projectName:region:instanceName&quot; E.g. &quot;skip-prod-bda1:europe-north1:my-db&quot;. true ip\tstring The IP address of the CloudSQL instance. This is used to create a serviceentry for the CloudSQL proxy. true serviceAccount\tstring Service account used by cloudsql auth proxy. This service account must have the roles/cloudsql.client role. true publicIP\tboolean Default: false false version\tstring Image version for the CloudSQL proxy sidecar. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.idportenâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecidporten","content":" â†© Parent  Settings for IDPorten integration with Digitaliseringsdirektoratet  Name\tType\tDescription\tRequiredenabled\tboolean Whether to enable provisioning of an ID-porten client. If enabled, an ID-porten client will be provisioned. true accessTokenLifetime\tinteger AccessTokenLifetime is the lifetime in seconds for any issued access token from ID-porten. If unspecified, defaults to 3600 seconds (1 hour). Minimum: 1 Maximum: 3600 false clientName\tstring The name of the Client as shown in Digitaliseringsdirektoratet's Samarbeidsportal Meant to be a human-readable name for separating clients in the portal. false clientURI\tstring ClientURI is the URL shown to the user at ID-porten when displaying a 'back' button or on errors. false frontchannelLogoutPath\tstring FrontchannelLogoutPath is a valid path for your application where ID-porten sends a request to whenever the user has initiated a logout elsewhere as part of a single logout (front channel logout) process. false integrationType\tenum IntegrationType is used to make sensible choices for your client. Which type of integration you choose will provide guidance on which scopes you can use with the client. A client can only have one integration type. NB! It is not possible to change the integration type after creation. Enum: krr, idporten, api_klient false postLogoutRedirectPath\tstring PostLogoutRedirectPath is a simpler verison of PostLogoutRedirectURIs that will be appended to the ingress false postLogoutRedirectURIs\t[]string PostLogoutRedirectURIs are valid URIs that ID-porten will allow redirecting the end-user to after a single logout has been initiated and performed by the application. false redirectPath\tstring RedirectPath is a valid path that ID-porten redirects back to after a successful authorization request. false requestAuthentication\tobject RequestAuthentication specifies how incoming JWTs should be validated. false scopes\t[]string Register different oauth2 Scopes on your client. You will not be able to add a scope to your client that conflicts with the client's IntegrationType. For example, you can not add a scope that is limited to the IntegrationType krr of IntegrationType idporten, and vice versa. Default for IntegrationType krr = (&quot;krr:global/kontaktinformasjon.read&quot;, &quot;krr:global/digitalpost.read&quot;) Default for IntegrationType idporten = (&quot;openid&quot;, &quot;profile&quot;) IntegrationType api_klient have no Default, checkout Digdir documentation. false sessionLifetime\tinteger SessionLifetime is the maximum lifetime in seconds for any given user's session in your application. The timeout starts whenever the user is redirected from the authorization_endpoint at ID-porten. If unspecified, defaults to 7200 seconds (2 hours). Note: Attempting to refresh the user's access_token beyond this timeout will yield an error. Minimum: 3600 Maximum: 7200 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.idporten.requestAuthenticationâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecidportenrequestauthentication","content":" â†© Parent  RequestAuthentication specifies how incoming JWTs should be validated.  Name\tType\tDescription\tRequiredenabled\tboolean Whether to enable JWT validation. If enabled, incoming JWTs will be validated against the issuer specified in the app registration and the generated audience. true forwardJwt\tboolean If set to true, the original token will be kept for the upstream request. Defaults to true. Default: true false ignorePaths\t[]string IgnorePaths specifies paths that do not require an authenticated JWT. The specified paths must be a valid URI path. It has to start with '/' and cannot end with '/'. The paths can also contain the wildcard operator '*', but only at the end. false outputClaimToHeaders\t[]object This field specifies a list of operations to copy the claim to HTTP headers on a successfully verified token. The header specified in each operation in the list must be unique. Nested claims of type string/int/bool is supported as well. false paths\t[]string Paths specifies paths that require an authenticated JWT. The specified paths must be a valid URI path. It has to start with '/' and cannot end with '/'. The paths can also contain the wildcard operator '*', but only at the end. false secretName\tstring The name of the Kubernetes Secret containing OAuth2 credentials. If omitted, the associated client registration in the application manifest is used for JWT validation. false tokenLocation\tenum Where to find the JWT in the incoming request An enum value of header means that the JWT is present in the Authorization header as a Bearer token. An enum value of cookie means that the JWT is present as a cookie called BearerToken. If omitted, its default value depends on the provider type: Defaults to &quot;cookie&quot; for providers supporting user login (e.g. IDPorten). Defaults to &quot;header&quot; for providers not supporting user login (e.g. Maskinporten). Enum: header, cookie false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.idporten.requestAuthentication.outputClaimToHeaders[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecidportenrequestauthenticationoutputclaimtoheadersindex","content":" â†© Parent  Name\tType\tDescription\tRequiredclaim\tstring The claim to be copied. true header\tstring The name of the HTTP header for which the specified claim will be copied to. true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.istioSettingsâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecistiosettings","content":" â†© Parent  IstioSettings are used to configure istio specific resources such as telemetry. Currently, adjusting sampling interval for tracing is the only supported option. By default, tracing is enabled with a random sampling percentage of 10%.  Name\tType\tDescription\tRequiredretries\tobject Retries is configurable automatic retries for requests towards the application. By default requests falling under: &quot;connect-failure,refused-stream,unavailable,cancelled&quot; will be retried. false telemetry\tobject Telemetry is a placeholder for all relevant telemetry types, and may be extended in the future to configure additional telemetry settings. Default: map[tracing:[map[randomSamplingPercentage:10]]] false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.istioSettings.retriesâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecistiosettingsretries","content":" â†© Parent  Retries is configurable automatic retries for requests towards the application. By default requests falling under: &quot;connect-failure,refused-stream,unavailable,cancelled&quot; will be retried.  Name\tType\tDescription\tRequiredattempts\tinteger Attempts is the number of retries to be allowed for a given request before giving up. The interval between retries will be determined automatically (25ms+). Default is 2 Format: int32 Minimum: 1 false perTryTimeout\tstring PerTryTimeout is the timeout per attempt for a given request, including the initial call and any retries. Format: 1h/1m/1s/1ms. MUST be &gt;=1ms. Default: no timeout Format: duration false retryOnHttpResponseCodes\t[]int or string RetryOnHttpResponseCodes HTTP response codes that should trigger a retry. A typical value is [503]. You may also use 5xx and retriable-4xx (only 409). mixed types are allowed such as [503, &quot;retriable-4xx&quot;] false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.istioSettings.telemetryâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecistiosettingstelemetry","content":" â†© Parent  Telemetry is a placeholder for all relevant telemetry types, and may be extended in the future to configure additional telemetry settings.  Name\tType\tDescription\tRequiredtracing\t[]object Tracing is a list of tracing configurations for the telemetry resource. Normally only one tracing configuration is needed. Default: [map[randomSamplingPercentage:10]] false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.istioSettings.telemetry.tracing[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecistiosettingstelemetrytracingindex","content":" â†© Parent  Tracing contains relevant settings for tracing in the telemetry configuration  Name\tType\tDescription\tRequiredrandomSamplingPercentage\tinteger RandomSamplingPercentage is the percentage of requests that should be sampled for tracing, specified by a whole number between 0-100. Setting RandomSamplingPercentage to 0 will disable tracing. Default: 10 Minimum: 0 Maximum: 100 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.livenessâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecliveness","content":" â†© Parent  Liveness probes define a resource that returns 200 OK when the app is running as intended. Returning a non-200 code will make kubernetes restart the app. Liveness is optional, but when provided, path and port are required  See Probe for structure definition.  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinportenâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinporten","content":" â†© Parent  Settings for Maskinporten integration with Digitaliseringsdirektoratet  Name\tType\tDescription\tRequiredenabled\tboolean If enabled, provisions and configures a Maskinporten client with consumed scopes and/or Exposed scopes with DigDir. true clientName\tstring The name of the Client as shown in Digitaliseringsdirektoratet's Samarbeidsportal Meant to be a human-readable name for separating clients in the portal false requestAuthentication\tobject RequestAuthentication specifies how incoming JWTs should be validated. false scopes\tobject Schema to configure Maskinporten clients with consumed scopes and/or exposed scopes. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.requestAuthenticationâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenrequestauthentication","content":" â†© Parent  RequestAuthentication specifies how incoming JWTs should be validated.  Name\tType\tDescription\tRequiredenabled\tboolean Whether to enable JWT validation. If enabled, incoming JWTs will be validated against the issuer specified in the app registration and the generated audience. true forwardJwt\tboolean If set to true, the original token will be kept for the upstream request. Defaults to true. Default: true false ignorePaths\t[]string IgnorePaths specifies paths that do not require an authenticated JWT. The specified paths must be a valid URI path. It has to start with '/' and cannot end with '/'. The paths can also contain the wildcard operator '*', but only at the end. false outputClaimToHeaders\t[]object This field specifies a list of operations to copy the claim to HTTP headers on a successfully verified token. The header specified in each operation in the list must be unique. Nested claims of type string/int/bool is supported as well. false paths\t[]string Paths specifies paths that require an authenticated JWT. The specified paths must be a valid URI path. It has to start with '/' and cannot end with '/'. The paths can also contain the wildcard operator '*', but only at the end. false secretName\tstring The name of the Kubernetes Secret containing OAuth2 credentials. If omitted, the associated client registration in the application manifest is used for JWT validation. false tokenLocation\tenum Where to find the JWT in the incoming request An enum value of header means that the JWT is present in the Authorization header as a Bearer token. An enum value of cookie means that the JWT is present as a cookie called BearerToken. If omitted, its default value depends on the provider type: Defaults to &quot;cookie&quot; for providers supporting user login (e.g. IDPorten). Defaults to &quot;header&quot; for providers not supporting user login (e.g. Maskinporten). Enum: header, cookie false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.requestAuthentication.outputClaimToHeaders[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenrequestauthenticationoutputclaimtoheadersindex","content":" â†© Parent  Name\tType\tDescription\tRequiredclaim\tstring The claim to be copied. true header\tstring The name of the HTTP header for which the specified claim will be copied to. true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.scopesâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenscopes","content":" â†© Parent  Schema to configure Maskinporten clients with consumed scopes and/or exposed scopes.  Name\tType\tDescription\tRequiredconsumes\t[]object This is the Schema for the consumes and exposes API.consumes is a list of scopes that your client can request access to. false exposes\t[]object exposes is a list of scopes your application want to expose to other organization where access to the scope is based on organization number. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.scopes.consumes[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenscopesconsumesindex","content":" â†© Parent  Name\tType\tDescription\tRequiredname\tstring The scope consumed by the application to gain access to an external organization API. Ensure that the NAV organization has been granted access to the scope prior to requesting access. true  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.scopes.exposes[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenscopesexposesindex","content":" â†© Parent  Name\tType\tDescription\tRequiredenabled\tboolean If Enabled the configured scope is available to be used and consumed by organizations granted access. true name\tstring The actual subscope combined with Product. Ensure that &lt;Product&gt;&lt;Name&gt; matches Pattern. true product\tstring The product-area your application belongs to e.g. arbeid, helse ... This will be included in the final scope nav:&lt;Product&gt;&lt;Name&gt;. true accessibleForAll\tboolean Allow any organization to access the scope. false allowedIntegrations\t[]string Whitelisting of integration's allowed. Default is maskinporten false atMaxAge\tinteger Max time in seconds for a issued access_token. Default is 30 sec. Minimum: 30 Maximum: 680 false consumers\t[]object External consumers granted access to this scope and able to request access_token. false delegationSource\tenum Delegation source for the scope. Default is empty, which means no delegation is allowed. Enum: altinn false separator\tstring Separator is the character that separates product and name in the final scope:scope := &lt;prefix&gt;:&lt;product&gt;&lt;separator&gt;&lt;name&gt;This overrides the default separator. The default separator is :. If name contains /, the default separator is instead /. false visibility\tenum Visibility controls the scope's visibility. Public scopes are visible for everyone. Private scopes are only visible for the organization that owns the scope as well as organizations that have been granted consumer access. Enum: private, public false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.maskinporten.scopes.exposes[index].consumers[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecmaskinportenscopesexposesindexconsumersindex","content":" â†© Parent  Name\tType\tDescription\tRequiredorgno\tstring The external business/organization number. true name\tstring This is a describing field intended for clarity not used for any other purpose. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.podSettingsâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecpodsettings","content":" â†© Parent  PodSettings are used to apply specific settings to the Pod Template used by Skiperator to create Deployments. This allows you to set things like annotations on the Pod to change the behaviour of sidecars, and set relevant Pod options such as TerminationGracePeriodSeconds.  Name\tType\tDescription\tRequiredannotations\tmap[string]string Annotations that are set on Pods created by Skiperator. These annotations can for example be used to change the behaviour of sidecars and similar. false disablePodSpreadTopologyConstraints\tboolean DisablePodSpreadTopologyConstraints specifies whether to disable the addition of Pod Topology Spread Constraints to a given pod. Default: false false terminationGracePeriodSeconds\tinteger TerminationGracePeriodSeconds determines how long Kubernetes waits after a SIGTERM signal sent to a Pod before terminating the pod. If your application uses longer than 30 seconds to terminate, you should increase TerminationGracePeriodSeconds. Format: int64 Default: 30 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.prometheusâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecprometheus","content":" â†© Parent  Optional settings for how Prometheus compatible metrics should be scraped.  Name\tType\tDescription\tRequiredport\tint or string The port number or name where metrics are exposed (at the Pod level). true allowAllMetrics\tboolean Setting AllowAllMetrics to true will ensure all exposed metrics are scraped. Otherwise, a list of predefined metrics will be dropped by default. See util/constants.go for the default list. Default: false false path\tstring The HTTP path where Prometheus compatible metrics exists Default: /metrics false scrapeInterval\tstring ScrapeInterval specifies the interval at which Prometheus should scrape the metrics. The interval must be at least 15 seconds (if using &quot;Xs&quot;) and divisible by 5. If minutes (&quot;Xm&quot;) are used, the value must be at least 1m. Validations: self == '' || self.matches('^([0-9]+[sm])+$'): self == '' || (self.endsWith('m') &amp;&amp; int(self.split('m')[0]) &gt;= 1) || (self.endsWith('s') &amp;&amp; int(self.split('s')[0]) &gt;= 15 &amp;&amp; int(self.split('s')[0]) % 5 == 0): Default: 60s false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.readinessâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecreadiness","content":" â†© Parent  Readiness probes define a resource that returns 200 OK when the app is running as intended. Kubernetes will wait until the resource returns 200 OK before marking the pod as Running and progressing with the deployment strategy. Readiness is optional, but when provided, path and port are required  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.resourcesâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecresources","content":" â†© Parent  ResourceRequirements to apply to the deployment. It's common to set some of these to prevent the app from swelling in resource usage and consuming all the resources of other apps on the cluster.  Name\tType\tDescription\tRequiredlimits\tmap[string]int or string Limits set the maximum the app is allowed to use. Exceeding this limit will make kubernetes kill the app and restart it. Limits can be set on the CPU and memory, but it is not recommended to put a limit on CPU, see: https://home.robusta.dev/blog/stop-using-cpu-limits false requests\tmap[string]int or string Requests set the initial allocation that is done for the app and will thus be available to the app on startup. More is allocated on demand until the limit is reached. Requests can be set on the CPU and memory. false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.startupâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecstartup","content":" â†© Parent  Kubernetes uses startup probes to know when a container application has started. If such a probe is configured, it disables liveness and readiness checks until it succeeds, making sure those probes don't interfere with the application startup. This can be used to adopt liveness checks on slow starting containers, avoiding them getting killed by Kubernetes before they are up and running. Startup is optional, but when provided, path and port are required  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"Application.spec.strategyâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationspecstrategy","content":" â†© Parent  Defines an alternative strategy for the Kubernetes deployment. This is useful when the default strategy, RollingUpdate, is not usable. Setting type to Recreate will take down all the pods before starting new pods, whereas the default of RollingUpdate will try to start the new pods before taking down the old ones.  Valid values are: RollingUpdate, Recreate. Default is RollingUpdate  Name\tType\tDescription\tRequiredtype\tenum Valid values are: RollingUpdate, Recreate. Default is RollingUpdate Enum: RollingUpdate, Recreate Default: RollingUpdate false  ","version":"Next","tagName":"h3"},{"title":"Application.statusâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationstatus","content":" â†© Parent  SkiperatorStatus  A status field shown on a Skiperator resource which contains information regarding deployment of the resource.  Name\tType\tDescription\tRequiredaccessPolicies\tstring Indicates if access policies are valid true conditions\t[]object true subresources\tmap[string]object true summary\tobject Status true  ","version":"Next","tagName":"h3"},{"title":"Application.status.conditions[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationstatusconditionsindex","content":" â†© Parent  Condition contains details for one aspect of the current state of this API Resource.  Name\tType\tDescription\tRequiredlastTransitionTime\tstring lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. Format: date-time true message\tstring message is a human readable message indicating details about the transition. This may be an empty string. true reason\tstring reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. true status\tenum status of the condition, one of True, False, Unknown. Enum: True, False, Unknown true type\tstring type of condition in CamelCase or in foo.example.com/CamelCase. true observedGeneration\tinteger observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. Format: int64 Minimum: 0 false  ","version":"Next","tagName":"h3"},{"title":"Application.status.subresources[key]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationstatussubresourceskey","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true  ","version":"Next","tagName":"h3"},{"title":"Application.status.summaryâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#applicationstatussummary","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true  ","version":"Next","tagName":"h3"},{"title":"Routingâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routing","content":" Name\tType\tDescription\tRequiredapiVersion\tstring\tskiperator.kartverket.no/v1alpha1\ttrue kind\tstring\tRouting\ttrue metadata\tobject\tRefer to the Kubernetes API documentation for the fields of the metadata field.\ttrue spec\tobject true status\tobject SkiperatorStatus A status field shown on a Skiperator resource which contains information regarding deployment of the resource. false  ","version":"Next","tagName":"h2"},{"title":"Routing.specâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingspec","content":" â†© Parent  Name\tType\tDescription\tRequiredhostname\tstring true routes\t[]object true redirectToHTTPS\tboolean Default: true false  ","version":"Next","tagName":"h3"},{"title":"Routing.spec.routes[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingspecroutesindex","content":" â†© Parent  Name\tType\tDescription\tRequiredpathPrefix\tstring true targetApp\tstring true port\tinteger Format: int32 false rewriteUri\tboolean Default: false false  ","version":"Next","tagName":"h3"},{"title":"Routing.statusâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingstatus","content":" â†© Parent  SkiperatorStatus  A status field shown on a Skiperator resource which contains information regarding deployment of the resource.  Name\tType\tDescription\tRequiredaccessPolicies\tstring Indicates if access policies are valid true conditions\t[]object true subresources\tmap[string]object true summary\tobject Status true  ","version":"Next","tagName":"h3"},{"title":"Routing.status.conditions[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingstatusconditionsindex","content":" â†© Parent  Condition contains details for one aspect of the current state of this API Resource.  Name\tType\tDescription\tRequiredlastTransitionTime\tstring lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. Format: date-time true message\tstring message is a human readable message indicating details about the transition. This may be an empty string. true reason\tstring reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. true status\tenum status of the condition, one of True, False, Unknown. Enum: True, False, Unknown true type\tstring type of condition in CamelCase or in foo.example.com/CamelCase. true observedGeneration\tinteger observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. Format: int64 Minimum: 0 false  ","version":"Next","tagName":"h3"},{"title":"Routing.status.subresources[key]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingstatussubresourceskey","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true  ","version":"Next","tagName":"h3"},{"title":"Routing.status.summaryâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#routingstatussummary","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true  ","version":"Next","tagName":"h3"},{"title":"SKIPJobâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjob","content":" SKIPJob is the Schema for the skipjobs API  Name\tType\tDescription\tRequiredapiVersion\tstring\tskiperator.kartverket.no/v1alpha1\ttrue kind\tstring\tSKIPJob\ttrue metadata\tobject\tRefer to the Kubernetes API documentation for the fields of the metadata field.\ttrue spec\tobject SKIPJobSpec defines the desired state of SKIPJob A SKIPJob is either defined as a one-off or a scheduled job. If the Cron field is set for SKIPJob, it may not be removed. If the Cron field is unset, it may not be added. The Container field of a SKIPJob is only mutable if the Cron field is set. If unset, you must delete your SKIPJob to change container settings. Validations: (has(oldSelf.cron) &amp;&amp; has(self.cron)) || (!has(oldSelf.cron) &amp;&amp; !has(self.cron)): After creation of a SKIPJob you may not remove the Cron field if it was previously present, or add it if it was previously omitted. Please delete the SKIPJob to change its nature from a one-off/scheduled job.((!has(self.cron) &amp;&amp; (oldSelf.container == self.container)) || has(self.cron)): The field Container is immutable for one-off jobs. Please delete your SKIPJob to change the containers settings. true status\tobject SkiperatorStatus A status field shown on a Skiperator resource which contains information regarding deployment of the resource. false  ","version":"Next","tagName":"h2"},{"title":"SKIPJob.specâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspec","content":" â†© Parent  SKIPJobSpec defines the desired state of SKIPJob  A SKIPJob is either defined as a one-off or a scheduled job. If the Cron field is set for SKIPJob, it may not be removed. If the Cron field is unset, it may not be added. The Container field of a SKIPJob is only mutable if the Cron field is set. If unset, you must delete your SKIPJob to change container settings.  Name\tType\tDescription\tRequiredcontainer\tobject Settings for the Pods running in the job. Fields are mostly the same as an Application, and are (probably) better documented there. Some fields are omitted, but none added. Once set, you may not change Container without deleting your current SKIPJob true cron\tobject Settings for the Job if you are running a scheduled job. Optional as Jobs may be one-off. false istioSettings\tobject IstioSettings are used to configure istio specific resources such as telemetry. Currently, adjusting sampling interval for tracing is the only supported option. By default, tracing is enabled with a random sampling percentage of 10%. Default: map[telemetry:map[tracing:[map[randomSamplingPercentage:10]]]] false job\tobject Settings for the actual Job. If you use a scheduled job, the settings in here will also specify the template of the job. false prometheus\tobject Prometheus settings for pod running in job. Fields are identical to Application and if set, a podmonitoring object is created. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.containerâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainer","content":" â†© Parent  Settings for the Pods running in the job. Fields are mostly the same as an Application, and are (probably) better documented there. Some fields are omitted, but none added. Once set, you may not change Container without deleting your current SKIPJob  Name\tType\tDescription\tRequiredimage\tstring true accessPolicy\tobject AccessPolicy Zero trust dictates that only applications with a reason for being able to access another resource should be able to reach it. This is set up by default by denying all ingress and egress traffic from the Pods in the Deployment. The AccessPolicy field is an allowlist of other applications and hostnames that are allowed to talk with this Application and which resources this app can talk to false additionalPorts\t[]object false command\t[]string false env\t[]object false envFrom\t[]object false filesFrom\t[]object false gcp\tobject GCP Configuration for interacting with Google Cloud Platform false liveness\tobject Probe Type configuration for all types of Kubernetes probes. false podSettings\tobject PodSettings false priority\tenum Enum: low, medium, high Default: medium false readiness\tobject Probe Type configuration for all types of Kubernetes probes. false resources\tobject ResourceRequirements A simplified version of the Kubernetes native ResourceRequirement field, in which only Limits and Requests are present. For the units used for resources, see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-units-in-kubernetes false restartPolicy\tenum RestartPolicy describes how the container should be restarted. Only one of the following restart policies may be specified. If none of the following policies is specified, the default one is RestartPolicyAlways. Enum: OnFailure, Never Default: Never false startup\tobject Probe Type configuration for all types of Kubernetes probes. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicyâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicy","content":" â†© Parent  AccessPolicy  Zero trust dictates that only applications with a reason for being able to access another resource should be able to reach it. This is set up by default by denying all ingress and egress traffic from the Pods in the Deployment. The AccessPolicy field is an allowlist of other applications and hostnames that are allowed to talk with this Application and which resources this app can talk to  Name\tType\tDescription\tRequiredinbound\tobject Inbound specifies the ingress rules. Which apps on the cluster can talk to this app? false outbound\tobject Outbound specifies egress rules. Which apps on the cluster and the internet is the Application allowed to send requests to? false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.inboundâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyinbound","content":" â†© Parent  Inbound specifies the ingress rules. Which apps on the cluster can talk to this app?  Name\tType\tDescription\tRequiredrules\t[]object The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces namespace is required true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.inbound.rules[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyinboundrulesindex","content":" â†© Parent  InternalRule  The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces, namespace is required.  Name\tType\tDescription\tRequiredapplication\tstring The name of the Application you are allowing traffic to/from. If you wish to allow traffic from a SKIPJob, this field should be suffixed with -skipjob true namespace\tstring The namespace in which the Application you are allowing traffic to/from resides. If unset, uses namespace of Application. false namespacesByLabel\tmap[string]string Namespace label value-pair in which the Application you are allowing traffic to/from resides. If both namespace and namespacesByLabel are set, namespace takes precedence and namespacesByLabel is omitted. false ports\t[]object The ports to allow for the above application. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.inbound.rules[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyinboundrulesindexportsindex","content":" â†© Parent  NetworkPolicyPort describes a port to allow traffic on  Name\tType\tDescription\tRequiredendPort\tinteger endPort indicates that the range of ports from port to endPort if set, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined or if the port field is defined as a named (string) port. The endPort must be equal or greater than port. Format: int32 false port\tint or string port represents the port on the given protocol. This can either be a numerical or named port on a pod. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched. false protocol\tstring protocol represents the protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.outboundâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyoutbound","content":" â†© Parent  Outbound specifies egress rules. Which apps on the cluster and the internet is the Application allowed to send requests to?  Name\tType\tDescription\tRequiredexternal\t[]object External specifies which applications on the internet the application can reach. Only host is required unless it is on another port than HTTPS port 443. If other ports or protocols are required then ports must be specified as well false rules\t[]object Rules apply the same in-cluster rules as InboundPolicy false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.outbound.external[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyoutboundexternalindex","content":" â†© Parent  ExternalRule  Describes a rule for allowing your Application to route traffic to external applications and hosts.  Name\tType\tDescription\tRequiredhost\tstring The allowed hostname. Note that this does not include subdomains. true ip\tstring Non-HTTP requests (i.e. using the TCP protocol) need to use IP in addition to hostname Only required for TCP requests. Note: Hostname must always be defined even if IP is set statically false ports\t[]object The ports to allow for the above hostname. When not specified HTTP and HTTPS on port 80 and 443 respectively are put into the allowlist false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.outbound.external[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyoutboundexternalindexportsindex","content":" â†© Parent  ExternalPort  A custom port describing an external host  Name\tType\tDescription\tRequiredname\tstring Name is required and is an arbitrary name. Must be unique within all ExternalRule ports. true port\tinteger The port number of the external host true protocol\tenum The protocol to use for communication with the host. Supported protocols are: HTTP, HTTPS, TCP and TLS. Enum: HTTP, HTTPS, TCP, TLS true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.outbound.rules[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyoutboundrulesindex","content":" â†© Parent  InternalRule  The rules list specifies a list of applications. When no namespace is specified it refers to an app in the current namespace. For apps in other namespaces, namespace is required.  Name\tType\tDescription\tRequiredapplication\tstring The name of the Application you are allowing traffic to/from. If you wish to allow traffic from a SKIPJob, this field should be suffixed with -skipjob true namespace\tstring The namespace in which the Application you are allowing traffic to/from resides. If unset, uses namespace of Application. false namespacesByLabel\tmap[string]string Namespace label value-pair in which the Application you are allowing traffic to/from resides. If both namespace and namespacesByLabel are set, namespace takes precedence and namespacesByLabel is omitted. false ports\t[]object The ports to allow for the above application. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.accessPolicy.outbound.rules[index].ports[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineraccesspolicyoutboundrulesindexportsindex","content":" â†© Parent  NetworkPolicyPort describes a port to allow traffic on  Name\tType\tDescription\tRequiredendPort\tinteger endPort indicates that the range of ports from port to endPort if set, inclusive, should be allowed by the policy. This field cannot be defined if the port field is not defined or if the port field is defined as a named (string) port. The endPort must be equal or greater than port. Format: int32 false port\tint or string port represents the port on the given protocol. This can either be a numerical or named port on a pod. If this field is not provided, this matches all port names and numbers. If present, only traffic on the specified protocol AND port will be matched. false protocol\tstring protocol represents the protocol (TCP, UDP, or SCTP) which traffic must match. If not specified, this field defaults to TCP. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.additionalPorts[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontaineradditionalportsindex","content":" â†© Parent  Name\tType\tDescription\tRequiredname\tstring true port\tinteger Format: int32 true protocol\tenum Protocol defines network protocols supported for things like container ports. Enum: TCP, UDP, SCTP true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindex","content":" â†© Parent  EnvVar represents an environment variable present in a Container.  Name\tType\tDescription\tRequiredname\tstring Name of the environment variable. May consist of any printable ASCII characters except '='. true value\tstring Variable references $(VAR_NAME) are expanded using the previously defined environment variables in the container and any service environment variables. If a variable cannot be resolved, the reference in the input string will be unchanged. Double $$ are reduced to a single $, which allows for escaping the $(VAR_NAME) syntax: i.e. &quot;$$(VAR_NAME)&quot; will produce the string literal &quot;$(VAR_NAME)&quot;. Escaped references will never be expanded, regardless of whether the variable exists or not. Defaults to &quot;&quot;. false valueFrom\tobject Source for the environment variable's value. Cannot be used if value is not empty. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFromâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefrom","content":" â†© Parent  Source for the environment variable's value. Cannot be used if value is not empty.  Name\tType\tDescription\tRequiredconfigMapKeyRef\tobject Selects a key of a ConfigMap. false fieldRef\tobject Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels['&lt;KEY&gt;'], metadata.annotations['&lt;KEY&gt;'], spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs. false fileKeyRef\tobject FileKeyRef selects a key of the env file. Requires the EnvFiles feature gate to be enabled. false resourceFieldRef\tobject Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported. false secretKeyRef\tobject Selects a key of a secret in the pod's namespace false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFrom.configMapKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefromconfigmapkeyref","content":" â†© Parent  Selects a key of a ConfigMap.  Name\tType\tDescription\tRequiredkey\tstring The key to select. true name\tstring Name of the referent. This field is effectively required, but due to backwards compatibility is allowed to be empty. Instances of this type with an empty value here are almost certainly wrong. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names Default: `` false optional\tboolean Specify whether the ConfigMap or its key must be defined false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFrom.fieldRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefromfieldref","content":" â†© Parent  Selects a field of the pod: supports metadata.name, metadata.namespace, metadata.labels['&lt;KEY&gt;'], metadata.annotations['&lt;KEY&gt;'], spec.nodeName, spec.serviceAccountName, status.hostIP, status.podIP, status.podIPs.  Name\tType\tDescription\tRequiredfieldPath\tstring Path of the field to select in the specified API version. true apiVersion\tstring Version of the schema the FieldPath is written in terms of, defaults to &quot;v1&quot;. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFrom.fileKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefromfilekeyref","content":" â†© Parent  FileKeyRef selects a key of the env file. Requires the EnvFiles feature gate to be enabled.  Name\tType\tDescription\tRequiredkey\tstring The key within the env file. An invalid key will prevent the pod from starting. The keys defined within a source may consist of any printable ASCII characters except '='. During Alpha stage of the EnvFiles feature gate, the key size is limited to 128 characters. true path\tstring The path within the volume from which to select the file. Must be relative and may not contain the '..' path or start with '..'. true volumeName\tstring The name of the volume mount containing the env file. true optional\tboolean Specify whether the file or its key must be defined. If the file or key does not exist, then the env var is not published. If optional is set to true and the specified key does not exist, the environment variable will not be set in the Pod's containers. If optional is set to false and the specified key does not exist, an error will be returned during Pod creation. Default: false false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFrom.resourceFieldRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefromresourcefieldref","content":" â†© Parent  Selects a resource of the container: only resources limits and requests (limits.cpu, limits.memory, limits.ephemeral-storage, requests.cpu, requests.memory and requests.ephemeral-storage) are currently supported.  Name\tType\tDescription\tRequiredresource\tstring Required: resource to select true containerName\tstring Container name: required for volumes, optional for env vars false divisor\tint or string Specifies the output format of the exposed resources, defaults to &quot;1&quot; false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.env[index].valueFrom.secretKeyRefâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvindexvaluefromsecretkeyref","content":" â†© Parent  Selects a key of a secret in the pod's namespace  Name\tType\tDescription\tRequiredkey\tstring The key of the secret to select from. Must be a valid secret key. true name\tstring Name of the referent. This field is effectively required, but due to backwards compatibility is allowed to be empty. Instances of this type with an empty value here are almost certainly wrong. More info: https://kubernetes.io/docs/concepts/overview/working-with-objects/names/#names Default: `` false optional\tboolean Specify whether the Secret or its key must be defined false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.envFrom[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerenvfromindex","content":" â†© Parent  Name\tType\tDescription\tRequiredconfigMap\tstring Name of Kubernetes ConfigMap in which the deployment should mount environment variables from. Must be in the same namespace as the Application false secret\tstring Name of Kubernetes Secret in which the deployment should mount environment variables from. Must be in the same namespace as the Application false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.filesFrom[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerfilesfromindex","content":" â†© Parent  FilesFrom  Struct representing information needed to mount a Kubernetes resource as a file to a Pod's directory. One of ConfigMap, Secret, EmptyDir or PersistentVolumeClaim must be present, and just represent the name of the resource in question NB. Out-of-the-box, skiperator provides a writable 'emptyDir'-volume at '/tmp'  Name\tType\tDescription\tRequiredmountPath\tstring The path to mount the file in the Pods directory. Required. true configMap\tstring false defaultMode\tinteger defaultMode is optional: mode bits used to set permissions on created files by default. Must be an octal value between 0000 and 0777 or a decimal value between 0 and 511. YAML accepts both octal and decimal values, JSON requires decimal values for mode bits. Defaults to 0644. Directories within the path are not affected by this setting. This might be in conflict with other options that affect the file mode, like fsGroup, and the result can be other mode bits set. false emptyDir\tstring false persistentVolumeClaim\tstring false secret\tstring false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.gcpâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainergcp","content":" â†© Parent  GCP  Configuration for interacting with Google Cloud Platform  Name\tType\tDescription\tRequiredauth\tobject Configuration for authenticating a Pod with Google Cloud Platform For authentication with GCP, to use services like Secret Manager and/or Pub/Sub we need to set the GCP Service Account Pods should identify as. To allow this, we need the IAM role iam.workloadIdentityUser set on a GCP service account and bind this to the Pod's Kubernetes SA. Documentation on how this is done can be found here (Closed Wiki):https://kartverket.atlassian.net/wiki/spaces/SKIPDOK/pages/422346824/Autentisering+mot+GCP+som+Kubernetes+SA false cloudSqlProxy\tobject CloudSQL is used to deploy a CloudSQL proxy sidecar in the pod. This is useful for connecting to CloudSQL databases that require Cloud SQL Auth Proxy. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.gcp.authâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainergcpauth","content":" â†© Parent  Configuration for authenticating a Pod with Google Cloud Platform For authentication with GCP, to use services like Secret Manager and/or Pub/Sub we need to set the GCP Service Account Pods should identify as. To allow this, we need the IAM role iam.workloadIdentityUser set on a GCP service account and bind this to the Pod's Kubernetes SA. Documentation on how this is done can be found here (Closed Wiki):https://kartverket.atlassian.net/wiki/spaces/SKIPDOK/pages/422346824/Autentisering+mot+GCP+som+Kubernetes+SA  Name\tType\tDescription\tRequiredserviceAccount\tstring Name of the service account in which you are trying to authenticate your pod with Generally takes the form of some-name@some-project-id.iam.gserviceaccount.com true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.gcp.cloudSqlProxyâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainergcpcloudsqlproxy","content":" â†© Parent  CloudSQL is used to deploy a CloudSQL proxy sidecar in the pod. This is useful for connecting to CloudSQL databases that require Cloud SQL Auth Proxy.  Name\tType\tDescription\tRequiredconnectionName\tstring Connection name for the CloudSQL instance. Found in the Google Cloud Console under your CloudSQL resource. The format is &quot;projectName:region:instanceName&quot; E.g. &quot;skip-prod-bda1:europe-north1:my-db&quot;. true ip\tstring The IP address of the CloudSQL instance. This is used to create a serviceentry for the CloudSQL proxy. true serviceAccount\tstring Service account used by cloudsql auth proxy. This service account must have the roles/cloudsql.client role. true publicIP\tboolean Default: false false version\tstring Image version for the CloudSQL proxy sidecar. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.livenessâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerliveness","content":" â†© Parent  Probe  Type configuration for all types of Kubernetes probes.  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.podSettingsâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerpodsettings","content":" â†© Parent  PodSettings  Name\tType\tDescription\tRequiredannotations\tmap[string]string Annotations that are set on Pods created by Skiperator. These annotations can for example be used to change the behaviour of sidecars and similar. false disablePodSpreadTopologyConstraints\tboolean DisablePodSpreadTopologyConstraints specifies whether to disable the addition of Pod Topology Spread Constraints to a given pod. Default: false false terminationGracePeriodSeconds\tinteger TerminationGracePeriodSeconds determines how long Kubernetes waits after a SIGTERM signal sent to a Pod before terminating the pod. If your application uses longer than 30 seconds to terminate, you should increase TerminationGracePeriodSeconds. Format: int64 Default: 30 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.readinessâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerreadiness","content":" â†© Parent  Probe  Type configuration for all types of Kubernetes probes.  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.resourcesâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerresources","content":" â†© Parent  ResourceRequirements  A simplified version of the Kubernetes native ResourceRequirement field, in which only Limits and Requests are present. For the units used for resources, see https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/#resource-units-in-kubernetes  Name\tType\tDescription\tRequiredlimits\tmap[string]int or string Limits set the maximum the app is allowed to use. Exceeding this limit will make kubernetes kill the app and restart it. Limits can be set on the CPU and memory, but it is not recommended to put a limit on CPU, see: https://home.robusta.dev/blog/stop-using-cpu-limits false requests\tmap[string]int or string Requests set the initial allocation that is done for the app and will thus be available to the app on startup. More is allocated on demand until the limit is reached. Requests can be set on the CPU and memory. false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.container.startupâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccontainerstartup","content":" â†© Parent  Probe  Type configuration for all types of Kubernetes probes.  Name\tType\tDescription\tRequiredpath\tstring The path to access on the HTTP server true port\tint or string Number of the port to access on the container true failureThreshold\tinteger Minimum consecutive failures for the probe to be considered failed after having succeeded. Defaults to 3. Minimum value is 1 Format: int32 Default: 3 false initialDelay\tinteger Delay sending the first probe by X seconds. Can be useful for applications that are slow to start. Format: int32 Default: 0 false period\tinteger Number of seconds Kubernetes waits between each probe. Defaults to 10 seconds. Format: int32 Default: 10 false successThreshold\tinteger Minimum consecutive successes for the probe to be considered successful after having failed. Defaults to 1. Must be 1 for liveness and startup Probes. Minimum value is 1. Format: int32 Default: 1 false timeout\tinteger Number of seconds after which the probe times out. Defaults to 1 second. Minimum value is 1 Format: int32 Default: 1 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.cronâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspeccron","content":" â†© Parent  Settings for the Job if you are running a scheduled job. Optional as Jobs may be one-off.  Name\tType\tDescription\tRequiredschedule\tstring A CronJob string for denoting the schedule of this job. See https://crontab.guru/ for help creating CronJob strings. Kubernetes CronJobs also include the extended &quot;Vixie cron&quot; step values: https://man.freebsd.org/cgi/man.cgi?crontab%285%29. true allowConcurrency\tenum Denotes how Kubernetes should react to multiple instances of the Job being started at the same time. Allow will allow concurrent jobs. Forbid will not allow this, and instead skip the newer schedule Job. Replace will replace the current active Job with the newer scheduled Job. Enum: Allow, Forbid, Replace Default: Allow false startingDeadlineSeconds\tinteger Denotes the deadline in seconds for starting a job on its schedule, if for some reason the Job's controller was not ready upon the scheduled time. If unset, Jobs missing their deadline will be considered failed jobs and will not start. Format: int64 false suspend\tboolean If set to true, this tells Kubernetes to suspend this Job till the field is set to false. If the Job is active while this field is set to true, all running Pods will be terminated. false timeZone\tstring The time zone name for the given schedule, see https://en.wikipedia.org/wiki/List_of_tz_database_time_zones. If not specified, this will default to the time zone of the cluster. Example: &quot;Europe/Oslo&quot; false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.istioSettingsâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspecistiosettings","content":" â†© Parent  IstioSettings are used to configure istio specific resources such as telemetry. Currently, adjusting sampling interval for tracing is the only supported option. By default, tracing is enabled with a random sampling percentage of 10%.  Name\tType\tDescription\tRequiredtelemetry\tobject Telemetry is a placeholder for all relevant telemetry types, and may be extended in the future to configure additional telemetry settings. Default: map[tracing:[map[randomSamplingPercentage:10]]] false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.istioSettings.telemetryâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspecistiosettingstelemetry","content":" â†© Parent  Telemetry is a placeholder for all relevant telemetry types, and may be extended in the future to configure additional telemetry settings.  Name\tType\tDescription\tRequiredtracing\t[]object Tracing is a list of tracing configurations for the telemetry resource. Normally only one tracing configuration is needed. Default: [map[randomSamplingPercentage:10]] false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.istioSettings.telemetry.tracing[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspecistiosettingstelemetrytracingindex","content":" â†© Parent  Tracing contains relevant settings for tracing in the telemetry configuration  Name\tType\tDescription\tRequiredrandomSamplingPercentage\tinteger RandomSamplingPercentage is the percentage of requests that should be sampled for tracing, specified by a whole number between 0-100. Setting RandomSamplingPercentage to 0 will disable tracing. Default: 10 Minimum: 0 Maximum: 100 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.jobâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspecjob","content":" â†© Parent  Settings for the actual Job. If you use a scheduled job, the settings in here will also specify the template of the job.  Name\tType\tDescription\tRequiredactiveDeadlineSeconds\tinteger ActiveDeadlineSeconds denotes a duration in seconds started from when the job is first active. If the deadline is reached during the job's workload the job and its Pods are terminated. If the job is suspended using the Suspend field, this timer is stopped and reset when unsuspended. Format: int64 false backoffLimit\tinteger Specifies the number of retry attempts before determining the job as failed. Defaults to 6. Format: int32 false suspend\tboolean If set to true, this tells Kubernetes to suspend this Job till the field is set to false. If the Job is active while this field is set to false, all running Pods will be terminated. false ttlSecondsAfterFinished\tinteger The number of seconds to wait before removing the Job after it has finished. If unset, Job will not be cleaned up. It is recommended to set this to avoid clutter in your resource tree. Format: int32 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.spec.prometheusâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobspecprometheus","content":" â†© Parent  Prometheus settings for pod running in job. Fields are identical to Application and if set, a podmonitoring object is created.  Name\tType\tDescription\tRequiredport\tint or string The port number or name where metrics are exposed (at the Pod level). true allowAllMetrics\tboolean Setting AllowAllMetrics to true will ensure all exposed metrics are scraped. Otherwise, a list of predefined metrics will be dropped by default. See util/constants.go for the default list. Default: false false path\tstring The HTTP path where Prometheus compatible metrics exists Default: /metrics false scrapeInterval\tstring ScrapeInterval specifies the interval at which Prometheus should scrape the metrics. The interval must be at least 15 seconds (if using &quot;Xs&quot;) and divisible by 5. If minutes (&quot;Xm&quot;) are used, the value must be at least 1m. Validations: self == '' || self.matches('^([0-9]+[sm])+$'): self == '' || (self.endsWith('m') &amp;&amp; int(self.split('m')[0]) &gt;= 1) || (self.endsWith('s') &amp;&amp; int(self.split('s')[0]) &gt;= 15 &amp;&amp; int(self.split('s')[0]) % 5 == 0): Default: 60s false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.statusâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobstatus","content":" â†© Parent  SkiperatorStatus  A status field shown on a Skiperator resource which contains information regarding deployment of the resource.  Name\tType\tDescription\tRequiredaccessPolicies\tstring Indicates if access policies are valid true conditions\t[]object true subresources\tmap[string]object true summary\tobject Status true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.status.conditions[index]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobstatusconditionsindex","content":" â†© Parent  Condition contains details for one aspect of the current state of this API Resource.  Name\tType\tDescription\tRequiredlastTransitionTime\tstring lastTransitionTime is the last time the condition transitioned from one status to another. This should be when the underlying condition changed. If that is not known, then using the time when the API field changed is acceptable. Format: date-time true message\tstring message is a human readable message indicating details about the transition. This may be an empty string. true reason\tstring reason contains a programmatic identifier indicating the reason for the condition's last transition. Producers of specific condition types may define expected values and meanings for this field, and whether the values are considered a guaranteed API. The value should be a CamelCase string. This field may not be empty. true status\tenum status of the condition, one of True, False, Unknown. Enum: True, False, Unknown true type\tstring type of condition in CamelCase or in foo.example.com/CamelCase. true observedGeneration\tinteger observedGeneration represents the .metadata.generation that the condition was set based upon. For instance, if .metadata.generation is currently 12, but the .status.conditions[x].observedGeneration is 9, the condition is out of date with respect to the current state of the instance. Format: int64 Minimum: 0 false  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.status.subresources[key]â€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobstatussubresourceskey","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true  ","version":"Next","tagName":"h3"},{"title":"SKIPJob.status.summaryâ€‹","type":1,"pageTitle":"API Reference","url":"/docs/applikasjon-utrulling/skiperator/api-docs#skipjobstatussummary","content":" â†© Parent  Status  Name\tType\tDescription\tRequiredmessage\tstring Default: hello true status\tstring Default: Synced true timestamp\tstring Default: hello true ","version":"Next","tagName":"h3"},{"title":"Autentisering mot GCP fra applikasjon","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/autentisering-mot-gcp-fra-applikasjon","content":"","keywords":"","version":"Next"},{"title":"1. Opprett Servicekontoâ€‹","type":1,"pageTitle":"Autentisering mot GCP fra applikasjon","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/autentisering-mot-gcp-fra-applikasjon#1-opprett-servicekonto","content":" Dersom man Ã¸nsker Ã¥ fÃ¥ tilgang til GCP-tjenester fra Kubernetes gjÃ¸res dette med Ã¥ fÃ¸rst opprette en servicekonto i GCP og Ã¥ gi den IAM-rettigheter til det man Ã¸nsker at den skal gjÃ¸re.  Servicekontoer bÃ¸r enten opprettes med terraform eller via gcp-service-accounts repoet til SKIP.  ","version":"Next","tagName":"h2"},{"title":"2. Gi WIF IAM Policy til Servicekontoâ€‹","type":1,"pageTitle":"Autentisering mot GCP fra applikasjon","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/autentisering-mot-gcp-fra-applikasjon#2-gi-wif-iam-policy-til-servicekonto","content":" For Ã¥ autentisere som denne GCP-servicekontoen fra Kubernetes mÃ¥ Kubernetes-servicekontoen gis tilganger til det. Dette gjÃ¸res ved Ã¥ gi Kubernetes-servicekontoen rollen iam.workloadIdentityUser.  Gitt variablene:  GCP_SA_NAME - Navnet pÃ¥ GCP servicekontoen GCP_SA_PROJECT_ID - GCP Project ID til prosjektet GCP SA ligger i KUBERNETES_PROJECT_ID - GCP Project ID for Kubernetes-cluster (for eksempel `kubernetes-dev-94b9` for dev-clusteret) KUBERNETES_NAMESPACE - Kubernetes namespace hvor servicekontoen er opprettet KUBERNETES_SA_NAME - Navnet pÃ¥ Kubernetes service accounten som brukes av en Pod (Vanligvis samme som applikasjonsnavnet, men med et suffix -skipjob for SKIPJob'er)   KjÃ¸r fÃ¸lgende kommando med gcloud CLI:  gcloud iam service-accounts add-iam-policy-binding \\ GCP_SA_NAME@GCP_SA_PROJECT_ID.iam.gserviceaccount.com \\ --role=roles/iam.workloadIdentityUser \\ --member=&quot;serviceAccount:KUBERNETES_PROJECT_ID.svc.id.goog[KUBERNETES_NAMESPACE/KUBERNETES_SA_NAME]&quot;   ","version":"Next","tagName":"h2"},{"title":"3. Legg inn config i Skiperatormanifestâ€‹","type":1,"pageTitle":"Autentisering mot GCP fra applikasjon","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/autentisering-mot-gcp-fra-applikasjon#3-legg-inn-config-i-skiperatormanifest","content":" Til slutt legger man til gcp config i sin skiperator Application for Ã¥ lage kubernetes-config slik at podden kan autentisere mot GCP.  //yaml format spec: gcp: auth: serviceAccount: GCP_SA_NAME@GCP_SA_PROJECT_ID.iam.gserviceaccount.com   NÃ¥ kan man fÃ¸lge â€œAuthenticate from your codeâ€ under https://cloud.google.com/anthos/fleet-management/docs/use-workload-identity#-python for Ã¥ autentisere mot GCP fra koden sin.  NÃ¥r dette er gjort kan applikasjonen snakke med GCP under runtime.  ","version":"Next","tagName":"h2"},{"title":"Alternativ til 1 / 2â€‹","type":1,"pageTitle":"Autentisering mot GCP fra applikasjon","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/autentisering-mot-gcp-fra-applikasjon#alternativ-til-1--2","content":" Dersom man ikke Ã¸nsker Ã¥ legge til roller manuelt har SKIP lagt til en ny mÃ¥te Ã¥ legge til Workload Identity User pÃ¥ en service account, ved hjelp av Crossplane.  apiVersion: 'skip.kartverket.no/v1alpha1' kind: 'WorkloadIdentityInstance' metadata: name: 'service-account-wi' spec: parameters: gcpKubernetesProject: 'some-kubernetes-project' #eks: 'kubernetes-dev-94b9' gcpProject: 'gcp-project-where-service-account-is' #eks: 'dsa-dev-e32c' gcpServiceAccount: 'name-of-service-account-in-gcp' #eks: 'dsa-runtime@dsa-dev-e32c.iam.gserviceaccount.com' serviceAccount: 'name-of-service-account-in-kubernetes' #eks 'dsa-backend', typically same name as your Application   Se Provisjonere infrastruktur med Crossplane om du ikke har brukt Crossplane tidligere. ","version":"Next","tagName":"h2"},{"title":"Bruk av porter i pods","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/bruk-av-porter-i-pods","content":"Bruk av porter i pods Porter under 1024 er priviligierte og krever at prosessen som kjÃ¸rer kjÃ¸rer som root. Dette er ikke tillatt pÃ¥ SKIP, og prosessen mÃ¥ derfor binde til en hÃ¸yere port. Dette betyr at man ofte mÃ¥ gjÃ¸re tilpasninger pÃ¥ Docker-imaget man bygger slik at f.eks. nginx binder til en annen port. NÃ¥r prosessen i containeren binder seg til en upriviligert port, kan man spesifisere denne porten i Skiperator-manifestet slik som under. I bakgrunnen vil Skiperator ta seg av Ã¥ lage en Kubernetes-service for denne porten slik at trafikken kan rutes til riktig sted. apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: teamname-frontend namespace: yournamespace spec: image: &quot;kartverket/eksempel-image&quot; port: 8080 additionalPorts: - name: metrics-port port: 8181 protocol: TCP - name: another-port port: 8090 protocol: TCP En annen ting Ã¥ merke seg her er muligheten for Ã¥ spesifisere ekstra porter som kan benyttes til andre formÃ¥l som f.eks. helsesjekker eller prometheus-metrikker. Disse portene vil automatisk fÃ¥ opprettet en service, men det er fortsatt kun hovedporten som kobles opp mot en ingress-gateway. PÃ¥ den mÃ¥ten kan man skille ut endepunktet som ikke trengs eksternt.","keywords":"","version":"Next"},{"title":"Certificates outside ACME","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme","content":"","keywords":"","version":"Next"},{"title":"Create certificate secret resource in istio-gatewaysâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#create-certificate-secret-resource-in-istio-gateways","content":" To be able to use a custom certificate we need a secret to mount to the gateway resource. This is a kubernetes.io/tls type secret and can be created via external secrets like this:  apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: star-matrikkel namespace: istio-gateways spec: dataFrom: - extract: conversionStrategy: Default decodingStrategy: Auto key: star-matrikkel-no-key refreshInterval: 1h secretStoreRef: kind: SecretStore name: gsm target: creationPolicy: Owner deletionPolicy: Retain name: star-matrikkel # Secret in Kubernetes template: engineVersion: v2 mergePolicy: Replace type: kubernetes.io/tls   This fetches the secret from Google Secret Manager. This secret should look like this:  { &quot;tls.crt&quot;:&quot;[base64 encoded cert chain]&quot;, &quot;tls.key&quot;:&quot;[base64 encoded tls.key]&quot; }   ","version":"Next","tagName":"h2"},{"title":"Edit the gateway resourceâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#edit-the-gateway-resource","content":" The gateway resource should then be updated with the new secret:  apiVersion: networking.istio.io/v1beta1 kind: Gateway metadata: name: gateway-ingress namespace: matrikkel-keycloak spec: selector: app: istio-ingress-external servers: - hosts: - auth.matrikkel.no port: name: http number: 80 protocol: HTTP - hosts: - auth.matrikkel.no port: name: https number: 443 protocol: HTTPS tls: credentialName: star-matrikkel # Secret created by externalsecret mode: SIMPLE   ","version":"Next","tagName":"h2"},{"title":"If Skiperator is the gateway creatorâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#if-skiperator-is-the-gateway-creator","content":" When the gateway is created via Skiperator it will have a credentialName corresponding to the secret created by the certificate from Skiperator. Skiperator will reset configurations to its resources unless the resource labeled â€œskiperator.kartverket.no/ignore: &quot;true&quot;â€œ. This will make skiperator ignore this specific resource during reconciliation loops.  apiVersion: networking.istio.io/v1beta1 kind: Gateway metadata: labels: skiperator.kartverket.no/ignore: &quot;true&quot;   This is meant to be a temporary solution, and ACME is the prefered way to get certificates in SKIP.  ","version":"Next","tagName":"h3"},{"title":"Change to ACME certificateâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#change-to-acme-certificate","content":" ","version":"Next","tagName":"h2"},{"title":"Non-Skiperator appsâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#non-skiperator-apps","content":" Using ACME certificate on a non skiperator app requires a certificate resource, and using the resulting secret in the gateway. This resource must be created in the istio-gateways namespace and therefore in the skip-apps :  apiVersion: cert-manager.io/v1 kind: Certificate metadata: name: certificate-name namespace: istio-gateways spec: dnsNames: - appname.kartverket.no issuerRef: kind: ClusterIssuer name: cluster-issuer secretName: desired-secret-name   After this is created and the secret is created, the gateway resource can be edited, and spec.tls.credentialName set to the secret.  ","version":"Next","tagName":"h3"},{"title":"Skiperator appsâ€‹","type":1,"pageTitle":"Certificates outside ACME","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/certificates-outside-acme#skiperator-apps","content":" Remove the â€œskiperator.kartverket.no/ignore: &quot;true&quot;â€œ label, and skiperator will handle the rest. ","version":"Next","tagName":"h3"},{"title":"Jobbe med Kubernetes cluster","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/jobbe-med-cluster","content":"","keywords":"","version":"Next"},{"title":"K9sâ€‹","type":1,"pageTitle":"Jobbe med Kubernetes cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/jobbe-med-cluster#k9s","content":" K9s er terminalbasert men gir deg mer informasjon enn du ellers ville fÃ¥tt ved enkle kubectl kommandoer. Se her en oversikt over alle Podder som kjÃ¸rer i et namespace.    Her fÃ¥r vi for eksempel en stor toast pÃ¥ at alle poddene kjÃ¸rer med mer minne enn de requester. I tillegg har vi en fin oversikt over generell ressursbruk og forhold mellom request/limit og faktisk bruk.  Man kan enkelt sortere pÃ¥ alle felter, sÃ¸ke pÃ¥ vilkÃ¥rlige ressurstyper, redigere ressurser, filtere basert pÃ¥ sÃ¸k og masse mer.  Nedlasting: K9s - Manage Your Kubernetes Clusters In Style  ","version":"Next","tagName":"h2"},{"title":"Freelensâ€‹","type":1,"pageTitle":"Jobbe med Kubernetes cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/jobbe-med-cluster#freelens","content":" Om man heller foretrekker GUI kan dette vÃ¦re et alternativ. En fersk fork og videreutvikling av Openlens.    Freelens nettside  Nedlasting: Freelens Github ","version":"Next","tagName":"h2"},{"title":"Logge inn pÃ¥ cluster","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster","content":"","keywords":"","version":"Next"},{"title":"1. Logg inn med gcloudâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#1-logg-inn-med-gcloud","content":" Hvis du ikke har logget inn med gcloud allerede mÃ¥ du logge inn  gcloud auth login   ","version":"Next","tagName":"h3"},{"title":"2. Finn og velg riktig GCP-prosjektâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#2-finn-og-velg-riktig-gcp-prosjekt","content":" FÃ¸rst, list opp tilgjengelige prosjekter for Ã¥ finne riktig ett:  gcloud projects list   GCP-prosjektet vil vÃ¦re et kubernetes-prosjekt med format kubernetes-&lt;env&gt;-xxxx. Jobber du f.eks. i dsa-dev-e32c velger du kubernetes-dev-94b9 (samme env).  Sett riktig prosjekt:  gcloud config set project kubernetes-dev-94b9   ","version":"Next","tagName":"h3"},{"title":"3. Finn riktig clusternavnâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#3-finn-riktig-clusternavn","content":" List opp tilgjengelige clusters:  gcloud container hub memberships list   Clusternavn-format:  On-prem: &lt;cluster&gt;-&lt;env&gt;-user-cluster (f.eks. atkv3-dev-user-cluster)GCP: &lt;cluster&gt;-&lt;env&gt; (f.eks. atgcp1-dev)  ","version":"Next","tagName":"h3"},{"title":"4. Logg inn pÃ¥ clusteretâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#4-logg-inn-pÃ¥-clusteret","content":" Generer kubeconfig og sett som aktiv context:  On-premiseâ€‹  gcloud container hub memberships get-credentials atkv3-dev-user-cluster   GCPâ€‹  gcloud container clusters get-credentials atgcp1-dev --region europe-north1 --project kubernetes-dev-94b9   Denne kommandoen oppretter en ny context som kan autentisere deg mot clusteret. Kommandoen er forskjellig mellom on-prem og GCP fordi man ikke behÃ¸ver Ã¥ gÃ¥ gjennom Connect gateway for Ã¥ koble til skyclustre.  Context-format som opprettes:  For on-prem: connectgateway_kubernetes-&lt;env&gt;-xxxx_europe-north1_&lt;clusternavn&gt;For GCP: gke_&lt;prosjektnavn&gt;_&lt;regionnavn&gt;_&lt;clusternavn&gt;  Eksempel on-prem: connectgateway_kubernetes-dev-94b9_europe-north1_atkv3-dev-user-clusterEksempel GCP: gke_kubernetes-dev-94b9_europe-north1_atgcp1-dev  ","version":"Next","tagName":"h3"},{"title":"5. Bytte til riktig contextâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#5-bytte-til-riktig-context","content":" Hvis du har kubectx installert:  kubectx connectgateway_kubernetes-dev-94b9_europe-north1_atkv3-dev-user-cluster   Eller bruk kubectl direkte:  kubectl config use-context connectgateway_kubernetes-dev-94b9_europe-north1_atkv3-dev-user-cluster   ","version":"Next","tagName":"h3"},{"title":"6. (Valgfritt) Gi contexten et enklere navnâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#6-valgfritt-gi-contexten-et-enklere-navn","content":" Du kan gi contexten et mer lesbart navn:  kubectl config rename-context connectgateway_kubernetes-dev-94b9_europe-north1_atkv3-dev-user-cluster atkv3-dev   ","version":"Next","tagName":"h3"},{"title":"Eksterne ressurserâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#eksterne-ressurser","content":" Se ogsÃ¥ https://cloud.google.com/anthos/multicluster-management/gateway/using.  ","version":"Next","tagName":"h2"},{"title":"Tilgangskravâ€‹","type":1,"pageTitle":"Logge inn pÃ¥ cluster","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/logge-inn-pÃ¥-cluster#tilgangskrav","content":" For Ã¥ ha adgang til Ã¥ logge pÃ¥ clusteret mÃ¥ du vÃ¦re medlem av en AAD - TF - TEAM EntraID-gruppe som er synket med GCP.  Du kan sjekke om teamet ditt er lagt til i entra-id-config hvis du er usikker. ","version":"Next","tagName":"h2"},{"title":"End-user IP-Addresses in Containers","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/end-user ip-addresses-in-containers","content":"End-user IP-Addresses in Containers To forward end-user IP-Addresses to a kubernetes container running spring boot, you need to add the following line to your configuration: server.forward-headers-strategy=NONE After testing, we found that this setting should be â€œNONEâ€. Running spring Behind a Front-end Proxy Server Spring server.forward-headers-strategy NATIVE vs FRAMEWORK","keywords":"","version":"Next"},{"title":"Helsesjekker i Kubernetes","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes","content":"","keywords":"","version":"Next"},{"title":"Bakgrunnâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#bakgrunn","content":" Helsesjekker i kubernetes er en veldig viktig del av mikrotjeneste-arkitekturen, og det er derfor lurt Ã¥ sette seg litt inn i hensikten og funksjonen til de ulike helse-endepunktene man kan konfigurere. Det finnes mange mÃ¥ter Ã¥ konfigurere disse pÃ¥, alt i fra helt egenlagde endepunkter til ferdige rammeverk som eksponerer dette automatisk.  I hovedsak finnes det tre typer prober som kubernetes opererer med:  Liveness probe - Sjekker om containeren kjÃ¸rer og fungerer, hvis ikke sÃ¥ restarter kubernetes containeren    Readiness probe - Brukes for Ã¥ bestemme om en pod en klar for Ã¥ ta i mot trafikk. En pod er klar nÃ¥r alle containere i poden er klare.    Startup probe - Hvis denne er konfigurert sÃ¥ avventer kubernetes med liveness og readiness til dette endepunktet svarer. Dette kan brukes for Ã¥ gi trege containere noe mer tid til Ã¥ starte opp.  Det finnes flere mÃ¥ter Ã¥ sette opp helsesjekker pÃ¥, som f.eks. kommandoer, HTTP-requests, TCP-requests og gRPC-requests. Den aller vanligste mÃ¥ten er Ã¥ konfigurere et endepunkt (f.eks /health, /liveness) i applikasjonen som svarer pÃ¥ HTTP-requests, og spesifisere dette som en del av pod-spesifikasjonen.  Litt mer om helsesjekker generelt: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/  Det er viktig Ã¥ merke seg at man ikkemÃ¥benytte seg av alle disse helsesjekkene, men man bÃ¸r ta et bevisst valg om det er hensiktsmessig eller ikke. Sjekk den lenken her for Ã¥ en oversikt over hva man bÃ¸r gjÃ¸re: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle/#when-should-you-use-a-liveness-probe  ","version":"Next","tagName":"h2"},{"title":"Skiperatorâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#skiperator","content":" De aller fleste som har applikasjoner pÃ¥ SKIP benytter Skiperator for Ã¥ forenkle oppsettet rundt applikasjonen. I Skiperator-manifestet kan man konfigurere helsesjekker pÃ¥ samme mÃ¥te man ville gjort for en vanilla-pod i kubernetes. Detaljer rundt dette stÃ¥r i dokumentasjonen for Skiperator . Se under ApplicationSpec og Liveness / Readiness / Startup .  ","version":"Next","tagName":"h2"},{"title":"Sikkerhetshensynâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#sikkerhetshensyn","content":" Det er noen fallgruver Ã¥ vÃ¦re klar over, sÃ¥ denne siden skal prÃ¸ve Ã¥ gi en oversikt over hvordan man typisk bÃ¸r konfigurere dette pÃ¥ en sikker og god mÃ¥te.  Hvis man ikke konfigurerer applikasjonen sin riktig kan man i verste fall ende opp med Ã¥ eksponere de samme endepunktene som kubernetes bruker internt ut pÃ¥ internett. Et enkelt /health endepunkt som svarer med HTTP 200 OK, gjÃ¸r ikke sÃ¥ stor skade. Et feilkonfigurert management-endepunkt derimot kan eksponere interne miljÃ¸variabler, debug-info og minnedump.  Ta en titt pÃ¥ fÃ¸lgende flytskjema fÃ¸r du gÃ¥r videre, og gÃ¥ til det punktet som gjelder deg  ","version":"Next","tagName":"h2"},{"title":"UndersÃ¸ke hva som eksponeres som standardâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#undersÃ¸ke-hva-som-eksponeres-som-standard","content":" En veldig vanlig mÃ¥te Ã¥ lÃ¸se helsejsekker pÃ¥ nÃ¥r man bruker Spring Boot er Ã¥ benytte seg av sub-prosjektet Spring Boot Actuator .  For Ã¥ ta det i bruk trenger man bare Ã¥ legge til fÃ¸lgende for Maven-prosjekt (pom.xml)  &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt;   Eller dette hvis man bruker Gradle (build.gradle)  dependencies { implementation 'org.springframework.boot:spring-boot-starter-actuator' }   Rammeverket setter automatisk opp endepunktet /actuator/health som en trygg default (gjelder versjon 2 og hÃ¸yere av Spring Boot). NÃ¥r man starter opp en Spring-applikasjon i kubernetes vil Spring Boot Actuator ogsÃ¥ automatisk tilgjengeliggjÃ¸re /actuator/health/liveness og /actuator/health/readiness som man benytte for helsesjekker. For Ã¥ teste disse manuelt kan du legge til management.endpoint.health.probes.enabled=true i application.properties .  Disse endepunktene kan du sÃ¥ bruke i Skiperator-manifestet:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: some-backend namespace: yournamespace spec: # Ã˜vrig konfigurasjon liveness: path: /actuator/health/liveness port: 8080 failureThreshold: 3 timeout: 1 initialDelay: 3 readiness: path: /actuator/health/readiness port: 8080 failureThreshold: 3 timeout: 1 initialDelay: 5   Det er viktig Ã¥ merke seg fÃ¸lgende notat:  warning Konfigurasjon som management.endpoints.web.exposure.include=* frarÃ¥des ettersom det eksponerer alle endepunkt som er skrudd pÃ¥. I sÃ¥ fall mÃ¥ man passe pÃ¥ Ã¥ sette management.endpoints.enabled-by-default=false og manuelt skru pÃ¥ de man Ã¸nsker Ã¥ bruke.  Ã˜nsker man Ã¥ eksponere ytterligere endepunkt , som f.eks. Ã¥ eksponere /info for Ã¥ presentere informasjon om bygget eller lignende er det tryggere Ã¥ eksplisitt man gjÃ¸re det pÃ¥ denne mÃ¥ten i application.properties :  management.endpoint.info.enabled=true management.endpoint.health.enabled=true management.endpoints.web.exposure.include=health,info   info Savner du ditt rammeverk? Legg det til da vel   ","version":"Next","tagName":"h3"},{"title":"Eksponer endepunktene pÃ¥ dedikert port uten serviceâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#eksponer-endepunktene-pÃ¥-dedikert-port-uten-service","content":" Her vil det variere litt hvordan man gÃ¥r frem avhengig av om man bruker et rammeverk eller ikke, siden prosessen i containeren mÃ¥ lytte pÃ¥ ekstra port.  FÃ¸rst mÃ¥ man velge seg en port, f.eks. 8081, og sÃ¥ eksponere denne i Dockerfile. I dette eksempelet vil 8080 vÃ¦re applikasjonsporten, og 8081 management/helseporten.  EXPOSE 8080 8081   Deretter mÃ¥ man konfigurere management-porten i application.properties pÃ¥ fÃ¸lgende mÃ¥te:  management.server.port=8081 management.endpoint.info.enabled=true management.endpoint.health.enabled=true management.endpoints.web.exposure.include=health,info   Skiperator-manifestet vil vÃ¦re helt likt, men man insturerer kubernetes til Ã¥ gjÃ¸re helsesjekkene pÃ¥ en annen port.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: some-backend namespace: yournamespace spec: port: 8080 # Ã˜vrig konfigurasjon liveness: path: /actuator/health/liveness port: 8081 failureThreshold: 3 timeout: 1 initialDelay: 3 readiness: path: /actuator/health/readiness port: 8081 failureThreshold: 3 timeout: 1 initialDelay: 5   ","version":"Next","tagName":"h3"},{"title":"Eksponer endepunktene pÃ¥ dedikert port med serviceâ€‹","type":1,"pageTitle":"Helsesjekker i Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/helsesjekker-i-kubernetes#eksponer-endepunktene-pÃ¥-dedikert-port-med-service","content":" note For Ã¸yeblikket kan man ikke spesifisere hvilken port man skal tillate trafikk til via skiperator sin accessPolicy  Hvis man har behov for at en annen applikasjon skal kunne nÃ¥ endepunktet pÃ¥ en annen port mÃ¥ man gjÃ¸re ytterligere konfigurasjon. Man bÃ¸r ta en ekstra vurdering pÃ¥ om det er hensiktmessig Ã¥ eksponere denne typen informasjon via actuator-endepunkter.  Sett opp konfigurasjonen pÃ¥ samme mÃ¥te som punktet over, men manifestet vil nÃ¥ inkludere spesifikasjon for ekstra porter og tilgangssstyring.  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: some-backend namespace: yournamespace spec: port: 8080 additionalPorts: - name: actuator port: 8081 protocol: TCP # .. Ã¸vrig konfigurasjon liveness: path: /actuator/health/liveness port: 8081 failureThreshold: 3 timeout: 1 initialDelay: 3 readiness: path: /actuator/health/readiness port: 8081 failureThreshold: 3 timeout: 1 initialDelay: 5 accessPolicy: inbound: rules: - application: some-frontend port: 8081 # Ikke mulig akkurat nÃ¥  ","version":"Next","tagName":"h3"},{"title":"Retningslinjer for Kubernetes","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/retningslinjer-for-kubernetes","content":"","keywords":"","version":"Next"},{"title":"Minstekrav for sikkerhetâ€‹","type":1,"pageTitle":"Retningslinjer for Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/retningslinjer-for-kubernetes#minstekrav-for-sikkerhet","content":" I Kubernetes bruker vi Pod Security Standards for Ã¥ sikre at alle pods som kjÃ¸rer i clusteret vÃ¥rt er sikre. Dette er en standard som er satt av CNCF, og som vi fÃ¸lger for Ã¥ sikre at vi ikke har noen Ã¥penbare sikkerhetshull i Kubernetes-clusteret vÃ¥rt. Alle workloads skal fÃ¸lge PSS nivÃ¥ &quot;restricted&quot;, som er et nivÃ¥ som fÃ¸lger dagens best practices for sikring av containere. Applikasjoner som kjÃ¸rer som Skiperator Applications fÃ¸lger allerede denne standarden. Les mer om Pod Security Standards her.  ","version":"Next","tagName":"h2"},{"title":"Namespaces som avgrensning mellom teamsâ€‹","type":1,"pageTitle":"Retningslinjer for Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/retningslinjer-for-kubernetes#namespaces-som-avgrensning-mellom-teams","content":" Hvert team kan lage sÃ¥ mange Namespaces som de har behov for. Dette er for Ã¥ kunne skille pÃ¥ ressurser og tilganger mellom forskjellige applikasjoner og team. Dette er ogsÃ¥ for Ã¥ kunne gi teamene mulighet til Ã¥ eksperimentere og teste ting uten at det pÃ¥virker andre team. Les mer om dette pÃ¥ Argo CD.  Kommunikasjon mellom tjenester internt i ett namespace er helt lukket (â€œdefault denyâ€-policy), og det er opp til teamet selv Ã¥ sÃ¸rge for Ã¥ Ã¥pne for kommunikasjon mellom tjenester. Les mer om dette pÃ¥ Skiperator.  Informasjon om kommunikasjon mot tjenester som ligger i andre namespaces finnes her: Anthos Service Mesh Brukerdokumentasjon  Tjenester og fellesfunksjoner som brukes av flere teams skal settes i egne namespaces. Tilgang til disse namespacene gis ved at det opprettes en ny gruppe i AD pÃ¥ samme mÃ¥te som et produktteam.  ","version":"Next","tagName":"h2"},{"title":"Ressursbruk i Kubernetesâ€‹","type":1,"pageTitle":"Retningslinjer for Kubernetes","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/retningslinjer-for-kubernetes#ressursbruk-i-kubernetes","content":" Ressursbruk i Kubernetes dreier seg om hvor mye CPU og RAM hver pod skal bruke.  Requests er hvor mye CPU og minne hvercontainerspÃ¸r om nÃ¥r den fÃ¸rst settes pÃ¥ en node. Hvis man for eksempel ber om 500 mCPUer, men noden bare har 250 mCPU ledig, kan containeres ikke kjÃ¸res pÃ¥ den noden.  Merk at man kan spesifisere CPU helt ned i millicpuer (mCPU).  Minne-requests kan settes i mange forskjellige enheter, se dokumentasjonen for detaljer. Vi anbefaler dog at man holder seg til M - megabytes.  Limits er hvor mye ressurser en container maksimalt fÃ¥r lov til Ã¥ bruke. Dette er med andre ord noe som settes for Ã¥ forhindre at en container med en bug tar over alle ressursene, og gjÃ¸r det umulig for andre containere Ã¥ skalere.  Vi anbefaler at du ser pÃ¥ Limiten som en mulighet til Ã¥ finne bugs og memory leaks. Sett den sÃ¥ lavt du er komfortabel med, og fÃ¸lg med pÃ¥ det faktiske forbruket. Hvis noe krÃ¦sjer er det da god sjanse for at det ble innfÃ¸rt en bug.  Dersom det faktiske forbruket nÃ¦rmer seg limiten pÃ¥ grunn av naturlige grunner - flere requests eller tyngre load+ er det pÃ¥ tide Ã¥ Ã¸ke limiten. Ikke vent til appliasjonen krÃ¦sjer - det skaper en dÃ¥rlig brukeropplevelse.  tip En god tommelfingerregel for requests og limits er fÃ¸lgende: For minne bÃ¸r man profilere applikasjonens gjennomsnittlige minnebruk og doble denne som limit. For CPU trenger man ikke limit, men heller definere en fornuftig request.  Logikken bak dette er at dersom en applikasjon bruker altfor mye minne kan det fÃ¸re til at andre applikasjoner gÃ¥r ned. Dersom en applikasjon bruker mye CPU fÃ¸rer det derimot bare i verste fall til at ting gÃ¥r tregere.  Dette er reglene for ressursbruk i Kubernetes pÃ¥ SKIP  Produktteamet velger selv hva som er naturlig ressursbruk for sine containere, og skal ha et bevisst forhold til hvilke grenser som er satt. Produktteamet skal fÃ¸lge med pÃ¥ ressursbruken over tid, og oppdatere grensene slik at de til enhver tid reflekterer hva applikasjonen faktisk trenger. Resource requests og limits skal settes pÃ¥ alle containere slik at det blir tydelig hva som er forventet ressursbruk. Resource limits skal skal alltid settes hÃ¸yere enn requests, men aldri unaturlig hÃ¸yt. Husk at dette fungerer bÃ¥de som dokumentasjon og som en sikring mot bugs og feilkonfigurasjon. Resource limits skal aldri fjernes permanent, men kan fjernes for debugging. Da skal SKIP-teamet gjÃ¸res oppmerksom pÃ¥ dette. Godt blogginnlegg om korrelasjonen mellom JVMs og Kubernetesâ€™ minnebruk  Kubernetesâ€™ dokumentasjon om ressursbruk  Google Clouds dokumentasjon om â€œcost effective appsâ€ (Merk at Google anbefaler Ã¥ sette limit til det samme som requests - vi setter driftsstabilitet over kostnad, og er derfor uenig i dette.) ","version":"Next","tagName":"h2"},{"title":"URLer og sertifikat for tjenester pÃ¥ SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip","content":"","keywords":"","version":"Next"},{"title":"Interne tjenesterâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#interne-tjenester","content":" ","version":"Next","tagName":"h2"},{"title":"kartverket-intern.cloudâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#kartverket-interncloud","content":" Dersom du har en tjeneste som kun skal vÃ¦re tilgjengelig for folk pÃ¥ kartverkets nettverk og VPN og ikke pÃ¥ internett for allmennheten har man flere forskjellige alternativer. Avhengig av bruksomrÃ¥de og hva slags URL man Ã¸nsker seg fungerer dette litt forskjellig, og beskrives i paragrafene under.  For tjenester som skal nÃ¥s pÃ¥ et domene under kartverket-intern.cloud hÃ¥ndteres alt automatisk, inkludert utstedelse og fornying av sertfikater. Det ligger et wildcard record i DNS som hÃ¥ndterer innkommende trafikk, og bruker cluster-leddet i URL-en pÃ¥ Load Balanceren til Ã¥ rute denne inn til riktig cluster. Deretter rutes denne til applikasjonen din basert pÃ¥ URL-konfigurasjonen din i Skiperator.  info Eksempel: minapp.atkv3-prod.kartverket-intern.cloud  ","version":"Next","tagName":"h3"},{"title":"Vanity URL-erâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#vanity-url-er","content":" note Akkurat nÃ¥ stÃ¸ttes kun kartverket-intern.cloud URL-er pga. en begrensning i utstedelse av sertfikater ( SKIP-1459 ) og en begrensning i lastbalanserer pÃ¥ atkv3-dev cluster ( SKIP-1458 ). Dette skal utbedres.  Dersom du Ã¸nsker et annet hostname enn app.&lt;cluster&gt;.kartverket-intern.cloud er dette mulig, men krever noe mer setup. Den nye URL-en mÃ¥ registreres i DNS og skiperator-applikasjonen din mÃ¥ settes opp til Ã¥ lytte pÃ¥ denne. Utstedelse og fornying av sertfikater vil fremdeles hÃ¥ndteres automatisk av Skiperator.  For Ã¥ sette opp DNS mÃ¥ du gjÃ¸re fÃ¸lgende: FÃ¸rst bestem hvilke URL du vil ha, deretter sett opp et CNAME for denne URL-en til &lt;cluster&gt;.kartverket-intern.cloud . Dersom du Ã¸nsker et CNAME som ligger under kartverket-intern.cloud (for eksempel minapp.kartverket-intern.cloud) kan dette gjÃ¸res av SKIP, for alle andre domener ta kontakt med eier av domenet via bestilling i pureservice. NÃ¥r dette er gjort vil alle spÃ¸rringer som gÃ¥r mot URL-en du har bestemt ende opp host lastbalansereren foran clusteret, og sendes videre inn til Kubernetes.  Neste steg er at Kubernetes sender spÃ¸rringen videre til din applikasjon. Da mÃ¥ du registere URL-en i Skiperator som vanlig under ingresses .  ","version":"Next","tagName":"h3"},{"title":"Cluster-internâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#cluster-intern","content":" Alle applikasjoner som kjÃ¸rer pÃ¥ SKIP har en kubernetes Service tilknyttet seg. Med denne servicen kan man sende spÃ¸rringer direkte til applikasjonen uten Ã¥ sende trafikken ut av clusteret.  Merk at man her bruker http og ikke https. Trafikken vil allikevel krypteres av service meshet sÃ¥ trafikken vil gÃ¥ over https mellom tjenestene, men fra ditt perspektiv skal du bruke http og trenger ikke tenke pÃ¥ sertfikater.  For Ã¥ sende en spÃ¸rring pÃ¥ denne mÃ¥ten bruker du en URL i fÃ¸lgende format:  http://&lt;appnavn&gt;.&lt;namespacenavn&gt;:port   Merk at Ã¥ snakke med en annen tjeneste pÃ¥ denne mÃ¥ten krever at du har Ã¥pnet opp for at trafikk kan flyte mellom disse tjenestene. I utgangspunktet blir all trafikk blokkert av sikkerhetshensyn. Ã… Ã¥pne opp gjÃ¸res ved Ã¥ spesifisere spec.accessPolicy.outbound.rules i applikasjonen som skal sende spÃ¸rringen og spec.accessPolicy.inbound.rules i applikasjonen som skal motta spÃ¸rringene.  ","version":"Next","tagName":"h3"},{"title":"Tjenester eksponert pÃ¥ internettâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#tjenester-eksponert-pÃ¥-internett","content":" Det er to alternativer for Ã¥ eksponere ting pÃ¥ internett. Bruk kartverket.cloud eller en penere â€œvanity URLâ€.  Merk at skiperator-tjenester som eksponeres pÃ¥ andre domenenavn enn subdomener av kartverket-intern.cloud vil automatisk bli Ã¥pnet for trafikk fra internett, men vil ikke vÃ¦re tilgjengelig fÃ¸r DNS konfigureres.  ","version":"Next","tagName":"h2"},{"title":"kartverket.cloudâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#kartverketcloud","content":" For tjenester som skal nÃ¥s pÃ¥ et domene under kartverket.cloud hÃ¥ndteres alt automatisk, inkludert utstedelse og fornying av sertfikater. Det ligger et wildcard record i DNS som hÃ¥ndterer innkommende trafikk, og bruker cluster-leddet i URL-en pÃ¥ Load Balanceren til Ã¥ rute denne inn til riktig cluster. Deretter rutes denne til applikasjonen din basert pÃ¥ URL-konfigurasjonen din i Skiperator.  info Eksempel: minapp.atkv3-prod.kartverket.cloud  ","version":"Next","tagName":"h3"},{"title":"Vanity URL-erâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#vanity-url-er-1","content":" Dersom du Ã¸nsker et annet hostname enn app.&lt;cluster&gt;.kartverket.cloud er dette mulig, men krever noe mer setup. Den nye URL-en mÃ¥ registreres i DNS og skiperator-applikasjonen din mÃ¥ settes opp til Ã¥ lytte pÃ¥ denne. Utstedelse og fornying av sertfikater vil fremdeles hÃ¥ndteres automatisk av Skiperator.  For Ã¥ sette opp DNS mÃ¥ du gjÃ¸re fÃ¸lgende: FÃ¸rst bestem hvilke URL du vil ha, deretter sett opp et CNAME for denne URL-en til &lt;cluster&gt;.kartverket.cloud . Dersom du Ã¸nsker et CNAME som ligger under kartverket.cloud (for eksempel minapp.kartverket.cloud) kan dette gjÃ¸res av SKIP, for alle andre domener ta kontakt med eier av domenet via bestilling i pureservice. NÃ¥r dette er gjort vil alle spÃ¸rringer som gÃ¥r mot URL-en du har bestemt ende opp host lastbalansereren foran clusteret, og sendes videre inn til Kubernetes.  Neste steg er at Kubernetes sender spÃ¸rringen videre til din applikasjon. Da mÃ¥ du registere URL-en i Skiperator som vanlig under ingresses .  Dersom du Ã¸nsker Ã¥ ha en URL pÃ¥ toppnivÃ¥ (annentjeneste.no) er ikke CNAME stÃ¸ttet i DNS. Her mÃ¥ man bruke an A record, og her kan man i sÃ¥ fall fÃ¥ IP-adresser med Ã¥ gjÃ¸re et DNS-oppslag pÃ¥ &lt;cluster&gt;.kartverket.cloud .  ","version":"Next","tagName":"h3"},{"title":"HTTPS by defaultâ€‹","type":1,"pageTitle":"URLer og sertifikat for tjenester pÃ¥ SKIP","url":"/docs/kom-i-gang/praktisk-intro/kubernetes/urler-og-sertifikat-for-tjenester-pÃ¥-skip#https-by-default","content":" NÃ¥r man eksponerer en applikasjon fÃ¥r man ogsÃ¥ HTTPS automatisk satt opp og eksponert. I dette tilfellet kan man fort spÃ¸rre seg om man burde redirecte HTTP til HTTPS for at alle brukerene skal nyte godt av dette, og svaret pÃ¥ det er i nesten alle tilfeller ja.  For Ã¥ sette opp en slik redirect er det enkleste Ã¥ fÃ¥ applikasjonen som serverer ressurser til klienten (nettleseren) Ã¥ sende en https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Strict-Transport-Security header (HSTS). NÃ¥r en nettleser laster en nettside og oppdager en HSTS header vil den legge denne nettsiden i sin interne cache med et flagg som sier at denne nettsiden alltid skal lastes med HTTPS. Lengden pÃ¥ denne cachen kan settes i flagget, og i de fleste tilfeller vil denne settes ganske hÃ¸yt.  Den eneste tiden hvor dette kan bli problematisk er om det plutselig skjer en endring som gjÃ¸r at nettsiden ikke lenger serveres pÃ¥ HTTPS. For Ã¥ forhindre downgrade attacks vil nettleseren serveres en feilmelding om at nettsiden kun kan Ã¥pnes pÃ¥ HTTPS og det vil ikke vÃ¦re mulig Ã¥ gÃ¥ forbi denne for Ã¥ nÃ¥ HTTP-siden. Men i de aller fleste tilfeller er ikke dette noe Ã¥ bekymre seg over. ","version":"Next","tagName":"h2"},{"title":"Sikkerhet","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/praktisk-intro/security","content":"Sikkerhet SKIP er bygget etter prinsippet om innebygget sikkerhet, slik at det blir lett Ã¥ gjÃ¸re rett. StandardoppfÃ¸rselen skal i utgangspunktet vÃ¦re sikker, med mulighet for produktteamene Ã¥ overstyre der det gir mening for deres applikasjon. Dette er kort fortalt hvordan SKIP balanserer behovet for sikkerhet med autonomi. Et eksempel pÃ¥ dette er prinsippet om Zero Trust i nettverkslaget. All trafikk pÃ¥ Kubernetes er i utgangspunktet stengt, en pod kan ikke snakke med en hvilken som helst annen. Kun om begge tjenestene Ã¥pner for at de kan snakke med hverandre kan trafikken flyte mellom dem. Dette gjÃ¸r produktteamene selv ved Ã¥ sette accessPolicy i sitt Skiperator-manifest. All trafikk mellom podder i Kubernetes er kryptert med mTLS helt automatisk. Det eneste man trenger Ã¥ gjÃ¸re er Ã¥ sende spÃ¸rringer til en annen pod, sÃ¥ krypterer Service Meshet koblingen automatisk. Dersom man trenger Ã¥ eksponere applikasjonen sin til omverdenen kan man konfigurere et endepunkt som applikasjonen skal eksponeres pÃ¥. NÃ¥r dette er konfigurert fÃ¥r man utstedt et gyldig sertifikat som gjÃ¸r at all trafikk krypteres med HTTPS helt automatisk. Dette sertifikatet fornyes ogsÃ¥ automatisk. Dette og mye mer fÃ¸rer til at det er lett Ã¥ gjÃ¸re rett pÃ¥ SKIP.","keywords":"","version":"Next"},{"title":"ðŸ«‚ Team pÃ¥ SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team","content":"ðŸ«‚ Team pÃ¥ SKIP Teamets ansvar pÃ¥ SKIPOnboarde nytt team SKIPLegge til/fjerne personer fra teametFÃ¥ tilgang til GCP, Grafana, ArgoCD, GitHUBHvordan fungerer tilgangsstyring pÃ¥ SKIP","keywords":"","version":"Next"},{"title":"Tilgang til GCP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team/access-gcp","content":"Tilgang til GCP SKIP benytter Google Cloud Platform som Ã¸kosystem rundt Kubernetes. Det gjÃ¸r at man kan benytte seg av andre Google-produkter selv om applikasjonen kjÃ¸rer pÃ¥ et on-premise cluster. Man kan ogsÃ¥ autentisere seg mot GCP og benyttekubectl gjennom Google sin Connect Gateway for Ã¥ aksessere on-premise cluster uten Ã¥ vÃ¦re pÃ¥ det interne nettverket/VDI. For Ã¥ kunne logge pÃ¥ GCP med Kartverket-brukeren mÃ¥ brukeren vÃ¦re medlem i en AAD - TF - TEAM - gruppe i EntraID. Dette er beskrevet i Legge til eller fjerne personer fra et teamSjekk onboarding-dokumentasjonen om du ikke allerede har gjort dette. Har du nettopp blitt onboardet kan det ta opptil en time fÃ¸r gruppen er synket inn i GCP.","keywords":"","version":"Next"},{"title":"Konfigurering av Entra ID grupper","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team/add-remove-team-member","content":"","keywords":"","version":"Next"},{"title":"Legge til eller fjerne personer fra et teamâ€‹","type":1,"pageTitle":"Konfigurering av Entra ID grupper","url":"/docs/kom-i-gang/team/add-remove-team-member#legge-til-eller-fjerne-personer-fra-et-team","content":" Det vil ofte forekomme tilfeller hvor personer gÃ¥r inn eller ut av et produktteam. Dette kan for eksempel vÃ¦re om man har fÃ¥tt en nyansatt som skal inn eller en konsulent som har skiftet over til et annet team. I disse tilfellene har man tradisjonelt vÃ¦rt avhengig av at dette hÃ¥ndteres som en bestilling og derfor er en tidkrevende prosess Ã¥ gi nye teammedlemmer tilganger, noe som fÃ¸rer til treghet i onboarding.  PÃ¥ SKIP har vi delegert tilganger til team lead pÃ¥ hvert team slik at disse personene kan administrere sine grupper i Entra ID. Disse gruppene er de som brukes for Ã¥ gi tilgang til tjenester pÃ¥ SKIP slik at et medlem av disse gruppene automatisk fÃ¥r tilgang til SKIP-tjenester som Google Cloud og Kubernetes. Med andre ord er det produktteamene sitt ansvar Ã¥ holde sine team oppdatert, og av sikkerhetsmessige hensyn forventes det at dette gjÃ¸res. Det kan bli utfÃ¸rt kontroll av dette i ettertid, sÃ¥ det forventes at team pÃ¥ SKIP har rutiner og sjekklister for offboarding av teammedlemmer.    For Ã¥ legge til eller fjerne et teammedlem mÃ¥ team leaden pÃ¥ teamet (eller personen som har fÃ¥tt team lead ansvar) gÃ¥ tilEntra ID . Her finner man sin gruppe ved Ã¥ sÃ¸ke etterTF - AAD - TEAM - mitt_teamnavn (bytt ut mitt_teamnavn med ditt teamnavn). Klikk deg inn pÃ¥ dette og du vil finne Members i sidemenyen til venstre. Etter du har klikket deg inn der bÃ¸r du se et skjermbilde som ligner pÃ¥ det over. Her ser du alle som ligger i team-gruppen deres og i kraft av det har fÃ¥tt tilganger til det en person pÃ¥ deres team skal ha.  Du vil ogsÃ¥ se at det ligger tre grupper Ã¸verst i denne listen. Dette er grupper for personer med henholdsvis produkteier-, team lead- og tech lead-ansvar. Disse skal ligge der og det forventes ogsÃ¥ at dere fyller ut disse med de enkeltpersonene som skal ha disse ansvarsomrÃ¥dene.  Dersom du er logget inn som team lead vil Add members-knappen Ã¸verst vÃ¦re mulig Ã¥ klikke pÃ¥. Dersom du vil legge til et nytt teammedlem klikker du pÃ¥ denne og sÃ¸ker opp den personen du Ã¸nsker Ã¥ legge til. Etter dette bekreftes vil denne personen legges i gruppen og etter litt tid fÃ¥ de tilgangene som forventes. Team lead mÃ¥ ogsÃ¥ legge til seg selv som medlem for Ã¥ tilgang til SKIPs tjenester.  For Ã¥ fjerne (offboarde) et teammedlem krysser du av i firkanten ved siden av bildet pÃ¥ brukeren og klikker Remove. Dette er ogsÃ¥ noe som kun team lead kan gjÃ¸re.  ","version":"Next","tagName":"h2"},{"title":"Endre team leadâ€‹","type":1,"pageTitle":"Konfigurering av Entra ID grupper","url":"/docs/kom-i-gang/team/add-remove-team-member#endre-team-lead","content":" Endring av team lead kan kun gjÃ¸res i entra-id-config repoet, dersom du prÃ¸ver Ã¥ endre pÃ¥ team lead eller owners i Entra ID portalen, sÃ¥ vil dette bli overskrevet. For Ã¥ endre team lead sÃ¥ mÃ¥ du finne teamet ditt i org.yaml, endre pÃ¥ team_lead variabelen, og lage en pull request. ","version":"Next","tagName":"h2"},{"title":"Dynamisk tilgangskontroll (JIT)","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team/jit","content":"Dynamisk tilgangskontroll (JIT) Most developers will at some point experience not having the correct permissions to operate on Google Cloud resources. This is intentional and is part of the principle of least privilege . In order to operate on the resources you want to access, you need to elevate your privileges. A system exists to make this operation self-service, and it is called Just-In-Time access. It can be accessed at https://jit.skip.kartverket.no . After logging in with your Kartverket google account, it will take you to the below screen. First step is filling in the ID of the project you wish to get access to. This can be found by searching in the box or by finding the ID from console.cloud.google.com. Second step, select the roles you want. It is often possible to see which role you need from the error message you got when trying to do an operation and getting denied. A common role that is used for administering secrets in Google Secret Manager is secretmanager.admin. Select a suitable duration using the slider and click continue. Note that some sensitive roles are not compatible with longer durations. Now for the final step, enter a reason for the access request. This is mostly for auditing, as generally speaking requests are granted automatically. The reason entered will be possible to see in the logs if we need to investigate a security breach. In less common cases, for example when restricted roles are to be granted, a manual approval is required. In that case the reason will be visible to the person who approves the request. When you click request access, you will be taken to a summary screen which gives you the result of your request. In the example above, my request was granted automatically. You now have access, and that's just in time!","keywords":"","version":"Next"},{"title":"Kostnadsoversikt og alarmer","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team/kostnadsoversikt-og-alarmer","content":"","keywords":"","version":"Next"},{"title":"Kostnadsoversiktâ€‹","type":1,"pageTitle":"Kostnadsoversikt og alarmer","url":"/docs/kom-i-gang/team/kostnadsoversikt-og-alarmer#kostnadsoversikt","content":" SKIP har laget et Grafana dashboard som kan brukes til Ã¥ holde en lÃ¸pende oversikt over kostnader. Dashboardet viser kostnader fordelt pÃ¥ prosjekter og tjenester, og gir en oversikt gruppert pÃ¥ divisjoner eller teams.  Dashboardet kan man finne her.  Merk: GCP Cost dashboardet vil vise smÃ¥ forskjeller fra GCP Budgets, dette skyldes start tiden pÃ¥ intervallet. Dataen i dashboardet kan ogsÃ¥ oppdatere seg litt tregere. Se pÃ¥ dashboardet som en pekepinn, mens GCP Budgets er fasiten.  ","version":"Next","tagName":"h2"},{"title":"Alarmerâ€‹","type":1,"pageTitle":"Kostnadsoversikt og alarmer","url":"/docs/kom-i-gang/team/kostnadsoversikt-og-alarmer#alarmer","content":" For Ã¥ unngÃ¥ overraskelser i form av hÃ¸ye kostnader, er det viktig Ã¥ sette opp alarmer. Alarmer kan settes opp for Ã¥ varsle om kostnader som overstiger en viss grense, eller for Ã¥ varsle om kostnader som Ã¸ker raskt.  Vi anbefaler pÃ¥ det sterkeste at alarmer blir satt nÃ¥r dere tar i bruk tjenester i Google Cloud. Dette kan gjÃ¸res i cost-alerts repoet pÃ¥ Github.  Kostnadsalarmer i GCP heter 'budgets', sÃ¥ herfra referes kostnadsalarmer som budsjett.  Standard intervall pÃ¥ budsjetter er mÃ¥nedlig. Det vil si fra den fÃ¸rste til den siste dagen i mÃ¥neden.  ","version":"Next","tagName":"h2"},{"title":"Hvordan sette opp et budsjettâ€‹","type":1,"pageTitle":"Kostnadsoversikt og alarmer","url":"/docs/kom-i-gang/team/kostnadsoversikt-og-alarmer#hvordan-sette-opp-et-budsjett","content":" cost-alerts fungerer pÃ¥ mange mÃ¥ter likt som grafana-alerts repoet. Dersom dere skal opprette deres fÃ¸rste budsjett, sÃ¥ opprett en PR mot cost-alerts repoet hvor dere gjÃ¸r fÃ¸lgende:  Opprett en fil med navnet pÃ¥ teamet i teams mappen, f.eks teams/mitt-team.tfLegg til en linje i CODEOWNERS-filen, med fÃ¸lgende format: teams/mitt-team.tf @kartverket/mitt-team  I teams/mitt-team.tf-filen sÃ¥ kan man opprette et budsjett slik:  module &quot;mitt_team_gcp_budget&quot; { source = &quot;./modules/gcp-budget&quot; budgets = [ { name = &quot;produkt&quot; project_ids = [&quot;project-dev-1&quot;, &quot;project-prod-2&quot;] budget_amount = 500 alert_exceeded_threshold = [0.75, 1.0] alert_forecast_threshold = [1.0] } ] slack_channel_name = &quot;#your-teams-slack-channel&quot; email_address = &quot;alerts@example.com&quot; }   Forklaringer pÃ¥ variabler:  name: Navnet pÃ¥ budsjettet, dere velger selvproject_ids: Prosjektene som budsjettet skal gjelde for. En prosjekt ID finner dere pÃ¥ 'forsiden' til prosjektet pÃ¥ GCP.budget_amount: BelÃ¸pet som budsjettet skal varsle om. Dette er i EURO.alert_exceeded_threshold: Dette er en liste med tall som sier hvor mye av budsjettet som skal overskrides fÃ¸r det varsles. Tallene er i desimalformat av prosent, altsÃ¥ 0.75 = 75%. Valgfritt, standard er 0.75 og 1.0.alert_forecast_threshold: Samme som over, men her varsles det om forventet bruk. Valgfritt, standard er 1.0.slack_channel_name: Navnet pÃ¥ slack-kanalen som varsler skal sendes til, husk Ã¥ inkluder # foran navnet.email_address: E-postadressen som varsler skal sendes til.  README i cost-alerts repoet inneholder mer utfyllende informasjon om bruk av modulen.  ","version":"Next","tagName":"h3"},{"title":"Slackâ€‹","type":1,"pageTitle":"Kostnadsoversikt og alarmer","url":"/docs/kom-i-gang/team/kostnadsoversikt-og-alarmer#slack","content":" Dersom dere har lagt inn at det skal varsles til slack, sÃ¥ mÃ¥ dere invitere SKIP Slack Bot til kanalen det skal varsles til.  GÃ¥ til slack kanalen og trykk pÃ¥ medlemslisten oppe til hÃ¸yre i vinduetTrykk pÃ¥ Integrations i menyen som kommer opp, velg deretter Add an AppSÃ¸k etter SKIP Slack Bot og trykk pÃ¥ Add ","version":"Next","tagName":"h3"},{"title":"Onboarding av nytt produkt-team til SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/team/onboarding-new-teams","content":"","keywords":"","version":"Next"},{"title":"Produkt-team oppgaverâ€‹","type":1,"pageTitle":"Onboarding av nytt produkt-team til SKIP","url":"/docs/kom-i-gang/team/onboarding-new-teams#produkt-team-oppgaver","content":" Produktteamet har ansvaret for Ã¥ fordele disse oppgavene internt.  Informere SKIP om hvem som er teamleder slik at de kan administrere AD-gruppenVurdere hvilke teammedlemmer som trenger ekstra Kubernetes/GCP-kursHvis ArgoCD skal brukes: Opprette nytt Apps-repo i GitHub basert pÃ¥ denne SKIP malenSÃ¸rge for at applikasjonen har en IP og/eller DPIATilpasse applikasjonen for Ã¥ tilfredsstille SKIPs sikkerhetskravSÃ¸rge for at utviklerne pÃ¥ teamet har tilgang pÃ¥ GitHub (se Tilgang til GitHub)Lese, forstÃ¥ og fÃ¸lge GitHub-sikkerhetskravene: Sikkerhet pÃ¥ GitHubFullfÃ¸re ROS-analyseForberede informasjon til SKIP-teamet Tekniske forventningerTjenestedesign/arkitekturUtenforliggende avhengiheter Ta ansvar for egne krav og kommunisere disse tydelig og konsist til SKIPSÃ¸rge for at alle teammedlemmer inviteres til mÃ¸ter og Slack-grupper under onboarding-prosessenLese og forstÃ¥ SKIP-dokumentasjonenGjÃ¸re forventet/pÃ¥krevd go-live-dato kjent for SKIP  ","version":"Next","tagName":"h2"},{"title":"SKIP-teamets oppgaverâ€‹","type":1,"pageTitle":"Onboarding av nytt produkt-team til SKIP","url":"/docs/kom-i-gang/team/onboarding-new-teams#skip-teamets-oppgaver","content":" ","version":"Next","tagName":"h2"},{"title":"FÃ¸r onboardingâ€‹","type":1,"pageTitle":"Onboarding av nytt produkt-team til SKIP","url":"/docs/kom-i-gang/team/onboarding-new-teams#fÃ¸r-onboarding","content":" Invitere en representant fra produktteamet til plattformlaugetDedikere et SKIP-teammedlem som kontaktpunkt for migreringsprosessen (TAM) (Kun for migreringsprosessen, etter dette starter en vanlig supportflyt)*Invitere til et mÃ¸te for Ã¥ avklare forventninger mellom SKIP og produktteametInvitere til gjennomgang av applikasjonerBli enige om frekvensen av onboarding standups med produktteamet og invitere til disseSÃ¸rge for at en prosess rundt risikovurdering (â€œROS-analyseâ€) startes. Denne vurderingen mÃ¥ vÃ¦re klar i tide til produksjonOpprette en kanal pÃ¥ Slack for samarbeid under onboardingInvitere til #gen-skip, #gen-argo og andre relevante felleskanaler for bruk av SKIPInvitere til GCP- og Kubernetes-kurs hvis produktteamet Ã¸nsker detGi en introduksjon til ArgoCD og beste praksis for dette verktÃ¸yet  ","version":"Next","tagName":"h3"},{"title":"Under onboardingâ€‹","type":1,"pageTitle":"Onboarding av nytt produkt-team til SKIP","url":"/docs/kom-i-gang/team/onboarding-new-teams#under-onboarding","content":" Invitere til et kickoff-mÃ¸te hvor kontaktpunkter, ansvarsfordeling, support, veikart og andre relevante saker diskuteres.Opprette grupper ved Ã¥ legge dem til entra-id-config (gruppe synces fra Entra ID til GCP hver time)Teamet mÃ¥ merkes med security i admin.google.com (workflow kjÃ¸res hver dag kl. 8 UTC)Opprett produkt/prosjekt i skip-core-infraWorkflow for Ã¥ kjÃ¸re terraform apply i skip-core-infra mÃ¥ kjÃ¸res av et SKIP-medlem med tilgang.Teamet og app-repositoriet settes opp i henhold til Komme i gang med Argo CD Komme i gang med Argo CDHvis teamet krever Terraform: Service account for Terraform settes opp med gcp-service-accounts og gis tilganger til kubernetes namespace via WIF. ","version":"Next","tagName":"h3"},{"title":"Teknologien bak SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/tech","content":"Teknologien bak SKIP SKIP er basert pÃ¥ en moderne teknologiplattform bygget rundt Google Cloud, GitOps-prinsipper og innebygget sikkerhet. Med Kubernetes i hjertet av plattformen automatiserer SKIP orkestreringen av containeriserte applikasjoner og sikrer sÃ¸mlÃ¸s distribusjon, oppdatering og skalerbarhet. Google Clouds rike Ã¸kosystem gir tilgang til en rekke tjenester for Ã¥ administrere og beskytte data og applikasjoner pÃ¥ en god mÃ¥te. Argo CD gir gjennomgÃ¥ende innsyn og oppdateringshÃ¥ndtering for Kubernetes-applikasjoner, mens Skiperator gir finjustert kontroll over applikasjonsstyring og konfigurasjon. Med Grafana kan du overvÃ¥ke ytelsen og helsen til dine tjenester i sanntid, slik at du kan identifisere og hÃ¥ndtere eventuelle problemer raskt og effektivt. Utstrakt bruk av GitHub gjÃ¸r det lett Ã¥ dele kode med andre, bÃ¥de internt og eksternt. ByggelÃ¸yper i form av GitHub Actions er fleksible og raske Ã¥ komme i gang med. I tillegg har man tilgang til GitHub Advanced Security for tilgang til blant annet sikkerhetsscanning og sÃ¥rbarhetsrapporter. Med SKIP er det lett for utviklere Ã¥ utforske mulighetene innen moderne skyinfrastruktur. Vi pÃ¥ SKIP-teamet hjelper deg med Ã¥ raskt implementere, administrere og optimalisere skybaserte tjenester, og holde tritt med det stadig skiftende teknologiske landskapet. Velkommen ombord til SKIP!","keywords":"","version":"Next"},{"title":"ðŸ¥” FeilsÃ¸king","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/troubleshoot","content":"ðŸ¥” FeilsÃ¸king","keywords":"","version":"Next"},{"title":"FeilsÃ¸king pÃ¥ SKIP","type":0,"sectionRef":"#","url":"/docs/kom-i-gang/troubleshoot/troubleshooting-on-skip","content":"","keywords":"","version":"Next"},{"title":"Relevante lenkerâ€‹","type":1,"pageTitle":"FeilsÃ¸king pÃ¥ SKIP","url":"/docs/kom-i-gang/troubleshoot/troubleshooting-on-skip#relevante-lenker","content":" Skiperator kode og dokumentasjon  CLI Jukselapp for SKIP (kan kreve ekstra privilegier)  ","version":"Next","tagName":"h2"},{"title":"Generell sjekkliste ved feilsÃ¸kingâ€‹","type":1,"pageTitle":"FeilsÃ¸king pÃ¥ SKIP","url":"/docs/kom-i-gang/troubleshoot/troubleshooting-on-skip#generell-sjekkliste-ved-feilsÃ¸king","content":" Nettverk/Istio-relaterte problemer:  Network policies - default-deny and others (if applicable).AccessPolicies both outbound and inbound.ServiceEntries+++ ","version":"Next","tagName":"h2"},{"title":"ðŸ’¾ Lagring","type":0,"sectionRef":"#","url":"/docs/lagring","content":"ðŸ’¾ Lagring","keywords":"","version":"Next"},{"title":"Objektlagring med Scality S3","type":0,"sectionRef":"#","url":"/docs/lagring/objektlagring-scality-s3","content":"Objektlagring med Scality S3 I Kartverket har vi en lokalt S3-kompatibel lagringslÃ¸sning ved navn Scality. Denne er mulig Ã¥ fÃ¥ tilgang til, og er godt egnet i tilfellet at dere trengre Ã¥ lagre filer fra en container. Ã… fÃ¥ tilgang til denne krever fÃ¸lgende: SKIP oppretter bruker og lagringsbÃ¸tter for dere i scality-lÃ¸sningen Admin interface Dere fÃ¥r access key og secret","keywords":"","version":"Next"},{"title":"ðŸ”­ Observabilitet","type":0,"sectionRef":"#","url":"/docs/observability","content":"","keywords":"","version":"Next"},{"title":"Hva er observabilitet?â€‹","type":1,"pageTitle":"ðŸ”­ Observabilitet","url":"/docs/observability#hva-er-observabilitet","content":" Observabilitet handler om evnen til Ã¥ forstÃ¥ den indre tilstanden og oppfÃ¸rselen til et system basert pÃ¥ de eksterne dataene det produserer, som logger, metrikker og sporingsdata (traces). Det gir team muligheten til Ã¥ fÃ¥ innsikt i hvordan systemet fungerer, identifisere problemer, og diagnostisere Ã¥rsakene til disse problemene uten Ã¥ mÃ¥tte endre systemets kode eller overvÃ¥kingsmekanismer. Observabilitet gÃ¥r utover tradisjonell overvÃ¥kning ved Ã¥ tilby en mer fleksibel og dypere analyse av systemets ytelse og helsetilstand, noe som gjÃ¸r det mulig Ã¥ stille og besvare nye spÃ¸rsmÃ¥l om systemet etter hvert som de oppstÃ¥r.  ","version":"Next","tagName":"h2"},{"title":"Hva tilbyr SKIP?â€‹","type":1,"pageTitle":"ðŸ”­ Observabilitet","url":"/docs/observability#hva-tilbyr-skip","content":" SKIP tilbyr innsamling, visualisering og alarmering basert pÃ¥ telemetri innsamlet fra applikasjonene pÃ¥ SKIP. Telemetrien vi samler inn er metrikker, logger og traces.  Grafana er verktÃ¸yet for Ã¥ sÃ¸ke, visualisere og sammenstille innsamlet telemetri fra ulike kilder. Her kan du ogsÃ¥ se hvilke alarmer som er konfigurert, alarmhistorikk og hvilke alarmer som gÃ¥r akkurat nÃ¥.  ","version":"Next","tagName":"h2"},{"title":"Andre nyttige ressurserâ€‹","type":1,"pageTitle":"ðŸ”­ Observabilitet","url":"/docs/observability#andre-nyttige-ressurser","content":" Intro to o11y: What is Observability?What is Observability?Bloggen til Charity Majors ","version":"Next","tagName":"h2"},{"title":"Databaser","type":0,"sectionRef":"#","url":"/docs/lagring/databaser","content":"","keywords":"","version":"Next"},{"title":"On-prem Postgresâ€‹","type":1,"pageTitle":"Databaser","url":"/docs/lagring/databaser#on-prem-postgres","content":" Dersom man Ã¸nsker en lokal postgres tar man kontakt med DBA-ene for Ã¥ bestille opp en server. Da vil man fÃ¥ en Postgres-database og en administratorbruker som man kan bruke til Ã¥ opprette tabeller.  For Ã¥ bestille dette sender man ticket gjennom service desken med hvor mye lagring man trenger og circa hvor mye CPU-kraft man trenger.  NÃ¥r man har fÃ¥tt en database sÃ¥ er det to ting man mÃ¥ gjÃ¸re fÃ¸r man kan ta den i bruk fra en applikasjon pÃ¥ SKIP:  Bestill brannmursÃ¥pning for databasen ved Ã¥ opprette en sak i PureService. F.eks. Jeg Ã¸nsker Ã¥ bestille en brannmursÃ¥pning for en database som skal aksesseres fra SKIP. Det er clusteret â€œatkv3-devâ€ som trenger Ã¥ nÃ¥ â€œXXXX.statkart.noâ€ pÃ¥ TCP port XXXX.Sett opp tilgang til databasen i Kubernetes. I Skiperator gjÃ¸res dette ved hjelp av external accessPolicies. Her mÃ¥ applikasjonen definere at den skal kunne snakke med den eksterne serveren som databasen lever pÃ¥.  accessPolicy: outbound: external: - host: XXXX.statkart.no ip: &quot;XXX.XXX.XXX.XXX&quot; ports: name: db port: 5432 protocol: TCP   ","version":"Next","tagName":"h2"},{"title":"Database i skyâ€‹","type":1,"pageTitle":"Databaser","url":"/docs/lagring/databaser#database-i-sky","content":" Se Cloud SQL for PostgreSQL for mer informasjon om hvordan sette opp og ta bruk Cloud SQL for PostgreSQL. ","version":"Next","tagName":"h2"},{"title":"Dashboards","type":0,"sectionRef":"#","url":"/docs/observability/dashboard","content":"","keywords":"","version":"Next"},{"title":"Rask intro til dashboardsâ€‹","type":1,"pageTitle":"Dashboards","url":"/docs/observability/dashboard#rask-intro-til-dashboards","content":" Det er ofte enklere Ã¥ eksperimentere raskt med data og lage gode spÃ¸rringer i Explore. Herfra kan du fra &quot;Add&quot;-menyen Ã¸verst til hÃ¸yre trykke &quot;Add to dashboard&quot; og deretter gjÃ¸re visualiseringen bedre derfra.    PÃ¥ dashboardet kan du klikke pÃ¥ de tre prikkene Ã¸verst til hÃ¸yre pÃ¥ et panel, og velge &quot;Edit&quot;.    Her kan du velge visualiseringstype oppe til hÃ¸yre:    De ulike visualiseringstypene har ulike muligheter for tilpasning. De viktigste visualiseringstypene er time series, heatmap, logs, stat og table.  ","version":"Next","tagName":"h2"},{"title":"Dynamiske dashboards med variablerâ€‹","type":1,"pageTitle":"Dashboards","url":"/docs/observability/dashboard#dynamiske-dashboards-med-variabler","content":" Variabler kan brukes for Ã¥ dynamisk velge miljÃ¸, namespace eller applikasjon. PÃ¥ denne mÃ¥ten kan dashboards brukes pÃ¥ tvers av team eller miljÃ¸er.  Legg til egne variabler ved Ã¥ trykke pÃ¥ &quot;Settings&quot; oppe til hÃ¸yre, deretter &quot;Variables&quot;.  Det viktigste variabeltypene er &quot;Data source&quot; og &quot;Query&quot;. FÃ¸rstnevnte lar deg velge ulike datakilder av samme type dynamisk. &quot;Query&quot; kan brukes for Ã¥ f.eks. velge namespace.  ","version":"Next","tagName":"h2"},{"title":"Eksempel med variablerâ€‹","type":1,"pageTitle":"Dashboards","url":"/docs/observability/dashboard#eksempel-med-variabler","content":" Her er fremgangsmÃ¥ten for Ã¥ lage en datasource variabel, metrics, og en query-variabel namespace.  FÃ¸rst data source-variabelen metrics:  Lag en ny variabel, med type &quot;Datasource&quot;. Gi den navnet metrics. Under &quot;Data source options&quot;, velg &quot;Type&quot; Prometheus. Helt nederst kommer det et preview av verdier, og her er det flere datakilder enn Ã¸nskelig. Dette kan fikses. Under &quot;Intance name filter&quot;, legg inn regex-en /Mimir-.*(dev|prod|atgcp1)/, som gir datakilder for bÃ¥de sky og on-prem clustre. Trykk &quot;Run Query&quot; helt nederst. SÃ¸rg for at alle &quot;Selection options&quot; ikke er valgt, og trykk &quot;Back to list&quot;.  Deretter namespace-variabelen:  Lag en ny variabel, med type &quot;Query&quot; og gi den navnet namespace. Under &quot;Query options&quot; velg datasource ${metrics}. Vi kan nÃ¥ gjÃ¸re spÃ¸rringer mot den datakilden som er valgt av metrics-variabelen. Velg &quot;Query type&quot; &quot;Label values&quot;. I boksene som dukker opp, velg &quot;Label&quot; namespace og &quot;Metric&quot; up. Trykk deretter pÃ¥ run query. Dette gir ganske mange verdier. Som produktteam vil alle namespaces ofte ha samme prefiks, eks. matrikkel-, norgeskart- eller annet. Vi kan igjen filtere ved hjelp av regex. I &quot;Regex&quot;-feltet, bruk regex /mittprefiks-.*/. Har du flere prefiks, kan du bruke /(prefiks1|prefiks2|prefiks3)-.*/. Deretter trykk pÃ¥ &quot;Run Query&quot; og verifiser at du fÃ¥r opp namespace-navnene du forventer. &quot;Selection options&quot; er her mer relevant, tenk over fÃ¸lgende: Dersom du Ã¸nsker Ã¥ vise ting pÃ¥ tvers av namespaces, velg &quot;Multi-value&quot;. Dette er nyttig i noen tilfeller, men krever at du hÃ¥ndterer det i spÃ¸rringene i dashboard-panelene.Dersom du Ã¸nsker Ã¥ la bruker skrive inn egne verdier, velg &quot;custom values&quot; (dette er ofte ikke relevant for namespace).Dersom du vil la bruker velge alle namespaces, eller har en spesiell verdi for alle kan du velge denne. Dette krever ogsÃ¥ at spÃ¸rringene hÃ¥ndterer det, tilsvarende &quot;multi-value&quot;. NÃ¥r du er ferdig, trykk &quot;Back to list&quot; nederst for Ã¥ lage flere variable, eller &quot;Save dashboard&quot; oppe til hÃ¸yre for Ã¥ lagre endringene.  NÃ¥ kan variablene brukes i dashboard-panelene:  Velg &quot;Data source&quot; ${metrics}, og bruk $namespace-variabelen i spÃ¸rringene.    ðŸ“š Se ogsÃ¥ Grafanas dokumentasjon om variabler  ","version":"Next","tagName":"h3"},{"title":"Dashboards som kodeâ€‹","type":1,"pageTitle":"Dashboards","url":"/docs/observability/dashboard#dashboards-som-kode","content":" Det er mulig Ã¥ lage dashboards som kode, enten egenlaget eller hentet fra eksterne kilder, som f.eks. Grafanas dashboardside. Du kan se eksempler pÃ¥ dette i skip-dashboards.  Dashboards om lages som kode bÃ¸r ikke endres i GUI-et. For Ã¥ eksperimentere med slike dashboards anbefaler vi Ã¥ lage en kopi av dashboardet, eksperimentere og deretter gjÃ¸re tilsvarende endringer i kode-repoet. Dette kan gjÃ¸res f.eks. ved Ã¥ trykke &quot;Export &gt; Export as JSON&quot; oppe til hÃ¸yre i dashboard UI-et.  ","version":"Next","tagName":"h2"},{"title":"Andre ressurserâ€‹","type":1,"pageTitle":"Dashboards","url":"/docs/observability/dashboard#andre-ressurser","content":" Det er mange mÃ¥ter Ã¥ lage dashboards pÃ¥, og det finnes gode artikler pÃ¥ det:  ðŸ“š Enkel introduksjon fra Grafana for Ã¥ lage dashboardsðŸ“š Grafanas egne &quot;best practices&quot; for Ã¥ lage dashboardsðŸ“š The Four Golden Signals fra Googles SRE Book diskuterer de viktigste metrikkene Ã¥ monitorere ","version":"Next","tagName":"h2"},{"title":"Distributed tracing with Tempo","type":0,"sectionRef":"#","url":"/docs/observability/distributed-tracing-with-tempo","content":"","keywords":"","version":"Next"},{"title":"What is distributed tracing?â€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#what-is-distributed-tracing","content":" In complex (and distributed) systems there are at any time many ongoing parallel processes. Some of these are interlinked or trigger each other. In order to find out which operations that originate from the same request, it is common in many systems to have a so-called Trace ID. With modern distributed tracing this is standardized, and in addition sub-operations (spans) per Trace ID are also supported. When you use a standardized setup to trace applications you also gain access to a large and exciting toolbox.  Further reading:  OpenTelemetryZipkin (interesting from a historical perspective)A general guide to getting started with distributed tracing  ","version":"Next","tagName":"h2"},{"title":"What does SKIP offer?â€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#what-does-skip-offer","content":" As part of our implementation of the LGTM stack, SKIP has chosen to offer Grafana Tempo as as service. This is a component that is fully integrated with the rest of this modern observability stack, and shares the same user interface and authentication as Grafana, Mimir and Loki.  ","version":"Next","tagName":"h2"},{"title":"How do I get started?â€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#how-do-i-get-started","content":" ","version":"Next","tagName":"h2"},{"title":"Instrumentationâ€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#instrumentation","content":" warning A known limitation in the way we have collected trace data is that we up until recently have had no way of excluding certain traces automatically. This means that all Prometheus scrapes (metrics collection) and automatic health checks will also be collected. Now that issue #4628has been implemented, this can finally be rectified. Follow SKIP-1250 for updates to when this is implemented in our setup.  In order to generate, propagate and send traces the application must be instrumented.  Instrumentation can be achieved in several ways, of which 2 are relevant to us: manual and automatic instrumentation.  Manual instrumentation requires the use of a library which knows how a given integration behaves, and which enables it to connect to hooks in that integrations in order to generate new traces and/or spans if those do not already exist.  The other (and recommended) method is to use an automated approach. In the case of Java applications (the only type that has been tested as of now), you will need to bundle a java agent in your Docker image, as well as set up some extra configuration when the application is run (for example through Skiperator).  info Itâ€™s worth mentioning that the Spring ecosystem offers a form of automatic instrumentation via Micrometer Tracing and OpenTelemetry OTLP exporters. Per october 2023 this is still under development and not considered a mature enough solution to utilize in our systems.  ","version":"Next","tagName":"h3"},{"title":"Example Dockerfileâ€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#example-dockerfile","content":" FROM alpine:3.18.3@sha256:c5c5fda71656f28e49ac9c5416b3643eaa6a108a8093151d6d1afc9463be8e33 AS builder ARG OTEL_AGENT_VERSION=1.29.0 # 1. Last ned pÃ¥krevd java-agent RUN apk add --no-cache curl \\ &amp;&amp; mkdir /agents \\ &amp;&amp; curl -L https://github.com/open-telemetry/opentelemetry-java-instrumentation/releases/download/v${OTEL_AGENT_VERSION}/opentelemetry-javaagent.jar &gt; /agents/opentelemetry.jar ADD build/distributions/gbok-run*.tar /gbok FROM eclipse-temurin:11-jdk-alpine COPY cert/kartverket_root_ca.crt /usr/local/share/ca-certificates/kartverket_root_ca.crt ENV USER_ID=150 ENV USER_NAME=apprunner RUN apk add --no-cache tzdata \\ &amp;&amp; addgroup -g ${USER_ID} ${USER_NAME} \\ &amp;&amp; adduser -u ${USER_ID} -G ${USER_NAME} -D ${USER_NAME} \\ &amp;&amp; keytool -import -v -noprompt -trustcacerts -alias kartverketrootca -file /usr/local/share/ca-certificates/kartverket_root_ca.crt -keystore $JAVA_HOME/lib/security/cacerts -storepass changeit ENV TZ=Europe/Oslo COPY --from=builder --chown=${USER_ID}:${USER_ID} /gbok /gbok # 2. Kopier inn nedlastet agent COPY --from=builder --chown=${USER_ID}:${USER_ID} /agents /agents USER ${USER_NAME} EXPOSE 8081 ENTRYPOINT [&quot;sh&quot;, &quot;-c&quot;, &quot;/gbok/gbok-run*/bin/gbok-run&quot;]   ","version":"Next","tagName":"h3"},{"title":"Runtime configurationâ€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#runtime-configuration","content":" In order to use the Java agent, it needs to be configured and loaded. Through testing with Grunnboken, we have arrived at the first version of configuration which can be seen here .  When this configuration is done, it is then passed to JAVA_TOOL_OPTIONS like this .  There is currently no inbuilt mechanism in ArgoKit to achieve this. We are open for PRs on this topic if anyone would like to contribute.  ","version":"Next","tagName":"h3"},{"title":"View tracesâ€‹","type":1,"pageTitle":"Distributed tracing with Tempo","url":"/docs/observability/distributed-tracing-with-tempo#view-traces","content":" Traces can be viewed through our Grafana instance at monitoring.kartverket.cloud . From here, choose Explore in the menu and then the correct Tempo data source corresponding to the environment you wish to view traces for.  After that, you have the choice of using the Search (graphical build tool for queries) or TraceQL (manual query specification) tools.  Above: The â€œSearchâ€ tab is active, and fields have been filled through the use of dropdowns.  Above: The â€œTraceQLâ€ tab lets you specify a user-defined query. Here is shown a query for â€œgbok2-serverâ€ traces, filtering out health checks ","version":"Next","tagName":"h3"},{"title":"Grafana","type":0,"sectionRef":"#","url":"/docs/observability/grafana","content":"","keywords":"","version":"Next"},{"title":"Rask rundtur i Grafanaâ€‹","type":1,"pageTitle":"Grafana","url":"/docs/observability/grafana#rask-rundtur-i-grafana","content":" NÃ¥r du kommer til vÃ¥r Grafana-instans kan du velge &quot;Sign in with Azure AD&quot;. Om du ikke kommer inn kan det vÃ¦re du ikke er lagt til i teamets AD-gruppe, eller at teamet ditt ikke er onboardet pÃ¥ SKIP. Ta kontakt i #gen-skip pÃ¥ Slack for spÃ¸rsmÃ¥l.  Venstre sidemeny lar deg navigere dit du trenger, og viser de viktigste tingene du trenger i Grafana.    Som produktteam pÃ¥ SKIP er de viktigste egenskapene i Grafana:  Utforsk data i Explore-mode. Her kan du utforske bÃ¥de logger, metrikker og traces.Grafana har ogsÃ¥ en egen Metrics explore som lar deg utforske hvilke metrikker som finnes. Lag dashboards som gir oversikt over hva som skjer i applikasjonene dine. FÃ¥ oversikt over og hÃ¥ndter alarmer. Vi anbefaler at du har alarmer som kode, men du kan ogsÃ¥ konfigurere alarmer manuelt her. Testing og synthetics brukes for syntetisk monitorering. ","version":"Next","tagName":"h2"},{"title":"Cloud SQL for PostgreSQL","type":0,"sectionRef":"#","url":"/docs/lagring/cloud-sql","content":"","keywords":"","version":"Next"},{"title":"Oppsett av instanser med terraformâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#oppsett-av-instanser-med-terraform","content":" SKIP har laget to terraform-moduler (cloud_sql ogcloud_sql_config) for Ã¥ gjÃ¸re det enkelt Ã¥ sette opp nye Cloud SQL-instanser i GCP.  Dokumentasjon for hvordan modulene brukes finnes pÃ¥ wiki-siden til terraform-modulesSpesielt guiden for hvordan bruke terraform-modules repoet er relevant.  ","version":"Next","tagName":"h2"},{"title":"cloud_sql modulenâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#cloud_sql-modulen","content":" For mer utfyllende dokumentasjon se cloud_sql wiki  module &quot;cloudsql_test&quot; { source = &quot;git@github.com:kartverket/terraform-modules.git/?ref=cloud_sql/v0.10.0&quot; env = &quot;sandbox&quot; instance_name = &quot;foo-db&quot; project_id = &quot;skip-sandbox-37c2&quot; }   Du kan koble deg til pÃ¥ denne mÃ¥ten:  JIT deg til cloudsql.adminLast ned cloudsql-proxygcloud auth application-default login./cloud-sql-proxy --private-ip &lt;connection-name&gt; --auto-iam-authn -- connection name finner du pÃ¥ sql instansen i GCPpsql -d admin -h localhost -U admin eller fra applikasjon  Du mÃ¥ vÃ¦re pÃ¥ Kartverkets nettverk for Ã¥ fÃ¥ tilgang, selv med cloud sql proxy. Man kan ikke koble til fra egen klient uten proxy. Du trenger ikke Ã¥ bruke SSL sertifikater nÃ¥r du kobler til via proxy.  ","version":"Next","tagName":"h3"},{"title":"cloud_sql_config modulen og konfigurering av brukereâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#cloud_sql_config-modulen-og-konfigurering-av-brukere","content":" For mer utfyllende dokumentasjon se cloud_sql_config wiki  Denne modulen er laget for konfigurasjon av postgres instanser. Vi har laget denne for Ã¥ gjÃ¸re konfigurering av databaser enklest mulig for dere, og for Ã¥ unngÃ¥ &quot;click-ops&quot;. Det er noen ting dere bÃ¸r tenke over fÃ¸r dere tar denne i bruk:  Den burde bare brukes pÃ¥ en ny instans. Ã… importere eksisterende databaser, brukere og skjemaer er noe vi frarÃ¥derFeil bruk av denne modulen kan slette brukere, secrets og hele databasen inkludert all data. Sjekk alltid PLAN fÃ¸r du applyer.VÃ¦r sikker pÃ¥ at migreringene dine er kompatible med modulen mtp. privileges  Eksempel config:  module &quot;cloudsql_config&quot; { source = &quot;git@github.com:kartverket/terraform-modules.git/?ref=cloud_sql_config/v0.7.0&quot; gcp_instance_name = module.cloudsql_test.cloud_sql_instance_name gcp_project_id = module.cloudsql_test.gcp_project_id env = &quot;prod&quot; databases = { &quot;backstage&quot; = { name = &quot;backstage&quot; owner = &quot;backstage&quot; extensions = [&quot;pgcrypto&quot;, &quot;postgis&quot;] prevent_destroy = true # Denne variabelen mÃ¥ IKKE endres uten at dere er klare til Ã¥ migrere state manuelt. schemas = [ { name = &quot;backstage&quot; migration_user = { name = &quot;backstage_migrater&quot; # migration_user blir eier av skjemaet som opprettes } application_user = { name = &quot;backstage_app&quot; # application user fÃ¥r CRUD privilegier } misc_users = [ { name = &quot;readonly&quot; privileges = [&quot;SELECT&quot;] } ] }, { name = &quot;opencost&quot; unified_user = true migration_user = { name = &quot;opencost_migrater&quot; # ignoreres, fordi vi har unified_user = true, men den mÃ¥ settes likevel } application_user = { name = &quot;opencost_app&quot; privileges = [&quot;SELECT&quot;, &quot;UPDATE&quot;] # ignoreres, app user blir owner av skjemaet fordi unified_user er true } misc_users = [ { name = &quot;readonly&quot; privileges = [&quot;SELECT&quot;] } ] } ] } } }   For hver bruker sÃ¥ vil modulen generere opp et klient sertifikat og en privatnÃ¸kkel, disse legges i GSM. Den private nÃ¸kkelen legges i to formater; PEM og PK8. Vi har erfart at JDBC ikke liker PEM, sÃ¥ i dette tilfellet sÃ¥ bÃ¸r du bruke PK8 nÃ¸kkelen istedenfor.  ","version":"Next","tagName":"h3"},{"title":"Bruke instansen fra SKIPâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#bruke-instansen-fra-skip","content":" NÃ¥r du skal bruke instansen fra SKIP sÃ¥ mÃ¥ du gjÃ¸re noen fÃ¥ modifikasjoner til applikasjonsmanifestet ditt.  Det fÃ¸rste du mÃ¥ gjÃ¸re er Ã¥ hente ut secrets.  Terraform modulen vil generere opp og legge inn alle secrets du trenger for Ã¥ koble til databasen i Google Secret Manager i prosjektet du har valgt.  Kjenner du ikke til GSM og ExternalSecrets anbefaler vi Ã¥ lese Hente hemmeligheter fra hemmelighetshvelv fÃ¸rst.  For Ã¥ hente ut disse sÃ¥ mÃ¥ du lage to ExternalSecret, en for sertifikater og en for passord/brukernavn, her er et eksempel:  apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: my-app-db-client-password # Denne brukes for Ã¥ hente ut password fra json secreten i gsm. namespace: my-app-namespace spec: refreshInterval: 1h secretStoreRef: name: gsm kind: SecretStore target: name: my-app-db-user-password # Navnet pÃ¥ Kubernetes Secret som opprettes creationPolicy: Owner data: - remoteRef: conversionStrategy: Default decodingStrategy: None key: cloudsql-myinstance-myuser # Navnet pÃ¥ GSM secret metadataPolicy: None property: password secretKey: password --- apiVersion: external-secrets.io/v1beta1 kind: ExternalSecret metadata: name: database-certs spec: secretStoreRef: kind: SecretStore name: gsm data: - secretKey: server.crt remoteRef: key: cloudsql-&lt;instansnavn&gt;-ca-certificate - secretKey: client.crt remoteRef: key: cloudsql-&lt;instansnavn&gt;-&lt;bruker&gt;-client-certificate ### client.key i PEM, fungerer for de fleste - secretKey: client.key remoteRef: key: cloudsql-&lt;instansnavn&gt;-&lt;bruker&gt;-client-key ### VISST DU TRENGER PK8 (JDBC kan kreve dette) - Bare ta med ÃˆN key, ikke begge - secretKey: client.pk8 remoteRef: decodingStrategy: Base64 # MÃ¥ vÃ¦re med for pk8 key: cloudsql-&lt;instansnavn&gt;-&lt;bruker&gt;-client-key-pk8   NÃ¥ har du hentet alle hemmelighetene du trenger, og kan bruke disse i skiperator manifestet ditt:  apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: minapp spec: image: ghcr.io/kartverket/minapp port: 8080 replicas: 2 accessPolicy: outbound: external: - host: &lt;instansnavn&gt;-db-&lt;env&gt; # Velg selv hva du vil kalle denne, sÃ¥ lenge den er unik ip: 10.x.x.x # Privat IP-adresse til databasen, den finner du i GCP ports: - name: sql port: 5432 protocol: TCP env: ## DISSE env VERDIENE ER EKSEMPLER, OG MÃ… JUSTERES FOR HVER APPLIKASJON - name: POSTGRES_DB value: minapp - name: POSTGRES_USER value: minappbrukernavn - name: POSTGRES_PASSWORD valueFrom: secretKeyRef: key: db_password name: minapp-hemmligheter - name: PGSSLCA value: /app/db-certs/server.crt - name: PGSSLKEY value: /app/db-certs/client.key - name: PGSSLCERT value: /app/db-certs/client.crt filesFrom: - mountPath: /app/db-certs secret: database-certs   Skiperator vil nÃ¥:  lage en NetworkPolicy som gir applikasjonen tilgang til databasen'mounte' sertifikatene inn i filsystemet til poden, slik applikasjonen kan bruke de til Ã¥ koble til databasenlaste inn passord hemmeligheten som en env variabel inn i poden, slik applikasjonen kan koble til databasen  ","version":"Next","tagName":"h2"},{"title":"Bruke CloudSQL fra Java applikasjonerâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#bruke-cloudsql-fra-java-applikasjoner","content":" Skal du bruke CloudSQL fra Java applikasjoner mÃ¥ du lage til ExternalSecrets og konfigurere skiperator som ovenfor, men bruk pk8 nÃ¸kkel istedenfor vanlig pem nÃ¸kkel. Det skal vÃ¦re nok Ã¥ konfigurere en connection string som ser noe slik ut postgresql://&lt;privat-ip&gt;:5432/&lt;database-navn&gt;?sslmode=require&amp;sslrootcert=/app/db-certs/server.crt&amp;sslcert=/app/db-certs/client.crt&amp;sslkey=/app/db-certs/client.pk8  Alternativt kan man ogsÃ¥ bruke en Cloud Sql Auth Proxy connector, men da vil man fÃ¥ litt dÃ¥rligere ytelse. Bruker man en connector sÃ¥ slipper man Ã¥ bruke certs, men man mÃ¥ Ã¥pne for port 3307 mot databasen i access policies i skiperator manifestet.  ","version":"Next","tagName":"h3"},{"title":"Monitorering og alarmeringâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#monitorering-og-alarmering","content":" Fungerer bare dersom dere bruker hÃ¸yere versjon enn 0.9.1 av cloud_sql modulen.  Vi har laget et dashboard, sammen med DBAene, for monitorering av CloudSQL databasene, som kan finne her. I tillegg sÃ¥ finnes ogsÃ¥ Googles standard dashboard og metrikker som man kan finne inne pÃ¥ CloudSQL ressursen i GCP consolen.  For alarmering sÃ¥ brukes grafana-alerts repoet som for alle andre type alerts. Her har vi utviklet en cloud_sql_alerts modul som gir dere et sett med standard alarmer. Metrikker vi baserer oss pÃ¥ blir hentet ut ved hjelp av sql_exporter, disse metrikkene er hentet ut pÃ¥ grunnlag av SQL-spÃ¸rringer som DBAene har predefinert. Ã˜nskes det andre metrikker sÃ¥ ta kontakt med dem.  Det er ogsÃ¥ tilgjengelig et sett med standardmetrikker fra Google gjennom grafana, for Ã¥ bruke disse sÃ¥ gÃ¥ inn i explore view i grafana. Velg Google Cloud Monitoring som datasource, og velg prosjektet ditt og Cloudsql som service. Se pÃ¥ cloud_sql_alerts modulen dersom du Ã¸nsker Ã¥ se hvordan de kan brukes i en alert.  ","version":"Next","tagName":"h2"},{"title":"Backup og katastrofehÃ¥ndteringâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#backup-og-katastrofehÃ¥ndtering","content":" ","version":"Next","tagName":"h2"},{"title":"Backupâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#backup","content":" CloudSQL er en google managed lÃ¸sning av postgres, og det betyr ogsÃ¥ at det har et innebygd backup system, og hÃ¥ndteres i gcp console. Dette systemet tar automatisk backup av databasen din, og lagrer disse i 7 dager som standard. Hvis du har behov for Ã¥ bevare backups lengre enn dette kan det konfigureres med en variabel til terraform-modulen, ref: input_retained_backupsBackupen er inkrementel og man har Point-in-time recovery tilgjengelig. Vi anbefaler at du leser gjennom Google sin dokumentasjon for Ã¥ forstÃ¥ hvordan backup fungerer i CloudSQL.  ","version":"Next","tagName":"h3"},{"title":"KatastrofehÃ¥ndteringâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#katastrofehÃ¥ndtering","content":" Google Cloud SQL har innebygd failover, og det betyr at dersom primÃ¦rinstansen din gÃ¥r ned, sÃ¥ vil en av de tilgjengelige replicaene ta over. Dette mÃ¥ konfigureres i terraform, ved bruk av availability_type variabelen, default pÃ¥ denne er ZONAL som betyr at du ikke fÃ¥r en secondary instans. I produksjon er det anbefalt Ã¥ ha en secondary instans, og da mÃ¥ availability_type settes til REGIONAL i terraform. Les mer her: Google sin dokumentasjon  ","version":"Next","tagName":"h3"},{"title":"Viktig Ã¥ huske pÃ¥â€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#viktig-Ã¥-huske-pÃ¥","content":" ","version":"Next","tagName":"h2"},{"title":"Max connectionsâ€‹","type":1,"pageTitle":"Cloud SQL for PostgreSQL","url":"/docs/lagring/cloud-sql#max-connections","content":" I enkelte situasjoner kan hele CloudSQL-instansen bli utilgjengelig, og man vil motta fÃ¸lgende feilmelding: HTTPError 409: Operation failed because another operation was already in progress. Try your request after the current operation is complete.  Basert pÃ¥ erfaring skyldes dette som regel at det er Ã¥pnet for mange samtidige connections mot databasen. For eksempel, dersom max_connections-variabelen i Terraform-modulen er satt til 100, og man har to applikasjoner som hver bruker 30 connections og kjÃ¸rer med to replikas, vil det totalt bli 120 connections â€“ i tillegg til noen system-connections (typisk 2â€“3).  I slike tilfeller kan instansen bli utilgjengelig: man kan verken restarte den eller gjÃ¸re konfigurasjonsendringer.  LÃ¸sning: Skaler ned alle applikasjoner (sett replicas til 0), og vent opptil Ã©n time. NÃ¥r connections er frigjort, kan man justere max_connections-verdien.  Anbefaling: Implementer connection pooling i applikasjonene. Hver enkelt connection Ã¸ker belastningen pÃ¥ databaseinstansen, og unÃ¸dvendig hÃ¸yt antall tilkoblinger er bÃ¥de ineffektivt og kostbart. Legg ogsÃ¥ til denne alarmmodulen i grafana-alerts, da fÃ¥r dere alarmer nÃ¥r connections nÃ¦rmer seg maks. ","version":"Next","tagName":"h3"},{"title":"Grafana and GCP","type":0,"sectionRef":"#","url":"/docs/observability/grafana-and-GCP","content":"","keywords":"","version":"Next"},{"title":"Google Cloud Monitoringâ€‹","type":1,"pageTitle":"Grafana and GCP","url":"/docs/observability/grafana-and-GCP#google-cloud-monitoring","content":" It is possible to get metrics from a Google Cloud project by the use of the Grafana data source â€œGoogle Cloud Monitoringâ€.    Through the use of this data source, you will be able to see all metrics that are exposed through different Google Cloud services, such as CloudSQL, BigQuery, CloudKMS, Logging etc. This can then be added to your dashboards and alarms.  ","version":"Next","tagName":"h2"},{"title":"Setting up the data sourceâ€‹","type":1,"pageTitle":"Grafana and GCP","url":"/docs/observability/grafana-and-GCP#setting-up-the-data-source","content":" While the data source is present, it will not scrape all projects in the Kartverket organisation in GCP by default. As of writing this (13 Oct 2023), SKIP does not facilitate this setup in any particular way, but you are free to do it the â€œSKIP wayâ€.  To add your GCP project to the list of projects, simply add the GCP role monitoring.viewer to the Google Service Account grafana-scraper@kubernetes-0dca.iam.gserviceaccount.com. It should look like the below image.    Remember that if you do not have access to editing IAM for your projects by default, you can always elevate your access using JIT Access .  Note that the setup for this may change in the future as this feature is somewhat unexplored as of writing this documentation. ","version":"Next","tagName":"h3"},{"title":"Alerting with Grafana","type":0,"sectionRef":"#","url":"/docs/observability/alerting-with-grafana","content":"","keywords":"","version":"Next"},{"title":"Creating alertsâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#creating-alerts","content":" The first step to start adding alerts to your application is to onboard that app to SKIP. Grafana is only used for SKIP, the rest of Kartverket uses Zabbix. Once you have been onboarded and deployed your app to SKIP you can request access to the grafana-alerts repo.  The grafana-alerts repo is designed to be a repo that contains the alerts of all teams and handles deployment of alerts to Grafana. You will get a file which contains the configuration of your alerts in a Terraform format. For example, the file could look like this:  resource &quot;grafana_folder&quot; &quot;MYTEAMNAME_folder&quot; { for_each = local.envs title = &quot;Alerts MYTEAMNAME ${each.key}&quot; } module &quot;MYTEAMNAME_alerts_kubernetes&quot; { source = &quot;../modules/grafana_alert_group&quot; for_each = local.envs name = &quot;kube-state-metrics&quot; env = each.value runbook_base_url = # URL to document describing each alert folder_uid = grafana_folder.MYTEAMNAME_folder[each.key].uid team = { name = &quot;MYTEAMNAME&quot; } alerts = { KubernetesPodNotHealthy = { summary = &quot;Kubernetes Pod not healthy (instance {{ $labels.instance }})&quot; description = &quot;Pod has been in a non-ready state for longer than 15 minutes.\\n VALUE = {{ $value }}\\n LABELS = {{ $labels }}&quot; severity = &quot;critical&quot; for = &quot;15m&quot; expr = &lt;&lt;EOT sum by (namespace, pod) (kube_pod_status_phase{phase=~&quot;Pending|Unknown|Failed&quot;, namespace=~&quot;nrl-.*&quot;}) EOT }, # ... more alerts } }   In the above file we create an alert that monitors the health of a pod in all nrl namespaces. Pay attention to the expr field, which is the Prometheus query language PromQL. If you want to learn more about PromQL look at the documentation as well as some examples from the Prometheus documentation and the examples at awesome prometheus alerts .  This is a file that you will be given CODEOWNER access to. This means that you and your team will be able to update this file and review your own changes without involving SKIP. Your team is expected to keep them at a level that verifies the running state of the application.  Updating this file in the GitHub repo will automatically deploy the changes to Grafana.  ","version":"Next","tagName":"h2"},{"title":"Grafana Oncall Alertsâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#grafana-oncall-alerts","content":" In addition to Grafana alerts, we have installed a plugin to Grafana called Oncall. This plugin gives us the possibility of adding schedules/shifts and custom alerting behaviour. It also gives your team an overview and a system to handle alerts.    ","version":"Next","tagName":"h2"},{"title":"Integrationâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#integration","content":" In order to start using Oncall you need an oncall integration to Grafana. This integration will show up as a contact point in Grafana which can be used in notification policies to route alerts to your integration.  From the integration you can add routes and escalation chains which decides how the integration will notify the team. The standard setup is to send all alerts to a slack channel, and also to a team member on schedule or shared inbox.      In the grafana-alerts repository we have created an oncall_integration module, which you can use to create your teams integration.  ","version":"Next","tagName":"h3"},{"title":"Routesâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#routes","content":" In an integration you always have a default route, but you can also have a specified route. A route will decide which escalation chain the integration should use when it receives an alert. For example if you have a critical app that requires 24/7 alerting, you can create a route that checks for certain labels, and if found, it will route the alert to the â€œappdriftâ€ escalation chain.  ","version":"Next","tagName":"h3"},{"title":"Schedulesâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#schedules","content":" An Oncall Schedule is a collection of â€œShiftsâ€. In short this means that you can assign a person to a shift, and that person will receive all alerts sent to the Oncall integration for the duration of their shift. In the grafana-alerts repository you can use the oncall_team integration to create both a schedule and escalation chain.    ","version":"Next","tagName":"h3"},{"title":"Escalation Chainsâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#escalation-chains","content":" Escalation chains are instructions to Oncall on how to notify you when the connected integration receives an alert. The standard setup here is to contact the assigned person in the set way in Oncall.  The escalation chain below will contact the person which has an assigned shift in Schedule, in the way they have set in Oncall. Usually email or slack mentions.    In Oncall â†’ Users â†’ edit user, you can decide how you want the escalation chain to contact you.    ","version":"Next","tagName":"h3"},{"title":"Terraformâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#terraform","content":" A typical Grafana Oncall setup for a team will look like this:  module &quot;team_oncall&quot; { source = &quot;../modules/oncall_team&quot; team_name = &quot;team&quot; use_schedule = true } module &quot;team_integration&quot; { source = &quot;../modules/oncall_integration&quot; integration_name = &quot;team&quot; slack_channel_name = &quot;grafana-oncall&quot; //Not required, replace with your own vaktlag_enabled = false default_escalation_chain_id = module.team_oncall.team_escalation_chain_id }   note The slack channel must already exist in grafana. If you want to use predefined users instead of a schedule, then the users must already exist in Oncall.  ","version":"Next","tagName":"h3"},{"title":"Notification policiesâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#notification-policies","content":" You also have to configure notification policies to use your integration. Terraform doesnâ€™t activate the contact point of the integration yet, so this has to be done manually before adding this to terraform(do this by navigating to your integration and activate the contact point). Add code here.  Example:  policy { contact_point = &quot;watchdog&quot; group_by = [&quot;cluster&quot;, &quot;alertname&quot;] matcher { label = &quot;team&quot; match = &quot;=&quot; value = &quot;Vaktlag&quot; } }   ","version":"Next","tagName":"h3"},{"title":"24/7 alertingâ€‹","type":1,"pageTitle":"Alerting with Grafana","url":"/docs/observability/alerting-with-grafana#247-alerting","content":" Once you have configured a set of alerts, you might want them to be monitored 24/7. Kartverket provides a solution for this in the form of â€œVaktlagetâ€. Vaktlaget is a team consisting of various people in IT-drift that have a special agreement that allows them to be notified and follow up when an alert fires outside of normal working hours.  The first step for getting your alerts onboarded onto vaktlaget is to maintain a set of alerts that only fire when there is a serious outage. Keep in mind that an alert that fires will potentially wake people in the middle of the night, so it is paramount that this set of alerts donâ€™t contain non-critical or â€œflakyâ€ alerts. These alerts should be given a severity of â€œcriticalâ€ to make them distinct from other alerts.  Once you have done this you need to contact vaktlaget to discuss the alerts you wish to onboard. They will comment on what is important enough to be onboarded and you will end up with a set of alerts that is a neat balance between ensuring the stability of our systems and preserving the mental health of the people on the alert schedule.  After youâ€™ve discussed with vaktlaget you can contact SKIP in #gen-skip to have your alert integration be switched over. When this is done, all alerts labeled with env=prod and severity=critical will be sent to vaktlaget using the following schedule:  The alerts will be sent to your slack channel all dayThe alerts will be sent to appdrift as email, SMS and phone call between 7 and 22The alerts will be sent to infrastrukturdrift as email, SMS and phone call between 22 and 7  You can also create a pull request in grafana-alerts with the vaktlag escalation chain added to your integration:  module &quot;skip&quot; { source = &quot;../modules/oncall_integration&quot; integration_name = &quot;skip&quot; slack_channel_name = &quot;grafana-oncall&quot; //Not required, replace with your own vaktlag_enabled = true vaktlag_escalation_chain_id = module.vaktlag.appdrift_escalation_chain_id default_escalation_chain_id = module.skip.team_escalation_chain_id }   When you later add more alerts to the critical level you also need to discuss with vaktlaget so they can sign off on the new alerts before they are added. ","version":"Next","tagName":"h2"},{"title":"Grafana cheat sheet","type":0,"sectionRef":"#","url":"/docs/observability/grafana-cheat-sheet","content":"","keywords":"","version":"Next"},{"title":"Useful Mimir queriesâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#useful-mimir-queries","content":" ","version":"Next","tagName":"h2"},{"title":"Top 20 of metrics with high cardinalityâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#top-20-of-metrics-with-high-cardinality","content":" https://monitoring.kartverket.cloud/goto/cc_GwW1SR?orgId=1  # Set time range to &quot;Last 5 minutes&quot; topk(20, count by (__name__)({__name__=~&quot;.+&quot;}))   ","version":"Next","tagName":"h3"},{"title":"Top 10 namespaces with overallocated cpu resourcesâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#top-10-namespaces-with-overallocated-cpu-resources","content":" https://monitoring.kartverket.cloud/goto/6V2jQZJIg?orgId=1  topk(10, sum by (namespace) (kube_pod_container_resource_requests{job=&quot;integrations/kubernetes/kube-state-metrics&quot;, resource=&quot;cpu&quot;}) - sum by (namespace) (rate(container_cpu_usage_seconds_total{}[$__rate_interval])))   ","version":"Next","tagName":"h3"},{"title":"Sum of overallocated cpu for containers by namespaceâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#sum-of-overallocated-cpu-for-containers-by-namespace","content":" https://monitoring.kartverket.cloud/goto/xF2DlW1SR?orgId=1  sum by (container) (kube_pod_container_resource_requests{job=&quot;integrations/kubernetes/kube-state-metrics&quot;, resource=&quot;cpu&quot;, namespace=~&quot;matrikkel.*&quot;}) - sum by (container) (rate(container_cpu_usage_seconds_total{namespace=~&quot;matrikkel.*&quot;}[$__rate_interval]))   ","version":"Next","tagName":"h3"},{"title":"Daily amount of requests by destination app and response codeâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#daily-amount-of-requests-by-destination-app-and-response-code","content":" sum by (destination_app, response_code) ( increase(istio_requests_total{namespace=&quot;&lt;namespace name&gt;&quot;, response_code=~&quot;.*&quot;, source_app=&quot;istio-ingress-external&quot;}[1d]) )   ","version":"Next","tagName":"h3"},{"title":"Useful Loki queriesâ€‹","type":1,"pageTitle":"Grafana cheat sheet","url":"/docs/observability/grafana-cheat-sheet#useful-loki-queries","content":"","version":"Next","tagName":"h3"},{"title":"Logs with Loki","type":0,"sectionRef":"#","url":"/docs/observability/logs-with-Loki","content":"Logs with Loki SKIPâ€™s LGTM stack is set up to automatically collect logs from all applications running in our Kubernetes clusters. There is nothing in particular you as a developer need to configure or set in order to achieve this, apart from ensuring that your application logs to stdout . These are picked up by the Grafana Agent through the PodLogs custom resource, which specifies which namespaces to collect logs for (all of them in this case) and a set of relabeling rules to ensure that we have a common set of labels for use in searching, dashboards and alerting. Logs are collected and stored in Loki, which is backed by an on-premise S3-compatible Scality storage bucket system, one for each cluster. Each Loki instance is defined as a data source in Grafana, which provides the tools for search queries, dashboards and alerting. For an overview of the Explore section as it pertains to Loki, see https://grafana.com/docs/grafana/latest/explore/logs-integration/ . This and other pages outline the features and how to use it efficiently in relatively good detail, so we shall not attempt to reproduce such a guide here, only to point out a few things as they apply to our own setup. By necessity, the default label set is rather limited compared to what some of you might wish. This is because a large selection of labels can be extremely detrimental to performance - see https://grafana.com/docs/loki/latest/get-started/labels/bp-labels/ for an explanation. Hence, it is recommended to use filter expressions instead. You can filter on log lines containing/not containing a given text, regex expression and a host of other possibilities. The search function is also equipped with a JSON parser which makes it easier to filter on the fields you want. You can choose between two modes of searching: typing a query manually, or building a query through Grafanaâ€™s graphical query builder. As long as the query you have built or typed is valid, you can seamlessly switch between the two modes. Above: Using JSON parser to extract fields and filtering on method â€œPOSTâ€","keywords":"","version":"Next"},{"title":"Metrikker","type":0,"sectionRef":"#","url":"/docs/observability/metrikker","content":"","keywords":"","version":"Next"},{"title":"Eksponer metrikker fra applikasjonenâ€‹","type":1,"pageTitle":"Metrikker","url":"/docs/observability/metrikker#eksponer-metrikker-fra-applikasjonen","content":" For Ã¥ kunne eksponere metrikker fra applikasjonen mÃ¥ du gjÃ¸re fÃ¸lgende:  Eksponer metrikker pÃ¥ et eget endepunkt, f.eks. /metrics. Det beste her er ogsÃ¥ Ã¥ eksponere metrikker pÃ¥ en egen port for Ã¥ unngÃ¥ at endepunktet uheldigvis eksponeres eksternt. Om du ikke kan gjÃ¸re dette, ta kontakt med SKIP for Ã¥ sammen sÃ¸rge for at data ikke eksponeres eksternt. Endre Skiperator-manifestet ved Ã¥ legge til en ekstra port og tillate innhenting av metrikker; apiVersion: skiperator.kartverket.no/v1alpha1 kind: Application metadata: name: super-app namespace: team-foo-main spec: image: &quot;kartverket/example&quot; port: 8080 # Definer egen port additionalPorts: - name: management port: 8181 protocol: TCP # Skru pÃ¥ innsamling av metrikker fra den nye porten prometheus: port: management path: &quot;/metrics&quot;   ","version":"Next","tagName":"h2"},{"title":"Utforsk metrikker i Metrics Exploreâ€‹","type":1,"pageTitle":"Metrikker","url":"/docs/observability/metrikker#utforsk-metrikker-i-metrics-explore","content":" For Ã¥ finne ut hvilke metrikker du har tilgjengelig for applikasjonen, sjekk ut Metrics Explore.    Bruk labels for Ã¥ filtrere pÃ¥ f.eks. namespace, application eller container for Ã¥ finne metrikker som er interessante, og sÃ¸k pÃ¥ metrikknavn i feltet. Du kan velge &quot;Select&quot; for Ã¥ se videre pÃ¥ en enkeltmetrikk, og trykke pÃ¥ kompassikonent for Ã¥ gÃ¥ videre til Explore for Ã¥ gjÃ¸re metrikkspÃ¸rringen mer nÃ¸yaktig.  Se ogsÃ¥:  ðŸ“š Grafanas egen dokumentasjon beskriver alle detaljene.ðŸŽ¬ Grafana har ogsÃ¥ en demovideo.  ","version":"Next","tagName":"h2"},{"title":"Lag spÃ¸rringer i Exploreâ€‹","type":1,"pageTitle":"Metrikker","url":"/docs/observability/metrikker#lag-spÃ¸rringer-i-explore","content":" Explore lar deg videreforedle spÃ¸rringer, eksperimentere og grave raskt.    Her kan du gjÃ¸re spÃ¸rringer i split screen fra ulike datakilder, korrelere data fra bÃ¥de logger, metrikker og traces, samt legge ferdige spÃ¸rringer som paneler i dashboards.  Se ogsÃ¥:  ðŸ“š Grafanas dokumentasjon ","version":"Next","tagName":"h2"},{"title":"Recording and alerting rules","type":0,"sectionRef":"#","url":"/docs/observability/recording-and-alerting-rules","content":"","keywords":"","version":"Next"},{"title":"Recording rules in Mimirâ€‹","type":1,"pageTitle":"Recording and alerting rules","url":"/docs/observability/recording-and-alerting-rules#recording-rules-in-mimir","content":" SKIP supports https://prometheus.io/docs/prometheus/latest/configuration/recording_rules/ through Mimir and Grafana Agent. Just define a PrometheusRule object in your applicationâ€™s namespace, and Grafana Agent will pick it up and add it to Mimir.  For more information, see the Prometheus documentation above, or visit https://grafana.com/docs/grafana/latest/alerting/alerting-rules/create-mimir-loki-managed-recording-rule/  ","version":"Next","tagName":"h2"},{"title":"Recording rules in Lokiâ€‹","type":1,"pageTitle":"Recording and alerting rules","url":"/docs/observability/recording-and-alerting-rules#recording-rules-in-loki","content":" TODO ","version":"Next","tagName":"h2"},{"title":"ðŸš¦ Trafikkstyring","type":0,"sectionRef":"#","url":"/docs/trafikkstyring","content":"ðŸš¦ Trafikkstyring Under denne siden finner du artikler som omhandler oppsett og bruk av Google Cloud Platform.","keywords":"","version":"Next"},{"title":"Real User Monitoring with Faro","type":0,"sectionRef":"#","url":"/docs/observability/real-user-monitoring-with-Faro","content":"","keywords":"","version":"Next"},{"title":"Getting startedâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#getting-started","content":" Setting up Faro requires two steps which are explained below:  Installing the SDKConfiguring the SDK  It will also be useful to start by reading the Faro quick start guide . See also the README of the Faro GitHub page for more links to relevant documentation.  ","version":"Next","tagName":"h2"},{"title":"Installing the SDKâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#installing-the-sdk","content":" If you use React this is done by running one of the following commands:  # If you use npm npm i -S @grafana/faro-web-sdk # If you use Yarn yarn add @grafana/faro-web-sdk   ","version":"Next","tagName":"h3"},{"title":"Configuring the SDKâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#configuring-the-sdk","content":" Import and configure the following options in your appâ€™s entrypoint (main.js or similar).  import { initializeFaro } from &quot;@grafana/faro-react&quot;; initializeFaro({ app: { name: &quot;my_app_name&quot;, environment: getCurrentEnvironment(), }, url: &quot;https://faro.atgcp1-prod.kartverket.cloud/collect&quot;, });   ","version":"Next","tagName":"h3"},{"title":"List of valid options for appâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#list-of-valid-options-for-app","content":" \tType\tDescription\tRequired?name\tstring\tThe name of the application as it will appear on dashboards in Grafana\tYes environment\tâ€œlocalhostâ€ | â€œdevâ€ | â€œtestâ€ | â€œprodâ€\tThe environment the frontend is currently running in. This is used to filter data in Grafana dashboards\tYes  ","version":"Next","tagName":"h3"},{"title":"Configuring the SDK with React Router integrationâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#configuring-the-sdk-with-react-router-integration","content":" Grafana Faro supports integration with React Router. This gives you events for page navigation and re-renders. See the Faro docs for more information on this.  ","version":"Next","tagName":"h3"},{"title":"Showing the dataâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#showing-the-data","content":" When the metrics have started to be gathered, they will be visible in a dedicated Grafana Faro dashboard. This dashboard can be found here .  It is also possible to search for data in the explore view . Useful labels to search for are:  faro_app_namekindenv  ","version":"Next","tagName":"h2"},{"title":"Privacy concernsâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#privacy-concerns","content":" note It is up to you and your team to consider the how to use Faro with personal information as outlined in your IP and DPIA  When we send data to Faro, it is mostly metrics that donâ€™t contain any PII . It is possible to include PII like name, IP or anything that is accessible from JavaScript in the SDK, but this is not done by default and requres calling the setUser function on the SDK.  A session ID is sent in to enable de-duplicating events like navigation between pages and ranking top users. This is a randomly generated string and is stored in the userâ€™s browser SessionStorage. Note that even though this is not a cookie, this means a â€œcookie bannerâ€ is required as per the EUâ€™s ePrivacy directive .  As SessionInstrumentation is included by default in the web instrumentation of the JavaScript SDK, disabling it requires invoking the SDK with instrumentations set and omitting the SessionInstrumentation function.  Data is stored on SKIPâ€™s atgcp1-prod cluster, which stores data in Google Cloud Storage europe-north1 region. This region is located in Finland, and is thus within EU. This means no data leaves the EUâ€™s borders which means the storage of the data is compliant with GDPR.  ","version":"Next","tagName":"h2"},{"title":"Rate limitingâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#rate-limiting","content":" A rate limit for requests is implemented and is currently set to 50 requests per second. This is shared between all users of Faro, so itâ€™s possible that we eventually reach the limit. Contact SKIP if you start getting queries rejected with HTTP 429 Too Many Requests .  The rate limiting algorighm is a token bucket algorithm, where a bucket has a maximum capacity for up to burst_size requests and refills at a rate of rate per second.  Each HTTP request drains the capacity of the bucket by one. Once the bucket is empty, HTTP requests are rejected with an HTTP 429 Too Many Requests status code until the bucket has more available capacity.  ","version":"Next","tagName":"h2"},{"title":"Tracingâ€‹","type":1,"pageTitle":"Real User Monitoring with Faro","url":"/docs/observability/real-user-monitoring-with-Faro#tracing","content":" Faro supports tracing of HTTP requests, but this is not currently implemented in the collector on SKIP. Contact SKIP if you want this! ","version":"Next","tagName":"h2"}],"options":{"languages":["en","no"],"id":"default"}}